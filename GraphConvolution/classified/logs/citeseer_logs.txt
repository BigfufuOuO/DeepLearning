----------------------------------------------------------
Time: 0516-1117
Training Loss: 
1.9458, 1.9124, 1.8677, 1.8132, 1.7545, 1.6856, 1.6114, 1.5374, 1.4701, 1.4011, **Epoch: 10
1.3412, 1.2745, 1.2176, 1.1687, 1.1145, 1.0772, 1.0278, 0.9946, 0.9507, 0.9191, **Epoch: 20
0.8969, 0.8621, 0.8383, 0.8083, 0.7945, 0.7658, 0.7456, 0.7374, 0.7269, 0.6980, **Epoch: 30
0.7041, 0.6897, 0.6795, 0.6684, 0.6723, 0.6551, 0.6440, 0.6344, 0.6324, 0.6268, **Epoch: 40
0.6218, 0.6135, 0.6164, 0.6090, 0.6041, 0.6110, 0.6033, 0.5919, 0.5869, 0.5882, **Epoch: 50
0.5850, 0.5893, 0.5881, 0.5920, 0.5838, 0.5814, 0.5799, 0.5690, 0.5701, 0.5785, **Epoch: 60
0.5722, 0.5772, 0.5687, 0.5631, 0.5704, 0.5718, 0.5574, 0.5720, 0.5725, 0.5731, **Epoch: 70
0.5517, 0.5664, 0.5703, 0.5660, 0.5673, 0.5642, 0.5665, 0.5766, 0.5730, 0.5623, **Epoch: 80
0.5607, 0.5675, 0.5592, 0.5579, 0.5691, 0.5715, 0.5635, 0.5707, 0.5739, 0.5679, **Epoch: 90
0.5718, 0.5800, 0.5664, 0.5642, 0.5682, 0.5660, 0.5689, 0.5701, 0.5725, 0.5584, **Epoch: 100
0.5717, 0.5683, 0.5708, 0.5652, 0.5688, 0.5687, 0.5685, 0.5660, 0.5683, 0.5778, **Epoch: 110
0.5658, 0.5730, 0.5573, 0.5605, 0.5612, 0.5744, 0.5656, 0.5605, 0.5609, 0.5602, **Epoch: 120
0.5678, 0.5764, 0.5610, 0.5723, 0.5624, 0.5577, 0.5626, 0.5733, 0.5745, 0.5691, **Epoch: 130
0.5694, 0.5732, 0.5687, 0.5683, 0.5617, 0.5632, 0.5509, 0.5585, 0.5522, 0.5668, **Epoch: 140
0.5655, 0.5763, 0.5610, 0.5705, 0.5616, 0.5627, 0.5605, 0.5585, 0.5605, 0.5630, **Epoch: 150
0.5703, 0.5665, 0.5682, 0.5606, 0.5685, 0.5682, 0.5564, 0.5588, 0.5637, 0.5583, **Epoch: 160
0.5675, 0.5629, 0.5666, 0.5526, 0.5588, 0.5653, 0.5663, 0.5560, 0.5690, 0.5659, **Epoch: 170
0.5646, 0.5613, 0.5608, 0.5622, 0.5741, 0.5580, 0.5592, 0.5590, 0.5556, 0.5791, **Epoch: 180
0.5676, 0.5703, 0.5602, 0.5687, 0.5526, 0.5564, 0.5576, 0.5657, 0.5652, 0.5771, **Epoch: 190
0.5638, 0.5640, 0.5707, 0.5609, 0.5610, 0.5649, 0.5674, 0.5622, 0.5624, 0.5527, **Epoch: 200
Validation Loss: 
1.9157, 1.8746, 1.8243, 1.7681, 1.7116, 1.6450, 1.5770, 1.5088, 1.4515, 1.3933, **Epoch: 10
1.3263, 1.2875, 1.2355, 1.1984, 1.1594, 1.1121, 1.0826, 1.0514, 1.0157, 0.9932, **Epoch: 20
0.9695, 0.9485, 0.9353, 0.9187, 0.9138, 0.9035, 0.8875, 0.8728, 0.8553, 0.8519, **Epoch: 30
0.8416, 0.8354, 0.8488, 0.8433, 0.8104, 0.8268, 0.8274, 0.8325, 0.8233, 0.8186, **Epoch: 40
0.8125, 0.7989, 0.8159, 0.8161, 0.8012, 0.8044, 0.8079, 0.7962, 0.8050, 0.7969, **Epoch: 50
0.7921, 0.7910, 0.7990, 0.8025, 0.7948, 0.7948, 0.7995, 0.7888, 0.8032, 0.7937, **Epoch: 60
0.7993, 0.7950, 0.8033, 0.7944, 0.7892, 0.7924, 0.7997, 0.7927, 0.7946, 0.7881, **Epoch: 70
0.7940, 0.8051, 0.7817, 0.7875, 0.7974, 0.7999, 0.7924, 0.7856, 0.7837, 0.7880, **Epoch: 80
0.7918, 0.7919, 0.7876, 0.7916, 0.7984, 0.8011, 0.7891, 0.7970, 0.8102, 0.7853, **Epoch: 90
0.8264, 0.8068, 0.7925, 0.7882, 0.7868, 0.7955, 0.8014, 0.7745, 0.8080, 0.8021, **Epoch: 100
0.8040, 0.7960, 0.7946, 0.7949, 0.8002, 0.8032, 0.7953, 0.8031, 0.7859, 0.7924, **Epoch: 110
0.8050, 0.7838, 0.8038, 0.7833, 0.7873, 0.7969, 0.7838, 0.8079, 0.8053, 0.7952, **Epoch: 120
0.8075, 0.8019, 0.7912, 0.7938, 0.7998, 0.8078, 0.7925, 0.7912, 0.7973, 0.7962, **Epoch: 130
0.7819, 0.7880, 0.7979, 0.7895, 0.8180, 0.7972, 0.8042, 0.8059, 0.7972, 0.7892, **Epoch: 140
0.7890, 0.7942, 0.7876, 0.7847, 0.7950, 0.8079, 0.7902, 0.7838, 0.7917, 0.8095, **Epoch: 150
0.8055, 0.7917, 0.7915, 0.7966, 0.7916, 0.7973, 0.7844, 0.7938, 0.7981, 0.8028, **Epoch: 160
0.7966, 0.7921, 0.7986, 0.7922, 0.7884, 0.7920, 0.7914, 0.7981, 0.7974, 0.7924, **Epoch: 170
0.7930, 0.7827, 0.8003, 0.8095, 0.7992, 0.8061, 0.8033, 0.8010, 0.7917, 0.8022, **Epoch: 180
0.7977, 0.7828, 0.7853, 0.7995, 0.8067, 0.8029, 0.8030, 0.7977, 0.8009, 0.7863, **Epoch: 190
0.7997, 0.7972, 0.7859, 0.8022, 0.7913, 0.8058, 0.8029, 0.7901, 0.7920, 0.7850, **Epoch: 200
Training Accuracy: 
0.3912, 0.4872, 0.4992, 0.4607, 0.4819, 0.5921, 0.6699, 0.7115, 0.7221, 0.7228, **Epoch: 10
0.7319, 0.7432, 0.7659, 0.7795, 0.7825, 0.7863, 0.7961, 0.7915, 0.7900, 0.8036, **Epoch: 20
0.7976, 0.7983, 0.8006, 0.8089, 0.8112, 0.8089, 0.8134, 0.8157, 0.8134, 0.8240, **Epoch: 30
0.8331, 0.8301, 0.8278, 0.8369, 0.8308, 0.8384, 0.8338, 0.8369, 0.8452, 0.8376, **Epoch: 40
0.8444, 0.8421, 0.8421, 0.8474, 0.8482, 0.8527, 0.8542, 0.8482, 0.8489, 0.8565, **Epoch: 50
0.8474, 0.8467, 0.8527, 0.8535, 0.8550, 0.8580, 0.8482, 0.8595, 0.8489, 0.8467, **Epoch: 60
0.8512, 0.8520, 0.8542, 0.8580, 0.8520, 0.8527, 0.8527, 0.8603, 0.8565, 0.8497, **Epoch: 70
0.8588, 0.8565, 0.8497, 0.8497, 0.8580, 0.8542, 0.8633, 0.8512, 0.8527, 0.8467, **Epoch: 80
0.8550, 0.8610, 0.8489, 0.8482, 0.8512, 0.8535, 0.8550, 0.8565, 0.8542, 0.8573, **Epoch: 90
0.8474, 0.8512, 0.8557, 0.8573, 0.8557, 0.8588, 0.8595, 0.8542, 0.8527, 0.8610, **Epoch: 100
0.8542, 0.8550, 0.8550, 0.8512, 0.8505, 0.8565, 0.8542, 0.8565, 0.8527, 0.8535, **Epoch: 110
0.8603, 0.8497, 0.8610, 0.8512, 0.8580, 0.8573, 0.8618, 0.8527, 0.8535, 0.8610, **Epoch: 120
0.8527, 0.8656, 0.8512, 0.8588, 0.8573, 0.8565, 0.8573, 0.8474, 0.8580, 0.8535, **Epoch: 130
0.8625, 0.8542, 0.8580, 0.8565, 0.8595, 0.8550, 0.8527, 0.8550, 0.8580, 0.8505, **Epoch: 140
0.8437, 0.8595, 0.8542, 0.8610, 0.8610, 0.8557, 0.8610, 0.8535, 0.8618, 0.8512, **Epoch: 150
0.8557, 0.8497, 0.8550, 0.8580, 0.8542, 0.8512, 0.8527, 0.8588, 0.8550, 0.8595, **Epoch: 160
0.8520, 0.8595, 0.8557, 0.8557, 0.8580, 0.8565, 0.8618, 0.8588, 0.8542, 0.8603, **Epoch: 170
0.8542, 0.8580, 0.8512, 0.8565, 0.8557, 0.8610, 0.8595, 0.8580, 0.8535, 0.8588, **Epoch: 180
0.8633, 0.8535, 0.8482, 0.8550, 0.8595, 0.8588, 0.8588, 0.8588, 0.8580, 0.8542, **Epoch: 190
0.8557, 0.8550, 0.8542, 0.8610, 0.8557, 0.8512, 0.8527, 0.8535, 0.8535, 0.8618, **Epoch: 200
Validation Accuracy: 
0.3454, 0.4481, 0.4703, 0.4320, 0.4542, 0.5579, 0.6395, 0.6808, 0.7009, 0.7049, **Epoch: 10
0.6979, 0.7190, 0.7170, 0.7372, 0.7362, 0.7503, 0.7543, 0.7553, 0.7533, 0.7533, **Epoch: 20
0.7513, 0.7462, 0.7462, 0.7513, 0.7523, 0.7482, 0.7523, 0.7533, 0.7533, 0.7392, **Epoch: 30
0.7533, 0.7523, 0.7472, 0.7563, 0.7563, 0.7472, 0.7482, 0.7553, 0.7603, 0.7533, **Epoch: 40
0.7543, 0.7543, 0.7573, 0.7593, 0.7593, 0.7503, 0.7593, 0.7613, 0.7613, 0.7593, **Epoch: 50
0.7553, 0.7573, 0.7583, 0.7593, 0.7503, 0.7573, 0.7593, 0.7613, 0.7593, 0.7623, **Epoch: 60
0.7573, 0.7533, 0.7503, 0.7633, 0.7674, 0.7593, 0.7654, 0.7613, 0.7613, 0.7694, **Epoch: 70
0.7533, 0.7654, 0.7623, 0.7704, 0.7774, 0.7674, 0.7674, 0.7704, 0.7633, 0.7583, **Epoch: 80
0.7603, 0.7613, 0.7613, 0.7623, 0.7674, 0.7724, 0.7654, 0.7633, 0.7613, 0.7704, **Epoch: 90
0.7654, 0.7674, 0.7674, 0.7583, 0.7633, 0.7674, 0.7654, 0.7674, 0.7694, 0.7623, **Epoch: 100
0.7734, 0.7563, 0.7603, 0.7674, 0.7654, 0.7664, 0.7633, 0.7644, 0.7654, 0.7654, **Epoch: 110
0.7674, 0.7644, 0.7573, 0.7724, 0.7734, 0.7573, 0.7583, 0.7654, 0.7664, 0.7684, **Epoch: 120
0.7664, 0.7644, 0.7613, 0.7613, 0.7583, 0.7644, 0.7633, 0.7583, 0.7654, 0.7633, **Epoch: 130
0.7603, 0.7644, 0.7744, 0.7623, 0.7573, 0.7664, 0.7623, 0.7613, 0.7583, 0.7633, **Epoch: 140
0.7684, 0.7613, 0.7583, 0.7563, 0.7623, 0.7694, 0.7613, 0.7623, 0.7593, 0.7503, **Epoch: 150
0.7633, 0.7714, 0.7573, 0.7623, 0.7603, 0.7613, 0.7613, 0.7573, 0.7664, 0.7654, **Epoch: 160
0.7674, 0.7674, 0.7633, 0.7583, 0.7633, 0.7623, 0.7654, 0.7603, 0.7694, 0.7714, **Epoch: 170
0.7623, 0.7644, 0.7654, 0.7654, 0.7563, 0.7623, 0.7623, 0.7613, 0.7613, 0.7533, **Epoch: 180
0.7633, 0.7724, 0.7613, 0.7684, 0.7694, 0.7623, 0.7623, 0.7633, 0.7613, 0.7432, **Epoch: 190
0.7613, 0.7704, 0.7644, 0.7664, 0.7613, 0.7633, 0.7613, 0.7573, 0.7664, 0.7644, **Epoch: 200
Validation Accuracy Final: 0.7644
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.1
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1118
Training Loss: 
1.9460, 1.9199, 1.8813, 1.8354, 1.7777, 1.7092, 1.6365, 1.5602, 1.4922, 1.4201, **Epoch: 10
1.3543, 1.2940, 1.2268, 1.1732, 1.1191, 1.0699, 1.0216, 0.9764, 0.9518, 0.9061, **Epoch: 20
0.8782, 0.8527, 0.8225, 0.8106, 0.7829, 0.7609, 0.7558, 0.7209, 0.7235, 0.6999, **Epoch: 30
0.6851, 0.6812, 0.6788, 0.6545, 0.6690, 0.6562, 0.6513, 0.6357, 0.6310, 0.6301, **Epoch: 40
0.6139, 0.6056, 0.6106, 0.6163, 0.6070, 0.6019, 0.6084, 0.5941, 0.5910, 0.5834, **Epoch: 50
0.5914, 0.5887, 0.5784, 0.5688, 0.5749, 0.5674, 0.5769, 0.5742, 0.5723, 0.5680, **Epoch: 60
0.5766, 0.5660, 0.5687, 0.5689, 0.5611, 0.5714, 0.5641, 0.5689, 0.5712, 0.5583, **Epoch: 70
0.5788, 0.5781, 0.5668, 0.5576, 0.5667, 0.5627, 0.5705, 0.5607, 0.5660, 0.5824, **Epoch: 80
0.5721, 0.5665, 0.5766, 0.5752, 0.5717, 0.5666, 0.5639, 0.5692, 0.5654, 0.5633, **Epoch: 90
0.5658, 0.5641, 0.5616, 0.5667, 0.5590, 0.5632, 0.5659, 0.5697, 0.5679, 0.5654, **Epoch: 100
0.5652, 0.5567, 0.5666, 0.5716, 0.5692, 0.5650, 0.5581, 0.5682, 0.5725, 0.5702, **Epoch: 110
0.5668, 0.5543, 0.5678, 0.5828, 0.5744, 0.5740, 0.5710, 0.5682, 0.5807, 0.5731, **Epoch: 120
0.5665, 0.5593, 0.5707, 0.5644, 0.5588, 0.5698, 0.5619, 0.5565, 0.5662, 0.5700, **Epoch: 130
0.5670, 0.5614, 0.5628, 0.5769, 0.5716, 0.5658, 0.5564, 0.5628, 0.5619, 0.5675, **Epoch: 140
0.5640, 0.5633, 0.5783, 0.5633, 0.5722, 0.5611, 0.5561, 0.5697, 0.5642, 0.5559, **Epoch: 150
0.5618, 0.5622, 0.5631, 0.5634, 0.5658, 0.5654, 0.5637, 0.5596, 0.5548, 0.5722, **Epoch: 160
0.5524, 0.5698, 0.5650, 0.5632, 0.5733, 0.5704, 0.5630, 0.5705, 0.5680, 0.5572, **Epoch: 170
0.5612, 0.5785, 0.5740, 0.5584, 0.5646, 0.5777, 0.5649, 0.5597, 0.5625, 0.5626, **Epoch: 180
0.5710, 0.5630, 0.5596, 0.5540, 0.5642, 0.5579, 0.5632, 0.5751, 0.5641, 0.5752, **Epoch: 190
0.5658, 0.5700, 0.5642, 0.5635, 0.5567, 0.5526, 0.5625, 0.5669, 0.5728, 0.5727, **Epoch: 200
Validation Loss: 
1.9226, 1.8880, 1.8469, 1.7965, 1.7365, 1.6754, 1.6014, 1.5494, 1.4846, 1.4305, **Epoch: 10
1.3659, 1.3057, 1.2564, 1.2020, 1.1641, 1.1124, 1.0845, 1.0413, 1.0124, 0.9934, **Epoch: 20
0.9707, 0.9562, 0.9372, 0.9037, 0.9005, 0.8864, 0.8869, 0.8704, 0.8651, 0.8526, **Epoch: 30
0.8692, 0.8501, 0.8444, 0.8346, 0.8320, 0.8337, 0.8331, 0.8226, 0.8277, 0.8158, **Epoch: 40
0.8102, 0.8244, 0.8273, 0.8094, 0.8052, 0.7984, 0.8043, 0.8091, 0.8093, 0.8007, **Epoch: 50
0.7982, 0.7892, 0.7942, 0.8111, 0.7978, 0.8001, 0.7981, 0.8025, 0.8023, 0.7958, **Epoch: 60
0.8028, 0.8034, 0.7947, 0.8062, 0.7959, 0.7971, 0.7875, 0.8019, 0.7865, 0.7903, **Epoch: 70
0.7982, 0.7946, 0.8044, 0.8059, 0.7911, 0.8049, 0.7977, 0.7968, 0.7981, 0.7904, **Epoch: 80
0.7944, 0.8029, 0.7982, 0.7870, 0.7881, 0.8091, 0.7932, 0.8018, 0.8065, 0.7909, **Epoch: 90
0.7973, 0.7957, 0.7834, 0.7984, 0.8095, 0.7981, 0.7816, 0.7932, 0.7931, 0.7869, **Epoch: 100
0.7887, 0.7937, 0.7976, 0.7990, 0.7920, 0.7954, 0.7986, 0.7973, 0.8049, 0.7920, **Epoch: 110
0.7967, 0.7940, 0.7962, 0.7796, 0.7934, 0.7960, 0.7973, 0.8097, 0.8067, 0.7952, **Epoch: 120
0.7793, 0.8002, 0.7896, 0.7921, 0.7936, 0.7814, 0.7905, 0.7980, 0.7876, 0.7736, **Epoch: 130
0.8060, 0.7846, 0.7858, 0.7811, 0.8122, 0.7997, 0.7956, 0.7972, 0.7935, 0.7906, **Epoch: 140
0.7897, 0.7951, 0.7947, 0.7784, 0.7950, 0.7979, 0.7883, 0.7910, 0.8026, 0.8012, **Epoch: 150
0.7938, 0.7945, 0.8039, 0.8010, 0.7899, 0.7890, 0.8006, 0.7902, 0.7970, 0.7951, **Epoch: 160
0.8060, 0.7850, 0.7951, 0.8052, 0.7902, 0.7991, 0.7894, 0.7941, 0.7965, 0.8058, **Epoch: 170
0.7927, 0.8023, 0.7990, 0.8088, 0.8021, 0.7846, 0.7991, 0.7816, 0.7912, 0.7886, **Epoch: 180
0.7829, 0.7920, 0.7848, 0.7865, 0.7994, 0.7941, 0.7924, 0.7998, 0.7916, 0.7948, **Epoch: 190
0.8114, 0.8078, 0.7965, 0.7882, 0.7805, 0.7923, 0.8017, 0.8025, 0.8020, 0.7927, **Epoch: 200
Training Accuracy: 
0.4343, 0.3958, 0.3421, 0.3512, 0.4418, 0.6148, 0.6835, 0.7281, 0.7379, 0.7470, **Epoch: 10
0.7666, 0.7651, 0.7742, 0.7855, 0.7870, 0.7968, 0.7870, 0.7900, 0.7931, 0.7983, **Epoch: 20
0.8021, 0.8089, 0.8006, 0.8051, 0.8082, 0.8082, 0.8263, 0.8218, 0.8195, 0.8233, **Epoch: 30
0.8240, 0.8270, 0.8263, 0.8285, 0.8346, 0.8384, 0.8376, 0.8353, 0.8437, 0.8338, **Epoch: 40
0.8384, 0.8414, 0.8452, 0.8444, 0.8384, 0.8505, 0.8467, 0.8406, 0.8512, 0.8429, **Epoch: 50
0.8505, 0.8474, 0.8505, 0.8505, 0.8489, 0.8610, 0.8565, 0.8557, 0.8535, 0.8467, **Epoch: 60
0.8429, 0.8482, 0.8527, 0.8557, 0.8603, 0.8520, 0.8565, 0.8573, 0.8603, 0.8573, **Epoch: 70
0.8489, 0.8497, 0.8573, 0.8520, 0.8542, 0.8520, 0.8527, 0.8542, 0.8588, 0.8527, **Epoch: 80
0.8573, 0.8527, 0.8557, 0.8550, 0.8542, 0.8474, 0.8557, 0.8520, 0.8573, 0.8512, **Epoch: 90
0.8588, 0.8512, 0.8595, 0.8603, 0.8625, 0.8505, 0.8557, 0.8565, 0.8618, 0.8565, **Epoch: 100
0.8542, 0.8565, 0.8573, 0.8497, 0.8618, 0.8565, 0.8580, 0.8535, 0.8474, 0.8580, **Epoch: 110
0.8580, 0.8527, 0.8588, 0.8505, 0.8580, 0.8497, 0.8580, 0.8520, 0.8497, 0.8603, **Epoch: 120
0.8520, 0.8497, 0.8527, 0.8595, 0.8573, 0.8580, 0.8603, 0.8520, 0.8557, 0.8595, **Epoch: 130
0.8580, 0.8610, 0.8580, 0.8573, 0.8610, 0.8580, 0.8610, 0.8573, 0.8535, 0.8535, **Epoch: 140
0.8580, 0.8573, 0.8527, 0.8497, 0.8535, 0.8573, 0.8618, 0.8557, 0.8580, 0.8603, **Epoch: 150
0.8565, 0.8535, 0.8580, 0.8588, 0.8527, 0.8580, 0.8557, 0.8505, 0.8595, 0.8588, **Epoch: 160
0.8565, 0.8580, 0.8573, 0.8527, 0.8542, 0.8527, 0.8580, 0.8573, 0.8603, 0.8497, **Epoch: 170
0.8610, 0.8588, 0.8542, 0.8497, 0.8527, 0.8512, 0.8565, 0.8557, 0.8588, 0.8497, **Epoch: 180
0.8595, 0.8595, 0.8595, 0.8557, 0.8565, 0.8535, 0.8527, 0.8459, 0.8557, 0.8512, **Epoch: 190
0.8542, 0.8603, 0.8520, 0.8573, 0.8565, 0.8489, 0.8588, 0.8557, 0.8550, 0.8610, **Epoch: 200
Validation Accuracy: 
0.3958, 0.3625, 0.3132, 0.3142, 0.4099, 0.5589, 0.6395, 0.6858, 0.6838, 0.6969, **Epoch: 10
0.7231, 0.7301, 0.7311, 0.7261, 0.7341, 0.7492, 0.7442, 0.7462, 0.7392, 0.7362, **Epoch: 20
0.7503, 0.7513, 0.7543, 0.7452, 0.7593, 0.7503, 0.7452, 0.7553, 0.7503, 0.7432, **Epoch: 30
0.7492, 0.7523, 0.7482, 0.7492, 0.7513, 0.7573, 0.7583, 0.7633, 0.7543, 0.7503, **Epoch: 40
0.7563, 0.7543, 0.7583, 0.7613, 0.7573, 0.7603, 0.7543, 0.7644, 0.7513, 0.7573, **Epoch: 50
0.7603, 0.7462, 0.7684, 0.7613, 0.7583, 0.7533, 0.7583, 0.7563, 0.7603, 0.7583, **Epoch: 60
0.7563, 0.7583, 0.7623, 0.7644, 0.7633, 0.7613, 0.7684, 0.7674, 0.7684, 0.7704, **Epoch: 70
0.7654, 0.7553, 0.7644, 0.7674, 0.7633, 0.7654, 0.7583, 0.7583, 0.7664, 0.7603, **Epoch: 80
0.7644, 0.7583, 0.7694, 0.7644, 0.7623, 0.7644, 0.7573, 0.7694, 0.7644, 0.7593, **Epoch: 90
0.7633, 0.7744, 0.7684, 0.7583, 0.7694, 0.7553, 0.7694, 0.7593, 0.7714, 0.7543, **Epoch: 100
0.7684, 0.7623, 0.7654, 0.7664, 0.7603, 0.7664, 0.7583, 0.7714, 0.7684, 0.7593, **Epoch: 110
0.7623, 0.7664, 0.7593, 0.7623, 0.7704, 0.7583, 0.7674, 0.7704, 0.7533, 0.7593, **Epoch: 120
0.7684, 0.7704, 0.7613, 0.7644, 0.7583, 0.7583, 0.7664, 0.7583, 0.7704, 0.7684, **Epoch: 130
0.7583, 0.7644, 0.7664, 0.7613, 0.7694, 0.7603, 0.7623, 0.7613, 0.7633, 0.7654, **Epoch: 140
0.7684, 0.7704, 0.7583, 0.7674, 0.7724, 0.7684, 0.7623, 0.7553, 0.7644, 0.7644, **Epoch: 150
0.7644, 0.7644, 0.7593, 0.7654, 0.7674, 0.7613, 0.7633, 0.7573, 0.7623, 0.7623, **Epoch: 160
0.7593, 0.7654, 0.7684, 0.7633, 0.7543, 0.7573, 0.7593, 0.7674, 0.7724, 0.7674, **Epoch: 170
0.7633, 0.7644, 0.7664, 0.7644, 0.7603, 0.7664, 0.7714, 0.7613, 0.7563, 0.7633, **Epoch: 180
0.7623, 0.7623, 0.7613, 0.7654, 0.7674, 0.7573, 0.7654, 0.7674, 0.7664, 0.7694, **Epoch: 190
0.7644, 0.7694, 0.7654, 0.7704, 0.7734, 0.7714, 0.7593, 0.7563, 0.7623, 0.7543, **Epoch: 200
Validation Accuracy Final: 0.7543
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.1
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1543
Training Loss: 
1.9457, 1.9081, 1.8556, 1.8002, 1.7292, 1.6563, 1.5773, 1.4931, 1.4212, 1.3522, **Epoch: 10
1.2768, 1.2147, 1.1598, 1.0970, 1.0355, 1.0012, 0.9587, 0.9227, 0.8982, 0.8662, **Epoch: 20
0.8344, 0.8201, 0.7940, 0.7890, 0.7591, 0.7405, 0.7237, 0.7088, 0.7021, 0.6877, **Epoch: 30
0.6871, 0.6737, 0.6553, 0.6552, 0.6515, 0.6410, 0.6328, 0.6205, 0.6302, 0.6202, **Epoch: 40
0.6033, 0.6036, 0.6116, 0.6154, 0.6011, 0.5943, 0.5935, 0.5934, 0.5886, 0.5782, **Epoch: 50
0.5814, 0.5769, 0.5790, 0.5871, 0.5725, 0.5765, 0.5715, 0.5855, 0.5700, 0.5655, **Epoch: 60
0.5725, 0.5753, 0.5651, 0.5693, 0.5594, 0.5684, 0.5558, 0.5677, 0.5654, 0.5568, **Epoch: 70
0.5542, 0.5709, 0.5651, 0.5660, 0.5660, 0.5533, 0.5656, 0.5606, 0.5580, 0.5538, **Epoch: 80
0.5707, 0.5575, 0.5636, 0.5734, 0.5686, 0.5624, 0.5707, 0.5660, 0.5667, 0.5552, **Epoch: 90
0.5651, 0.5608, 0.5705, 0.5796, 0.5688, 0.5712, 0.5706, 0.5640, 0.5710, 0.5683, **Epoch: 100
0.5717, 0.5611, 0.5678, 0.5727, 0.5602, 0.5711, 0.5640, 0.5600, 0.5693, 0.5632, **Epoch: 110
0.5582, 0.5639, 0.5634, 0.5611, 0.5580, 0.5555, 0.5586, 0.5671, 0.5601, 0.5716, **Epoch: 120
0.5717, 0.5663, 0.5619, 0.5611, 0.5619, 0.5698, 0.5661, 0.5618, 0.5649, 0.5714, **Epoch: 130
0.5736, 0.5660, 0.5665, 0.5555, 0.5597, 0.5670, 0.5642, 0.5633, 0.5677, 0.5589, **Epoch: 140
0.5661, 0.5620, 0.5638, 0.5728, 0.5646, 0.5664, 0.5671, 0.5623, 0.5667, 0.5760, **Epoch: 150
0.5624, 0.5660, 0.5689, 0.5672, 0.5730, 0.5703, 0.5694, 0.5768, 0.5705, 0.5587, **Epoch: 160
0.5738, 0.5663, 0.5633, 0.5566, 0.5663, 0.5612, 0.5656, 0.5649, 0.5720, 0.5516, **Epoch: 170
0.5740, 0.5662, 0.5637, 0.5630, 0.5716, 0.5669, 0.5530, 0.5595, 0.5538, 0.5721, **Epoch: 180
0.5688, 0.5609, 0.5539, 0.5635, 0.5683, 0.5635, 0.5679, 0.5708, 0.5664, 0.5698, **Epoch: 190
0.5591, 0.5629, 0.5745, 0.5703, 0.5641, 0.5837, 0.5607, 0.5679, 0.5597, 0.5590, **Epoch: 200
Validation Loss: 
1.9129, 1.8650, 1.8096, 1.7489, 1.6785, 1.6113, 1.5465, 1.4745, 1.4097, 1.3505, **Epoch: 10
1.2911, 1.2397, 1.1840, 1.1364, 1.1016, 1.0643, 1.0313, 1.0083, 0.9966, 0.9535, **Epoch: 20
0.9463, 0.9201, 0.9254, 0.8988, 0.8805, 0.8789, 0.8842, 0.8664, 0.8500, 0.8438, **Epoch: 30
0.8424, 0.8331, 0.8220, 0.8248, 0.8238, 0.8186, 0.8150, 0.8199, 0.8211, 0.8100, **Epoch: 40
0.7999, 0.8155, 0.7948, 0.8057, 0.7948, 0.8039, 0.8096, 0.8011, 0.8073, 0.8023, **Epoch: 50
0.7928, 0.7948, 0.7940, 0.7955, 0.8014, 0.8068, 0.8095, 0.8055, 0.7832, 0.7829, **Epoch: 60
0.7881, 0.7927, 0.7963, 0.7875, 0.7919, 0.7950, 0.7913, 0.7975, 0.7913, 0.7933, **Epoch: 70
0.7902, 0.7908, 0.7922, 0.8051, 0.8004, 0.8041, 0.7924, 0.7994, 0.7961, 0.7890, **Epoch: 80
0.7888, 0.7955, 0.7843, 0.8036, 0.8041, 0.7916, 0.7971, 0.7790, 0.7969, 0.7899, **Epoch: 90
0.8026, 0.7917, 0.7849, 0.7952, 0.7974, 0.7970, 0.7903, 0.8075, 0.7904, 0.7893, **Epoch: 100
0.7820, 0.8024, 0.7955, 0.8047, 0.7967, 0.7918, 0.8005, 0.7976, 0.7874, 0.7953, **Epoch: 110
0.8007, 0.7808, 0.7936, 0.7918, 0.7875, 0.7967, 0.7876, 0.7957, 0.7886, 0.7937, **Epoch: 120
0.7831, 0.8021, 0.7980, 0.7815, 0.7908, 0.8024, 0.8009, 0.7955, 0.7921, 0.8057, **Epoch: 130
0.7912, 0.7858, 0.7779, 0.7753, 0.7964, 0.7983, 0.8093, 0.8004, 0.7901, 0.7875, **Epoch: 140
0.7788, 0.7811, 0.8022, 0.8053, 0.8057, 0.8029, 0.7881, 0.7895, 0.7876, 0.7909, **Epoch: 150
0.8003, 0.7954, 0.7716, 0.7862, 0.7819, 0.7925, 0.8028, 0.7984, 0.7899, 0.8015, **Epoch: 160
0.7933, 0.7833, 0.7807, 0.7938, 0.7986, 0.7812, 0.7948, 0.7948, 0.8010, 0.7876, **Epoch: 170
0.8018, 0.7967, 0.7977, 0.7946, 0.8040, 0.7883, 0.7965, 0.7967, 0.7899, 0.7865, **Epoch: 180
0.7876, 0.7836, 0.7923, 0.7972, 0.8072, 0.8057, 0.7975, 0.8066, 0.8090, 0.7817, **Epoch: 190
0.7939, 0.8079, 0.7924, 0.7868, 0.7907, 0.7891, 0.8071, 0.8003, 0.7937, 0.7984, **Epoch: 200
Training Accuracy: 
0.6888, 0.5378, 0.4532, 0.5015, 0.5884, 0.6677, 0.7213, 0.7455, 0.7628, 0.7681, **Epoch: 10
0.7734, 0.7772, 0.7825, 0.7878, 0.7863, 0.7938, 0.7946, 0.8006, 0.8044, 0.8036, **Epoch: 20
0.8051, 0.8082, 0.8104, 0.8089, 0.8134, 0.8051, 0.8150, 0.8278, 0.8195, 0.8165, **Epoch: 30
0.8210, 0.8278, 0.8225, 0.8293, 0.8346, 0.8331, 0.8399, 0.8391, 0.8308, 0.8406, **Epoch: 40
0.8399, 0.8399, 0.8421, 0.8482, 0.8459, 0.8459, 0.8482, 0.8437, 0.8459, 0.8535, **Epoch: 50
0.8489, 0.8520, 0.8512, 0.8550, 0.8542, 0.8535, 0.8520, 0.8535, 0.8565, 0.8520, **Epoch: 60
0.8557, 0.8580, 0.8588, 0.8618, 0.8633, 0.8603, 0.8497, 0.8542, 0.8580, 0.8512, **Epoch: 70
0.8512, 0.8656, 0.8557, 0.8640, 0.8610, 0.8580, 0.8618, 0.8610, 0.8550, 0.8656, **Epoch: 80
0.8573, 0.8588, 0.8550, 0.8595, 0.8520, 0.8565, 0.8580, 0.8580, 0.8610, 0.8535, **Epoch: 90
0.8625, 0.8633, 0.8550, 0.8595, 0.8610, 0.8467, 0.8505, 0.8497, 0.8520, 0.8557, **Epoch: 100
0.8595, 0.8595, 0.8633, 0.8610, 0.8527, 0.8520, 0.8588, 0.8505, 0.8610, 0.8625, **Epoch: 110
0.8550, 0.8482, 0.8527, 0.8595, 0.8542, 0.8542, 0.8489, 0.8565, 0.8527, 0.8512, **Epoch: 120
0.8542, 0.8603, 0.8595, 0.8625, 0.8535, 0.8520, 0.8542, 0.8505, 0.8527, 0.8580, **Epoch: 130
0.8573, 0.8573, 0.8565, 0.8512, 0.8482, 0.8580, 0.8595, 0.8512, 0.8573, 0.8573, **Epoch: 140
0.8557, 0.8497, 0.8595, 0.8550, 0.8565, 0.8550, 0.8588, 0.8625, 0.8557, 0.8535, **Epoch: 150
0.8625, 0.8573, 0.8557, 0.8573, 0.8580, 0.8565, 0.8557, 0.8580, 0.8656, 0.8565, **Epoch: 160
0.8520, 0.8573, 0.8580, 0.8474, 0.8588, 0.8565, 0.8588, 0.8580, 0.8595, 0.8573, **Epoch: 170
0.8520, 0.8542, 0.8557, 0.8535, 0.8497, 0.8520, 0.8618, 0.8603, 0.8467, 0.8603, **Epoch: 180
0.8603, 0.8550, 0.8573, 0.8550, 0.8489, 0.8557, 0.8520, 0.8535, 0.8535, 0.8565, **Epoch: 190
0.8603, 0.8535, 0.8550, 0.8489, 0.8588, 0.8550, 0.8573, 0.8678, 0.8542, 0.8557, **Epoch: 200
Validation Accuracy: 
0.6435, 0.5156, 0.4451, 0.4904, 0.5579, 0.6344, 0.6818, 0.6949, 0.7241, 0.7241, **Epoch: 10
0.7301, 0.7402, 0.7331, 0.7331, 0.7412, 0.7442, 0.7492, 0.7513, 0.7462, 0.7523, **Epoch: 20
0.7472, 0.7432, 0.7472, 0.7593, 0.7573, 0.7503, 0.7593, 0.7563, 0.7503, 0.7573, **Epoch: 30
0.7472, 0.7472, 0.7472, 0.7482, 0.7492, 0.7573, 0.7553, 0.7563, 0.7583, 0.7563, **Epoch: 40
0.7553, 0.7583, 0.7654, 0.7623, 0.7523, 0.7563, 0.7674, 0.7623, 0.7583, 0.7633, **Epoch: 50
0.7553, 0.7694, 0.7603, 0.7603, 0.7644, 0.7684, 0.7613, 0.7684, 0.7593, 0.7684, **Epoch: 60
0.7603, 0.7583, 0.7664, 0.7664, 0.7654, 0.7684, 0.7633, 0.7664, 0.7664, 0.7644, **Epoch: 70
0.7644, 0.7583, 0.7623, 0.7593, 0.7573, 0.7664, 0.7664, 0.7644, 0.7593, 0.7593, **Epoch: 80
0.7674, 0.7603, 0.7583, 0.7583, 0.7724, 0.7633, 0.7714, 0.7623, 0.7633, 0.7583, **Epoch: 90
0.7644, 0.7583, 0.7563, 0.7633, 0.7664, 0.7714, 0.7523, 0.7623, 0.7623, 0.7543, **Epoch: 100
0.7573, 0.7613, 0.7633, 0.7623, 0.7623, 0.7704, 0.7593, 0.7613, 0.7704, 0.7704, **Epoch: 110
0.7553, 0.7633, 0.7573, 0.7573, 0.7623, 0.7583, 0.7553, 0.7603, 0.7704, 0.7623, **Epoch: 120
0.7674, 0.7543, 0.7613, 0.7644, 0.7633, 0.7613, 0.7603, 0.7603, 0.7644, 0.7593, **Epoch: 130
0.7714, 0.7593, 0.7704, 0.7704, 0.7674, 0.7774, 0.7654, 0.7613, 0.7573, 0.7593, **Epoch: 140
0.7623, 0.7613, 0.7593, 0.7613, 0.7563, 0.7633, 0.7613, 0.7563, 0.7654, 0.7644, **Epoch: 150
0.7523, 0.7613, 0.7704, 0.7633, 0.7674, 0.7684, 0.7623, 0.7593, 0.7593, 0.7694, **Epoch: 160
0.7664, 0.7684, 0.7664, 0.7593, 0.7674, 0.7623, 0.7603, 0.7694, 0.7633, 0.7563, **Epoch: 170
0.7644, 0.7633, 0.7714, 0.7644, 0.7644, 0.7694, 0.7744, 0.7533, 0.7623, 0.7482, **Epoch: 180
0.7664, 0.7573, 0.7684, 0.7623, 0.7674, 0.7694, 0.7623, 0.7613, 0.7654, 0.7603, **Epoch: 190
0.7593, 0.7583, 0.7603, 0.7603, 0.7613, 0.7674, 0.7623, 0.7754, 0.7633, 0.7613, **Epoch: 200
Validation Accuracy Final: 0.7613
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.1
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1544
Training Loss: 
1.9458, 1.9281, 1.9070, 1.8794, 1.8482, 1.8074, 1.7671, 1.7251, 1.6859, 1.6482, **Epoch: 10
1.6103, 1.5476, 1.5143, 1.4722, 1.4285, 1.3774, 1.3314, 1.2973, 1.2507, 1.2089, **Epoch: 20
1.1922, 1.1295, 1.1117, 1.0731, 1.0558, 1.0264, 1.0118, 0.9970, 0.9675, 0.9722, **Epoch: 30
0.9508, 0.9418, 0.9269, 0.9174, 0.9211, 0.9038, 0.8921, 0.8878, 0.8787, 0.8699, **Epoch: 40
0.8769, 0.8533, 0.8593, 0.8466, 0.8440, 0.8454, 0.8482, 0.8397, 0.8567, 0.8490, **Epoch: 50
0.8240, 0.8651, 0.8402, 0.8296, 0.8342, 0.8274, 0.8199, 0.8223, 0.8224, 0.8326, **Epoch: 60
0.8220, 0.8160, 0.8312, 0.8424, 0.8315, 0.8183, 0.8161, 0.8273, 0.8173, 0.8305, **Epoch: 70
0.8175, 0.8343, 0.8214, 0.8390, 0.8279, 0.8477, 0.8556, 0.8261, 0.8333, 0.8456, **Epoch: 80
0.8235, 0.8446, 0.8108, 0.8400, 0.8137, 0.8320, 0.8192, 0.8364, 0.8530, 0.8440, **Epoch: 90
0.8367, 0.8408, 0.8263, 0.8346, 0.8474, 0.8501, 0.8376, 0.8370, 0.8510, 0.8307, **Epoch: 100
0.8465, 0.8274, 0.8281, 0.8239, 0.8203, 0.8251, 0.8278, 0.8324, 0.8266, 0.8342, **Epoch: 110
0.8446, 0.8431, 0.8179, 0.8509, 0.8326, 0.8374, 0.8236, 0.8269, 0.8474, 0.8286, **Epoch: 120
0.8229, 0.8233, 0.8135, 0.8493, 0.8279, 0.8257, 0.8309, 0.8433, 0.8343, 0.8298, **Epoch: 130
0.8374, 0.8268, 0.8341, 0.8232, 0.8110, 0.8248, 0.8343, 0.8237, 0.8513, 0.8434, **Epoch: 140
0.8341, 0.8185, 0.8312, 0.8412, 0.8495, 0.8138, 0.8174, 0.8579, 0.8318, 0.8425, **Epoch: 150
0.8311, 0.8426, 0.8356, 0.8110, 0.8532, 0.8142, 0.8354, 0.8141, 0.8283, 0.8236, **Epoch: 160
0.8288, 0.8431, 0.8297, 0.8362, 0.8298, 0.8096, 0.8300, 0.8403, 0.8378, 0.8384, **Epoch: 170
0.8332, 0.8668, 0.8426, 0.8580, 0.8223, 0.8461, 0.8353, 0.8323, 0.8315, 0.8382, **Epoch: 180
0.8210, 0.8201, 0.8272, 0.8300, 0.8328, 0.8417, 0.8236, 0.8326, 0.8342, 0.8348, **Epoch: 190
0.8323, 0.8153, 0.8246, 0.8298, 0.8357, 0.8282, 0.8178, 0.8436, 0.8373, 0.8351, **Epoch: 200
Validation Loss: 
1.9296, 1.9089, 1.8851, 1.8550, 1.8133, 1.7729, 1.7449, 1.7114, 1.6703, 1.6416, **Epoch: 10
1.6044, 1.5642, 1.5112, 1.4909, 1.4387, 1.4051, 1.3413, 1.3214, 1.2827, 1.2732, **Epoch: 20
1.2068, 1.1928, 1.1656, 1.1204, 1.1535, 1.1078, 1.0873, 1.0728, 1.0653, 1.0549, **Epoch: 30
1.0288, 1.0288, 1.0177, 1.0031, 1.0205, 0.9789, 0.9983, 0.9902, 0.9783, 0.9914, **Epoch: 40
0.9876, 0.9692, 0.9720, 0.9734, 0.9775, 0.9688, 0.9787, 0.9721, 0.9689, 0.9876, **Epoch: 50
0.9757, 0.9915, 0.9633, 0.9715, 0.9684, 0.9719, 0.9797, 0.9660, 0.9806, 0.9686, **Epoch: 60
0.9798, 0.9630, 0.9422, 0.9618, 0.9480, 0.9785, 0.9618, 0.9700, 0.9519, 0.9943, **Epoch: 70
0.9676, 0.9702, 0.9471, 0.9619, 0.9430, 0.9654, 0.9815, 0.9632, 0.9592, 0.9688, **Epoch: 80
0.9755, 0.9628, 0.9567, 0.9534, 0.9787, 0.9581, 0.9653, 0.9676, 0.9622, 0.9603, **Epoch: 90
0.9586, 0.9484, 0.9738, 0.9603, 0.9764, 0.9746, 0.9758, 0.9851, 0.9733, 0.9591, **Epoch: 100
0.9706, 0.9772, 0.9588, 0.9742, 0.9409, 0.9661, 0.9608, 0.9746, 0.9770, 0.9766, **Epoch: 110
0.9844, 0.9745, 0.9957, 0.9460, 0.9569, 0.9533, 0.9477, 0.9728, 0.9854, 0.9744, **Epoch: 120
0.9617, 0.9698, 0.9550, 0.9529, 0.9566, 0.9576, 0.9591, 0.9685, 0.9619, 0.9667, **Epoch: 130
0.9446, 0.9724, 0.9799, 0.9783, 0.9430, 0.9517, 0.9780, 0.9725, 0.9536, 0.9641, **Epoch: 140
0.9707, 0.9700, 0.9506, 0.9769, 0.9833, 0.9665, 0.9601, 0.9725, 0.9771, 0.9790, **Epoch: 150
0.9664, 0.9629, 0.9646, 0.9603, 0.9552, 0.9623, 0.9897, 0.9572, 0.9663, 0.9657, **Epoch: 160
0.9454, 0.9564, 0.9648, 0.9646, 0.9662, 0.9571, 0.9668, 0.9735, 0.9895, 0.9756, **Epoch: 170
0.9659, 0.9597, 0.9633, 0.9653, 0.9638, 0.9764, 0.9819, 0.9705, 0.9637, 0.9557, **Epoch: 180
0.9813, 0.9597, 0.9629, 0.9432, 0.9733, 0.9483, 0.9607, 0.9695, 0.9502, 0.9700, **Epoch: 190
0.9742, 0.9640, 0.9663, 0.9536, 0.9728, 0.9604, 0.9506, 0.9779, 0.9492, 0.9467, **Epoch: 200
Training Accuracy: 
0.2198, 0.2122, 0.2115, 0.2160, 0.2198, 0.2273, 0.2402, 0.2983, 0.4056, 0.4637, **Epoch: 10
0.5068, 0.5695, 0.6571, 0.6745, 0.7077, 0.7190, 0.7258, 0.7205, 0.7447, 0.7455, **Epoch: 20
0.7273, 0.7387, 0.7477, 0.7447, 0.7500, 0.7477, 0.7568, 0.7523, 0.7447, 0.7659, **Epoch: 30
0.7628, 0.7606, 0.7636, 0.7742, 0.7689, 0.7674, 0.7583, 0.7727, 0.7727, 0.7613, **Epoch: 40
0.7636, 0.7644, 0.7787, 0.7764, 0.7757, 0.7764, 0.7742, 0.7931, 0.7749, 0.7727, **Epoch: 50
0.7749, 0.7742, 0.7802, 0.7817, 0.7787, 0.7727, 0.7613, 0.7749, 0.7742, 0.7787, **Epoch: 60
0.7727, 0.7628, 0.7704, 0.7696, 0.7689, 0.7666, 0.7772, 0.7878, 0.7764, 0.7779, **Epoch: 70
0.7742, 0.7870, 0.7795, 0.7704, 0.7772, 0.7772, 0.7674, 0.7817, 0.7719, 0.7696, **Epoch: 80
0.7727, 0.7742, 0.7757, 0.7689, 0.7825, 0.7749, 0.7749, 0.7810, 0.7915, 0.7840, **Epoch: 90
0.7855, 0.7863, 0.7749, 0.7719, 0.7628, 0.7863, 0.7802, 0.7900, 0.7779, 0.7817, **Epoch: 100
0.7923, 0.7704, 0.7689, 0.7832, 0.7779, 0.7772, 0.7825, 0.7749, 0.7817, 0.7719, **Epoch: 110
0.7696, 0.7802, 0.7810, 0.7742, 0.7885, 0.7757, 0.7787, 0.7855, 0.7749, 0.7878, **Epoch: 120
0.7787, 0.7900, 0.7893, 0.7810, 0.7772, 0.7779, 0.7900, 0.7795, 0.7817, 0.7893, **Epoch: 130
0.7802, 0.7802, 0.7764, 0.7749, 0.7810, 0.7704, 0.7976, 0.7961, 0.7689, 0.7825, **Epoch: 140
0.7757, 0.7847, 0.7870, 0.7689, 0.7779, 0.7734, 0.7727, 0.7795, 0.7840, 0.7870, **Epoch: 150
0.7847, 0.7727, 0.7870, 0.7757, 0.7810, 0.7689, 0.7696, 0.7742, 0.7772, 0.7795, **Epoch: 160
0.7764, 0.7863, 0.7742, 0.7742, 0.7651, 0.7779, 0.7689, 0.7749, 0.7727, 0.7968, **Epoch: 170
0.7764, 0.7727, 0.7764, 0.7772, 0.7734, 0.7636, 0.7840, 0.7742, 0.7757, 0.7802, **Epoch: 180
0.7810, 0.7727, 0.7696, 0.7764, 0.7764, 0.7681, 0.7802, 0.7795, 0.7772, 0.7711, **Epoch: 190
0.7779, 0.7719, 0.7893, 0.7817, 0.7968, 0.7787, 0.7689, 0.7696, 0.7742, 0.7696, **Epoch: 200
Validation Accuracy: 
0.2195, 0.2205, 0.2145, 0.2185, 0.2226, 0.2216, 0.2306, 0.2820, 0.3726, 0.4300, **Epoch: 10
0.4814, 0.5478, 0.6062, 0.6475, 0.6697, 0.6818, 0.6788, 0.6757, 0.6989, 0.6999, **Epoch: 20
0.7110, 0.7180, 0.7120, 0.7200, 0.7180, 0.7261, 0.7200, 0.7160, 0.7170, 0.7170, **Epoch: 30
0.7190, 0.7160, 0.7039, 0.7200, 0.7090, 0.7160, 0.7090, 0.7170, 0.7150, 0.7291, **Epoch: 40
0.7200, 0.7281, 0.7130, 0.7170, 0.7160, 0.7170, 0.7080, 0.7382, 0.7190, 0.6959, **Epoch: 50
0.7190, 0.7069, 0.7160, 0.7261, 0.7190, 0.7140, 0.7059, 0.7120, 0.7170, 0.7130, **Epoch: 60
0.7170, 0.7291, 0.7190, 0.7241, 0.7190, 0.6999, 0.7221, 0.7251, 0.7251, 0.7090, **Epoch: 70
0.7200, 0.7281, 0.7251, 0.7331, 0.7090, 0.7039, 0.7170, 0.7110, 0.7180, 0.7261, **Epoch: 80
0.7160, 0.7160, 0.7180, 0.7261, 0.7120, 0.7150, 0.7311, 0.7160, 0.7120, 0.7271, **Epoch: 90
0.7251, 0.7210, 0.7190, 0.7019, 0.7150, 0.7170, 0.7351, 0.7200, 0.7321, 0.7100, **Epoch: 100
0.7090, 0.7210, 0.7321, 0.7180, 0.7120, 0.7140, 0.7069, 0.7231, 0.7110, 0.7140, **Epoch: 110
0.7069, 0.7221, 0.7301, 0.7241, 0.7009, 0.7150, 0.7160, 0.7221, 0.7160, 0.7090, **Epoch: 120
0.7251, 0.7140, 0.7210, 0.7241, 0.7261, 0.7150, 0.7261, 0.7221, 0.7291, 0.7190, **Epoch: 130
0.7200, 0.7210, 0.7170, 0.7221, 0.7140, 0.7170, 0.7412, 0.7331, 0.7311, 0.7170, **Epoch: 140
0.7120, 0.6999, 0.7241, 0.7190, 0.7261, 0.7069, 0.7200, 0.7241, 0.7271, 0.7120, **Epoch: 150
0.7362, 0.7090, 0.7080, 0.7150, 0.7180, 0.7321, 0.7200, 0.7100, 0.7261, 0.7271, **Epoch: 160
0.7331, 0.7130, 0.7291, 0.7180, 0.7140, 0.7281, 0.7080, 0.7200, 0.7160, 0.7170, **Epoch: 170
0.7130, 0.7261, 0.7150, 0.7221, 0.7140, 0.7231, 0.7261, 0.7251, 0.7301, 0.7170, **Epoch: 180
0.7231, 0.7281, 0.7281, 0.7120, 0.7090, 0.7180, 0.7271, 0.7180, 0.7402, 0.7341, **Epoch: 190
0.7231, 0.7190, 0.7160, 0.7140, 0.7382, 0.7251, 0.7291, 0.7291, 0.7221, 0.7291, **Epoch: 200
Validation Accuracy Final: 0.7291
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.3
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1544
Training Loss: 
1.9415, 1.5785, 1.4557, 1.3446, 1.2425, 1.1525, 1.0692, 0.9978, 0.9169, 0.8703, **Epoch: 10
0.8157, 0.7588, 0.7364, 0.6967, 0.6681, 0.6196, 0.6041, 0.5642, 0.5380, 0.5360, **Epoch: 20
0.5174, 0.4961, 0.5012, 0.4588, 0.4516, 0.4203, 0.4184, 0.4198, 0.4207, 0.3916, **Epoch: 30
0.4094, 0.4009, 0.3821, 0.3832, 0.3933, 0.3589, 0.3710, 0.3533, 0.3571, 0.3630, **Epoch: 40
0.3640, 0.3557, 0.3681, 0.3602, 0.3507, 0.3679, 0.3590, 0.3633, 0.3376, 0.3525, **Epoch: 50
0.3620, 0.3375, 0.3445, 0.3566, 0.3598, 0.3749, 0.3547, 0.3516, 0.3497, 0.3536, **Epoch: 60
0.3550, 0.3466, 0.3735, 0.3436, 0.3369, 0.3445, 0.3606, 0.3773, 0.3486, 0.3611, **Epoch: 70
0.3690, 0.3463, 0.3467, 0.3553, 0.3518, 0.3556, 0.3801, 0.3545, 0.3668, 0.3685, **Epoch: 80
0.3574, 0.3517, 0.3572, 0.3595, 0.3545, 0.3570, 0.3398, 0.3694, 0.3380, 0.3535, **Epoch: 90
0.3303, 0.3529, 0.3531, 0.3519, 0.3410, 0.3321, 0.3560, 0.3641, 0.3610, 0.3415, **Epoch: 100
0.3712, 0.3595, 0.3485, 0.3549, 0.3410, 0.3644, 0.3523, 0.3468, 0.3387, 0.3600, **Epoch: 110
0.3442, 0.3462, 0.3527, 0.3551, 0.3473, 0.3731, 0.3615, 0.3572, 0.3643, 0.3456, **Epoch: 120
0.3346, 0.3794, 0.3474, 0.3667, 0.3687, 0.3698, 0.3361, 0.3532, 0.3515, 0.3573, **Epoch: 130
0.3559, 0.3654, 0.3377, 0.3498, 0.3370, 0.3477, 0.3485, 0.3360, 0.3672, 0.3409, **Epoch: 140
0.3315, 0.3601, 0.3414, 0.3539, 0.3582, 0.3397, 0.3515, 0.3586, 0.3666, 0.3558, **Epoch: 150
0.3655, 0.3656, 0.3652, 0.3627, 0.3618, 0.3588, 0.3630, 0.3461, 0.3523, 0.3503, **Epoch: 160
0.3617, 0.3505, 0.3455, 0.3495, 0.3564, 0.3662, 0.3608, 0.3776, 0.3621, 0.3373, **Epoch: 170
0.3443, 0.3453, 0.3494, 0.3658, 0.3560, 0.3495, 0.3592, 0.3765, 0.3886, 0.3638, **Epoch: 180
0.3500, 0.3889, 0.3723, 0.3592, 0.3413, 0.3475, 0.3465, 0.3587, 0.3539, 0.3690, **Epoch: 190
0.3435, 0.3377, 0.3654, 0.3676, 0.3545, 0.3514, 0.3717, 0.3256, 0.3540, 0.3630, **Epoch: 200
Validation Loss: 
1.6315, 1.5372, 1.4198, 1.3585, 1.2707, 1.1949, 1.1313, 1.0807, 1.0428, 1.0127, **Epoch: 10
0.9897, 0.9718, 0.9898, 0.9331, 0.9331, 0.9533, 0.9730, 0.9357, 1.0162, 0.9580, **Epoch: 20
0.9723, 0.9321, 1.0054, 1.0197, 1.0200, 1.0429, 1.0946, 1.0406, 1.0603, 1.0495, **Epoch: 30
1.1167, 1.0975, 1.1170, 1.1534, 1.1407, 1.1471, 1.1390, 1.1992, 1.1173, 1.1845, **Epoch: 40
1.2036, 1.1755, 1.1763, 1.2103, 1.1773, 1.1638, 1.1534, 1.1976, 1.1950, 1.2121, **Epoch: 50
1.1833, 1.1549, 1.1230, 1.1888, 1.1490, 1.1557, 1.1624, 1.2022, 1.2074, 1.1661, **Epoch: 60
1.2114, 1.2143, 1.1532, 1.1696, 1.2397, 1.1719, 1.1580, 1.1426, 1.2151, 1.2006, **Epoch: 70
1.1657, 1.1922, 1.1734, 1.1775, 1.1395, 1.1454, 1.1809, 1.1864, 1.1645, 1.1884, **Epoch: 80
1.1890, 1.2148, 1.1745, 1.1860, 1.1232, 1.1822, 1.1772, 1.1764, 1.1914, 1.2015, **Epoch: 90
1.2099, 1.1712, 1.2127, 1.2056, 1.2634, 1.2260, 1.2133, 1.1969, 1.1854, 1.2033, **Epoch: 100
1.2265, 1.1974, 1.1977, 1.2245, 1.1809, 1.1944, 1.2430, 1.2335, 1.2346, 1.1898, **Epoch: 110
1.1660, 1.2298, 1.1916, 1.2356, 1.2412, 1.2382, 1.2135, 1.1592, 1.2187, 1.2680, **Epoch: 120
1.1989, 1.2388, 1.2666, 1.2169, 1.2499, 1.2818, 1.2444, 1.2166, 1.1878, 1.1796, **Epoch: 130
1.2235, 1.2014, 1.2035, 1.2061, 1.2060, 1.1806, 1.2038, 1.1799, 1.2346, 1.1673, **Epoch: 140
1.1447, 1.1689, 1.2530, 1.1886, 1.2550, 1.2212, 1.2164, 1.2152, 1.2067, 1.2276, **Epoch: 150
1.2284, 1.1964, 1.2217, 1.2659, 1.2333, 1.1984, 1.1823, 1.2169, 1.1888, 1.1979, **Epoch: 160
1.2260, 1.2112, 1.1978, 1.1805, 1.1671, 1.2377, 1.1928, 1.2478, 1.2566, 1.2012, **Epoch: 170
1.2096, 1.2195, 1.2631, 1.2752, 1.2582, 1.3301, 1.2137, 1.2606, 1.2658, 1.1453, **Epoch: 180
1.2154, 1.2624, 1.1694, 1.1631, 1.2435, 1.2728, 1.1950, 1.2297, 1.2380, 1.2539, **Epoch: 190
1.2508, 1.2450, 1.2097, 1.2284, 1.2063, 1.2112, 1.2078, 1.2518, 1.2297, 1.1644, **Epoch: 200
Training Accuracy: 
0.7092, 0.7402, 0.7764, 0.7538, 0.7795, 0.7772, 0.7810, 0.8051, 0.7840, 0.8150, **Epoch: 10
0.8059, 0.8059, 0.8066, 0.8112, 0.8361, 0.8218, 0.8369, 0.8520, 0.8505, 0.8429, **Epoch: 20
0.8421, 0.8535, 0.8573, 0.8648, 0.8731, 0.8724, 0.8671, 0.8648, 0.8829, 0.8822, **Epoch: 30
0.8671, 0.8708, 0.8776, 0.8708, 0.8716, 0.8792, 0.8784, 0.8927, 0.8656, 0.8754, **Epoch: 40
0.8807, 0.8784, 0.8837, 0.8882, 0.8852, 0.8724, 0.8731, 0.8927, 0.8792, 0.8701, **Epoch: 50
0.8844, 0.8943, 0.8776, 0.8927, 0.8739, 0.8897, 0.8799, 0.8799, 0.8897, 0.8844, **Epoch: 60
0.8965, 0.8844, 0.8852, 0.8958, 0.8943, 0.8882, 0.8844, 0.8875, 0.8844, 0.8897, **Epoch: 70
0.8829, 0.8769, 0.8844, 0.8807, 0.8829, 0.8792, 0.8807, 0.8890, 0.8731, 0.8935, **Epoch: 80
0.8882, 0.8784, 0.8867, 0.8799, 0.8716, 0.8724, 0.8852, 0.8852, 0.8912, 0.8852, **Epoch: 90
0.8897, 0.8739, 0.8980, 0.8799, 0.8837, 0.8920, 0.8973, 0.8897, 0.8807, 0.8701, **Epoch: 100
0.8837, 0.8875, 0.8890, 0.8739, 0.8897, 0.8890, 0.8837, 0.8776, 0.9079, 0.8882, **Epoch: 110
0.8980, 0.8829, 0.8731, 0.8927, 0.9003, 0.8935, 0.8867, 0.8754, 0.8769, 0.8943, **Epoch: 120
0.8860, 0.8935, 0.8973, 0.8912, 0.8860, 0.8852, 0.8837, 0.8746, 0.8844, 0.8867, **Epoch: 130
0.8950, 0.8693, 0.8844, 0.8920, 0.8844, 0.8875, 0.8844, 0.8807, 0.8882, 0.8844, **Epoch: 140
0.8754, 0.8882, 0.8724, 0.8708, 0.8784, 0.8837, 0.8792, 0.8746, 0.8814, 0.8965, **Epoch: 150
0.8920, 0.8867, 0.8860, 0.8792, 0.8943, 0.8671, 0.8844, 0.8844, 0.8882, 0.8837, **Epoch: 160
0.8844, 0.8769, 0.8784, 0.8912, 0.8724, 0.8807, 0.8897, 0.8693, 0.8837, 0.8875, **Epoch: 170
0.8852, 0.8829, 0.8807, 0.8837, 0.8905, 0.8844, 0.8784, 0.8852, 0.8799, 0.8844, **Epoch: 180
0.8656, 0.8769, 0.8988, 0.8761, 0.8912, 0.8829, 0.8754, 0.8776, 0.8905, 0.8935, **Epoch: 190
0.8799, 0.8958, 0.8927, 0.8927, 0.8822, 0.8822, 0.8882, 0.8920, 0.8943, 0.8844, **Epoch: 200
Validation Accuracy: 
0.6586, 0.6808, 0.6949, 0.6979, 0.7009, 0.7160, 0.7110, 0.7281, 0.7221, 0.7200, **Epoch: 10
0.7341, 0.7210, 0.7362, 0.7301, 0.7170, 0.7019, 0.6858, 0.7200, 0.7190, 0.7090, **Epoch: 20
0.7090, 0.7019, 0.7049, 0.6969, 0.6858, 0.7069, 0.6959, 0.6939, 0.6898, 0.6878, **Epoch: 30
0.6888, 0.7029, 0.7009, 0.6788, 0.6757, 0.6818, 0.6788, 0.6727, 0.6777, 0.6798, **Epoch: 40
0.6848, 0.6818, 0.6687, 0.6788, 0.6898, 0.6747, 0.6818, 0.6848, 0.6657, 0.6707, **Epoch: 50
0.6918, 0.6697, 0.6888, 0.6727, 0.6566, 0.6647, 0.6838, 0.6898, 0.6647, 0.6848, **Epoch: 60
0.6818, 0.6888, 0.6767, 0.6838, 0.6798, 0.6888, 0.6898, 0.6989, 0.6838, 0.6918, **Epoch: 70
0.6918, 0.6697, 0.6868, 0.6838, 0.6727, 0.6888, 0.6858, 0.6848, 0.6788, 0.6667, **Epoch: 80
0.6657, 0.6798, 0.6707, 0.6788, 0.6757, 0.6898, 0.6767, 0.6485, 0.6586, 0.6647, **Epoch: 90
0.6717, 0.6526, 0.6647, 0.6878, 0.6687, 0.6636, 0.6737, 0.6868, 0.6636, 0.6657, **Epoch: 100
0.6526, 0.6586, 0.6727, 0.6878, 0.6777, 0.6767, 0.6767, 0.6808, 0.6647, 0.6828, **Epoch: 110
0.6908, 0.6858, 0.6888, 0.6737, 0.6757, 0.6818, 0.6838, 0.6918, 0.6798, 0.6657, **Epoch: 120
0.6737, 0.6717, 0.6777, 0.6697, 0.6818, 0.6747, 0.6868, 0.6808, 0.6888, 0.6898, **Epoch: 130
0.6918, 0.6959, 0.6858, 0.6798, 0.6636, 0.6687, 0.6788, 0.6838, 0.6788, 0.6848, **Epoch: 140
0.6808, 0.6777, 0.6707, 0.6798, 0.6717, 0.6727, 0.6848, 0.6626, 0.6636, 0.6737, **Epoch: 150
0.6747, 0.6777, 0.6586, 0.6788, 0.6717, 0.6737, 0.6636, 0.6647, 0.6667, 0.6606, **Epoch: 160
0.6647, 0.6667, 0.6777, 0.6667, 0.6818, 0.6717, 0.6717, 0.6687, 0.6677, 0.6707, **Epoch: 170
0.6767, 0.6707, 0.6566, 0.6707, 0.6707, 0.6667, 0.6788, 0.6647, 0.6767, 0.6818, **Epoch: 180
0.6898, 0.6848, 0.6777, 0.6828, 0.6939, 0.6878, 0.6928, 0.6737, 0.6717, 0.6727, **Epoch: 190
0.6798, 0.6747, 0.6848, 0.6939, 0.6687, 0.6798, 0.6928, 0.7029, 0.6828, 0.6788, **Epoch: 200
Validation Accuracy Final: 0.6788
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.3
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1545
Training Loss: 
1.9850, 1.4930, 1.3607, 1.2246, 1.1066, 1.0038, 0.9105, 0.8234, 0.7697, 0.7080, **Epoch: 10
0.6478, 0.6121, 0.5672, 0.5379, 0.5160, 0.4884, 0.4455, 0.4253, 0.4005, 0.3702, **Epoch: 20
0.3537, 0.3443, 0.3314, 0.3179, 0.2962, 0.2800, 0.2707, 0.2618, 0.2417, 0.2364, **Epoch: 30
0.2399, 0.2121, 0.2179, 0.2076, 0.2048, 0.1987, 0.1939, 0.1908, 0.1814, 0.1804, **Epoch: 40
0.1800, 0.1750, 0.1832, 0.1694, 0.1687, 0.1898, 0.1688, 0.1835, 0.1786, 0.1673, **Epoch: 50
0.1605, 0.1700, 0.1791, 0.1733, 0.1774, 0.1755, 0.1742, 0.1704, 0.1853, 0.1742, **Epoch: 60
0.1835, 0.1853, 0.1742, 0.1608, 0.1863, 0.1721, 0.1814, 0.1734, 0.1786, 0.1640, **Epoch: 70
0.1614, 0.1721, 0.1596, 0.1686, 0.1758, 0.1635, 0.1799, 0.1628, 0.1732, 0.1731, **Epoch: 80
0.1706, 0.1616, 0.1742, 0.1775, 0.1805, 0.1825, 0.1731, 0.1844, 0.1739, 0.1690, **Epoch: 90
0.1621, 0.1764, 0.1776, 0.1744, 0.1801, 0.1836, 0.1747, 0.1654, 0.1674, 0.1681, **Epoch: 100
Validation Loss: 
1.5466, 1.4348, 1.3279, 1.2377, 1.1467, 1.0809, 1.0145, 0.9692, 0.9356, 0.9206, **Epoch: 10
0.8872, 0.8789, 0.8493, 0.8493, 0.8746, 0.8448, 0.8577, 0.8564, 0.8580, 0.8646, **Epoch: 20
0.8656, 0.8919, 0.8920, 0.9311, 0.9215, 0.9321, 0.9339, 0.9347, 0.9888, 0.9419, **Epoch: 30
1.0036, 0.9890, 1.0327, 1.0438, 1.0755, 1.0842, 1.1091, 1.1700, 1.1334, 1.1598, **Epoch: 40
1.1658, 1.1866, 1.1589, 1.2099, 1.1727, 1.1799, 1.2185, 1.2033, 1.2063, 1.2245, **Epoch: 50
1.1744, 1.1930, 1.1965, 1.2576, 1.2293, 1.2616, 1.2698, 1.2452, 1.2181, 1.2310, **Epoch: 60
1.2634, 1.2212, 1.2322, 1.2490, 1.2998, 1.3127, 1.2737, 1.3005, 1.2617, 1.2214, **Epoch: 70
1.2150, 1.1958, 1.2007, 1.2425, 1.2540, 1.2320, 1.2126, 1.2296, 1.2287, 1.2450, **Epoch: 80
1.1995, 1.1649, 1.2338, 1.2486, 1.2830, 1.2814, 1.2807, 1.2615, 1.2478, 1.2533, **Epoch: 90
1.2820, 1.2660, 1.2543, 1.2452, 1.2634, 1.2898, 1.2459, 1.2684, 1.2653, 1.2577, **Epoch: 100
Training Accuracy: 
0.6911, 0.7470, 0.7674, 0.7885, 0.7900, 0.8029, 0.8142, 0.8210, 0.8270, 0.8323, **Epoch: 10
0.8452, 0.8512, 0.8535, 0.8588, 0.8625, 0.8769, 0.8867, 0.8829, 0.8890, 0.8995, **Epoch: 20
0.9003, 0.9169, 0.9094, 0.9177, 0.9237, 0.9252, 0.9267, 0.9260, 0.9373, 0.9358, **Epoch: 30
0.9373, 0.9396, 0.9449, 0.9373, 0.9479, 0.9479, 0.9471, 0.9471, 0.9524, 0.9471, **Epoch: 40
0.9509, 0.9449, 0.9509, 0.9456, 0.9486, 0.9456, 0.9381, 0.9502, 0.9517, 0.9471, **Epoch: 50
0.9569, 0.9471, 0.9494, 0.9585, 0.9547, 0.9502, 0.9502, 0.9396, 0.9441, 0.9456, **Epoch: 60
0.9456, 0.9494, 0.9471, 0.9426, 0.9509, 0.9456, 0.9464, 0.9509, 0.9547, 0.9532, **Epoch: 70
0.9539, 0.9494, 0.9524, 0.9502, 0.9479, 0.9562, 0.9524, 0.9569, 0.9464, 0.9524, **Epoch: 80
0.9517, 0.9502, 0.9494, 0.9517, 0.9449, 0.9509, 0.9547, 0.9456, 0.9479, 0.9607, **Epoch: 90
0.9517, 0.9539, 0.9547, 0.9562, 0.9509, 0.9532, 0.9577, 0.9569, 0.9479, 0.9585, **Epoch: 100
Validation Accuracy: 
0.6264, 0.6838, 0.6979, 0.7190, 0.7160, 0.7271, 0.7362, 0.7412, 0.7452, 0.7462, **Epoch: 10
0.7523, 0.7462, 0.7593, 0.7573, 0.7563, 0.7513, 0.7633, 0.7664, 0.7573, 0.7573, **Epoch: 20
0.7543, 0.7432, 0.7402, 0.7432, 0.7341, 0.7331, 0.7301, 0.7170, 0.7372, 0.7341, **Epoch: 30
0.7291, 0.7261, 0.7331, 0.7291, 0.7251, 0.7301, 0.7200, 0.7180, 0.7039, 0.7180, **Epoch: 40
0.7049, 0.7059, 0.7080, 0.7069, 0.7140, 0.6949, 0.7019, 0.6969, 0.6979, 0.7019, **Epoch: 50
0.7100, 0.7251, 0.7059, 0.6999, 0.6979, 0.6979, 0.6868, 0.6949, 0.6999, 0.6989, **Epoch: 60
0.6767, 0.6928, 0.6959, 0.7120, 0.6999, 0.6969, 0.6908, 0.7049, 0.7180, 0.6949, **Epoch: 70
0.6969, 0.6989, 0.7019, 0.7009, 0.6999, 0.6979, 0.7039, 0.7039, 0.7080, 0.6999, **Epoch: 80
0.6979, 0.7049, 0.6989, 0.7029, 0.7069, 0.6848, 0.6828, 0.6848, 0.6949, 0.6939, **Epoch: 90
0.6949, 0.7069, 0.6979, 0.6989, 0.7019, 0.7090, 0.7029, 0.7019, 0.7009, 0.7019, **Epoch: 100
Validation Accuracy Final: 0.7019
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.1
Epochs: 100
--------------------------END------------------------------
----------------------------------------------------------
Time: 0516-1545
Training Loss: 
1.9457, 1.8613, 1.7982, 1.7674, 1.7552, 1.7334, 1.7124, 1.6847, 1.6603, 1.6355, **Epoch: 10
1.6165, 1.5950, 1.5633, 1.5365, 1.4917, 1.4649, 1.4350, 1.3907, 1.3631, 1.3253, **Epoch: 20
1.3021, 1.2666, 1.2382, 1.2220, 1.1871, 1.1566, 1.1419, 1.1104, 1.0944, 1.0797, **Epoch: 30
1.0790, 1.0580, 1.0481, 1.0251, 1.0187, 0.9897, 0.9803, 0.9841, 0.9771, 0.9703, **Epoch: 40
0.9563, 0.9499, 0.9378, 0.9249, 0.9244, 0.9344, 0.9171, 0.9224, 0.9069, 0.9113, **Epoch: 50
0.8981, 0.9011, 0.8923, 0.8912, 0.8939, 0.8637, 0.8776, 0.8884, 0.8709, 0.8578, **Epoch: 60
0.8640, 0.8704, 0.8564, 0.8606, 0.8588, 0.8710, 0.8430, 0.8600, 0.8519, 0.8536, **Epoch: 70
0.8468, 0.8554, 0.8465, 0.8270, 0.8374, 0.8524, 0.8181, 0.8450, 0.8375, 0.8450, **Epoch: 80
0.8341, 0.8324, 0.8346, 0.8335, 0.8321, 0.8186, 0.8456, 0.8052, 0.8277, 0.8181, **Epoch: 90
0.8343, 0.8282, 0.8200, 0.8252, 0.8249, 0.8397, 0.8003, 0.8095, 0.8205, 0.8125, **Epoch: 100
Validation Loss: 
1.8720, 1.8157, 1.7960, 1.7816, 1.7639, 1.7440, 1.7197, 1.6867, 1.6577, 1.6428, **Epoch: 10
1.6152, 1.5866, 1.5601, 1.5292, 1.5021, 1.4723, 1.4455, 1.4077, 1.3857, 1.3480, **Epoch: 20
1.3200, 1.2921, 1.2588, 1.2375, 1.2452, 1.1916, 1.1815, 1.1814, 1.1540, 1.1639, **Epoch: 30
1.1190, 1.1205, 1.1005, 1.0993, 1.0761, 1.0611, 1.0749, 1.0612, 1.0565, 1.0384, **Epoch: 40
1.0467, 1.0422, 1.0337, 1.0239, 1.0139, 1.0199, 1.0229, 1.0099, 1.0025, 1.0124, **Epoch: 50
1.0195, 0.9944, 0.9919, 0.9844, 0.9927, 0.9862, 1.0044, 0.9939, 0.9890, 0.9986, **Epoch: 60
0.9989, 0.9832, 0.9694, 0.9665, 0.9757, 0.9760, 0.9679, 0.9763, 0.9398, 0.9810, **Epoch: 70
0.9532, 0.9620, 0.9727, 0.9619, 0.9575, 0.9718, 0.9678, 0.9538, 0.9541, 0.9415, **Epoch: 80
0.9716, 0.9649, 0.9563, 0.9588, 0.9484, 0.9448, 0.9681, 0.9425, 0.9489, 0.9398, **Epoch: 90
0.9404, 0.9519, 0.9512, 0.9565, 0.9292, 0.9476, 0.9462, 0.9483, 0.9441, 0.9528, **Epoch: 100
Training Accuracy: 
0.1850, 0.4275, 0.2689, 0.2205, 0.2190, 0.3233, 0.3950, 0.3693, 0.3603, 0.4109, **Epoch: 10
0.5234, 0.5763, 0.6125, 0.6420, 0.6677, 0.6918, 0.6722, 0.6888, 0.7107, 0.7160, **Epoch: 20
0.6971, 0.7153, 0.7183, 0.7319, 0.7175, 0.7205, 0.7289, 0.7394, 0.7372, 0.7402, **Epoch: 30
0.7568, 0.7258, 0.7628, 0.7719, 0.7417, 0.7538, 0.7477, 0.7515, 0.7666, 0.7659, **Epoch: 40
0.7591, 0.7628, 0.7606, 0.7666, 0.7704, 0.7681, 0.7628, 0.7711, 0.7545, 0.7613, **Epoch: 50
0.7711, 0.7598, 0.7696, 0.7711, 0.7795, 0.7666, 0.7636, 0.7764, 0.7591, 0.7636, **Epoch: 60
0.7795, 0.7847, 0.7674, 0.7727, 0.7757, 0.7674, 0.7779, 0.7764, 0.7757, 0.7772, **Epoch: 70
0.7817, 0.7644, 0.7908, 0.7787, 0.7704, 0.7727, 0.7779, 0.7795, 0.7832, 0.7787, **Epoch: 80
0.7802, 0.7749, 0.7772, 0.7757, 0.7719, 0.7719, 0.7764, 0.7779, 0.7832, 0.7795, **Epoch: 90
0.7810, 0.7878, 0.7764, 0.7742, 0.7711, 0.7802, 0.7711, 0.7779, 0.7847, 0.7757, **Epoch: 100
Validation Accuracy: 
0.1893, 0.4048, 0.2618, 0.2216, 0.2276, 0.3041, 0.3696, 0.3474, 0.3565, 0.3948, **Epoch: 10
0.4904, 0.5488, 0.5740, 0.6022, 0.6485, 0.6767, 0.6576, 0.6727, 0.6868, 0.6788, **Epoch: 20
0.6908, 0.6717, 0.6989, 0.6868, 0.7039, 0.6788, 0.6949, 0.6878, 0.7019, 0.6918, **Epoch: 30
0.6999, 0.6808, 0.7130, 0.7251, 0.7059, 0.7170, 0.7130, 0.7291, 0.7180, 0.7251, **Epoch: 40
0.7080, 0.7351, 0.7291, 0.7200, 0.7130, 0.7251, 0.7241, 0.7251, 0.7351, 0.7231, **Epoch: 50
0.7221, 0.7221, 0.7372, 0.7452, 0.7110, 0.7351, 0.7019, 0.7221, 0.7190, 0.7100, **Epoch: 60
0.7180, 0.7341, 0.7200, 0.7120, 0.7311, 0.7180, 0.7261, 0.7331, 0.7251, 0.7291, **Epoch: 70
0.7281, 0.7200, 0.7210, 0.7200, 0.7341, 0.7231, 0.7281, 0.7261, 0.7140, 0.7221, **Epoch: 80
0.7150, 0.7251, 0.7321, 0.7231, 0.7281, 0.7200, 0.7180, 0.7341, 0.7221, 0.7271, **Epoch: 90
0.7130, 0.7221, 0.7190, 0.7140, 0.7221, 0.7321, 0.7311, 0.7301, 0.7321, 0.7271, **Epoch: 100
Validation Accuracy Final: 0.7271
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.3
Epochs: 100
--------------------------END------------------------------
