----------------------------------------------------------
Time: 0510-1252
Training Loss: 
1.9463, 1.9198, 1.8691, 1.8105, 1.7424, 1.6554, 1.5803, 1.4806, 1.3780, 1.2756, **Epoch: 10
1.1890, 1.0882, 1.0148, 0.9664, 0.8827, 0.8253, 0.7911, 0.7530, 0.7223, 0.7245, **Epoch: 20
0.6498, 0.6199, 0.5655, 0.5952, 0.5641, 0.5240, 0.5190, 0.4986, 0.4535, 0.4465, **Epoch: 30
0.4527, 0.4154, 0.4130, 0.3996, 0.3947, 0.3801, 0.3787, 0.3594, 0.3805, 0.3648, **Epoch: 40
0.3410, 0.3592, 0.3459, 0.3434, 0.3412, 0.3370, 0.3392, 0.3231, 0.3265, 0.3109, **Epoch: 50
0.3179, 0.3119, 0.3112, 0.3318, 0.2908, 0.2973, 0.3356, 0.3414, 0.3325, 0.3313, **Epoch: 60
0.3617, 0.3494, 0.2888, 0.3051, 0.3122, 0.3292, 0.3120, 0.3203, 0.3528, 0.3236, **Epoch: 70
0.3045, 0.3380, 0.3180, 0.3259, 0.2874, 0.3032, 0.3105, 0.3199, 0.3312, 0.3316, **Epoch: 80
Validation Loss: 
1.9220, 1.8819, 1.8292, 1.7721, 1.7072, 1.6380, 1.5712, 1.5011, 1.4178, 1.3537, **Epoch: 10
1.2877, 1.2315, 1.1776, 1.1152, 1.0831, 1.0492, 1.0214, 1.0012, 0.9648, 0.9469, **Epoch: 20
0.9157, 0.9113, 0.8883, 0.8931, 0.8623, 0.8509, 0.8377, 0.8219, 0.8088, 0.7728, **Epoch: 30
0.7758, 0.7723, 0.7793, 0.7500, 0.7494, 0.7301, 0.7482, 0.7495, 0.7304, 0.7248, **Epoch: 40
0.7268, 0.7300, 0.7277, 0.7340, 0.7427, 0.7287, 0.6945, 0.7359, 0.7066, 0.7094, **Epoch: 50
0.7151, 0.7049, 0.7042, 0.7017, 0.7049, 0.7101, 0.7272, 0.7165, 0.7305, 0.7326, **Epoch: 60
0.7065, 0.7043, 0.7223, 0.7077, 0.7127, 0.7137, 0.7020, 0.7333, 0.7156, 0.7299, **Epoch: 70
0.7156, 0.7243, 0.7156, 0.7264, 0.7162, 0.6906, 0.7193, 0.7039, 0.7205, 0.7248, **Epoch: 80
Training Accuracy: 
0.3148, 0.3148, 0.3444, 0.4481, 0.4741, 0.5333, 0.6000, 0.6519, 0.7370, 0.7852, **Epoch: 10
0.8000, 0.8037, 0.8148, 0.8222, 0.8259, 0.8370, 0.8519, 0.8519, 0.8556, 0.8444, **Epoch: 20
0.8667, 0.8667, 0.8889, 0.9037, 0.9222, 0.9296, 0.9407, 0.9333, 0.9481, 0.9444, **Epoch: 30
0.9556, 0.9481, 0.9407, 0.9519, 0.9519, 0.9667, 0.9593, 0.9556, 0.9630, 0.9444, **Epoch: 40
0.9593, 0.9556, 0.9704, 0.9778, 0.9667, 0.9593, 0.9815, 0.9630, 0.9704, 0.9852, **Epoch: 50
0.9741, 0.9667, 0.9593, 0.9630, 0.9556, 0.9778, 0.9815, 0.9741, 0.9593, 0.9481, **Epoch: 60
0.9704, 0.9741, 0.9852, 0.9815, 0.9630, 0.9593, 0.9667, 0.9593, 0.9630, 0.9741, **Epoch: 70
0.9630, 0.9741, 0.9704, 0.9667, 0.9556, 0.9556, 0.9593, 0.9778, 0.9630, 0.9778, **Epoch: 80
Validation Accuracy: 
0.3316, 0.3368, 0.3619, 0.4180, 0.4513, 0.4970, 0.5362, 0.5901, 0.6462, 0.6965, **Epoch: 10
0.7083, 0.7134, 0.7186, 0.7230, 0.7334, 0.7319, 0.7349, 0.7326, 0.7378, 0.7422, **Epoch: 20
0.7533, 0.7408, 0.7518, 0.7533, 0.7578, 0.7792, 0.7829, 0.7880, 0.7954, 0.8072, **Epoch: 30
0.8072, 0.8013, 0.7947, 0.8050, 0.8124, 0.8139, 0.8131, 0.8028, 0.8006, 0.7984, **Epoch: 40
0.8102, 0.8176, 0.8072, 0.8080, 0.8131, 0.8050, 0.8124, 0.8058, 0.8131, 0.8013, **Epoch: 50
0.8102, 0.8124, 0.8080, 0.8028, 0.8154, 0.8080, 0.8131, 0.8161, 0.8072, 0.8028, **Epoch: 60
0.8161, 0.8087, 0.8213, 0.8109, 0.8124, 0.8131, 0.8109, 0.8028, 0.8013, 0.8050, **Epoch: 70
0.8117, 0.8095, 0.8146, 0.8117, 0.8131, 0.8013, 0.8146, 0.8191, 0.8065, 0.8124, **Epoch: 80
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 80
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1442
Training Loss: 
1.9462, 1.9231, 1.8760, 1.8134, 1.7451, 1.6561, 1.5612, 1.4511, 1.3467, 1.2616, **Epoch: 10
1.1374, 1.1060, 1.0480, 0.9515, 0.9000, 0.8590, 0.8318, 0.8026, 0.7738, 0.7236, **Epoch: 20
0.6953, 0.6571, 0.6277, 0.6341, 0.5995, 0.6437, 0.5527, 0.5441, 0.5820, 0.5307, **Epoch: 30
0.5233, 0.4528, 0.4944, 0.4232, 0.4531, 0.4259, 0.4290, 0.3807, 0.4065, 0.4227, **Epoch: 40
0.3651, 0.3602, 0.3649, 0.3677, 0.3724, 0.3578, 0.3340, 0.3360, 0.3382, 0.3391, **Epoch: 50
0.3207, 0.3167, 0.3163, 0.3187, 0.3547, 0.3554, 0.3321, 0.3301, 0.2910, 0.3592, **Epoch: 60
0.3349, 0.3333, 0.3266, 0.3196, 0.3000, 0.3423, 0.3191, 0.2984, 0.3390, 0.3626, **Epoch: 70
0.3158, 0.3263, 0.3140, 0.3366, 0.3189, 0.3830, 0.2862, 0.3235, 0.3301, 0.3238, **Epoch: 80
Validation Loss: 
1.9277, 1.8914, 1.8422, 1.7829, 1.7180, 1.6574, 1.5845, 1.5169, 1.4390, 1.3776, **Epoch: 10
1.3052, 1.2580, 1.2177, 1.1726, 1.1331, 1.0976, 1.0704, 1.0415, 1.0211, 1.0130, **Epoch: 20
0.9910, 0.9670, 0.9425, 0.9379, 0.9079, 0.8999, 0.8836, 0.8644, 0.8542, 0.8483, **Epoch: 30
0.8184, 0.7918, 0.7988, 0.8056, 0.8089, 0.7838, 0.7784, 0.7652, 0.7747, 0.7842, **Epoch: 40
0.7782, 0.7582, 0.7597, 0.7511, 0.7411, 0.7420, 0.7315, 0.7327, 0.7506, 0.7392, **Epoch: 50
0.7155, 0.7165, 0.7271, 0.7123, 0.7317, 0.7452, 0.7080, 0.7203, 0.7258, 0.7256, **Epoch: 60
0.7143, 0.7349, 0.7131, 0.7112, 0.7116, 0.7087, 0.7254, 0.7211, 0.7362, 0.7168, **Epoch: 70
0.7081, 0.7098, 0.7211, 0.7152, 0.7272, 0.7155, 0.7285, 0.7313, 0.7160, 0.7224, **Epoch: 80
Training Accuracy: 
0.5222, 0.5074, 0.5593, 0.5852, 0.5889, 0.6222, 0.7000, 0.7370, 0.7741, 0.7852, **Epoch: 10
0.7926, 0.8074, 0.8037, 0.8074, 0.8185, 0.8148, 0.8111, 0.8148, 0.8259, 0.8259, **Epoch: 20
0.8259, 0.8111, 0.8481, 0.8593, 0.8667, 0.8963, 0.9000, 0.9185, 0.9111, 0.9259, **Epoch: 30
0.9296, 0.9481, 0.9444, 0.9407, 0.9481, 0.9370, 0.9481, 0.9519, 0.9481, 0.9667, **Epoch: 40
0.9519, 0.9667, 0.9556, 0.9630, 0.9630, 0.9593, 0.9630, 0.9704, 0.9704, 0.9667, **Epoch: 50
0.9704, 0.9667, 0.9630, 0.9630, 0.9630, 0.9630, 0.9593, 0.9704, 0.9667, 0.9630, **Epoch: 60
0.9630, 0.9593, 0.9778, 0.9704, 0.9556, 0.9741, 0.9593, 0.9704, 0.9630, 0.9481, **Epoch: 70
0.9704, 0.9741, 0.9667, 0.9519, 0.9667, 0.9667, 0.9630, 0.9667, 0.9556, 0.9630, **Epoch: 80
Validation Accuracy: 
0.4705, 0.4778, 0.5081, 0.5303, 0.5347, 0.5340, 0.5709, 0.6086, 0.6425, 0.6566, **Epoch: 10
0.6706, 0.6773, 0.6780, 0.6920, 0.6839, 0.6994, 0.7009, 0.7009, 0.7061, 0.7083, **Epoch: 20
0.7112, 0.7120, 0.7216, 0.7297, 0.7312, 0.7356, 0.7511, 0.7555, 0.7600, 0.7792, **Epoch: 30
0.7799, 0.7792, 0.7806, 0.7792, 0.7917, 0.7895, 0.7770, 0.7969, 0.7939, 0.8124, **Epoch: 40
0.7925, 0.8028, 0.8043, 0.8087, 0.7969, 0.8028, 0.8058, 0.8117, 0.8065, 0.8035, **Epoch: 50
0.8117, 0.8139, 0.8154, 0.8080, 0.8065, 0.8035, 0.8191, 0.8198, 0.8124, 0.8058, **Epoch: 60
0.8154, 0.8191, 0.8250, 0.8161, 0.8183, 0.8058, 0.8117, 0.8109, 0.8124, 0.8072, **Epoch: 70
0.8117, 0.8109, 0.8006, 0.8043, 0.8102, 0.8117, 0.8065, 0.8117, 0.8117, 0.8043, **Epoch: 80
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 80
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1443
Training Loss: 
1.9461, 1.9153, 1.8539, 1.7820, 1.6862, 1.5919, 1.5042, 1.3986, 1.3231, 1.2483, **Epoch: 10
1.1696, 1.1062, 1.0718, 0.9876, 0.9435, 0.9273, 0.9051, 0.8689, 0.8240, 0.7648, **Epoch: 20
0.7824, 0.7304, 0.7248, 0.7142, 0.6676, 0.6445, 0.6523, 0.5998, 0.6086, 0.6021, **Epoch: 30
0.5864, 0.6008, 0.5677, 0.5662, 0.5400, 0.5033, 0.4826, 0.4820, 0.4953, 0.4865, **Epoch: 40
0.4368, 0.4727, 0.4386, 0.4188, 0.4249, 0.4252, 0.4174, 0.3878, 0.4065, 0.3541, **Epoch: 50
0.3680, 0.3311, 0.3631, 0.3509, 0.3579, 0.3609, 0.3853, 0.3395, 0.3458, 0.3140, **Epoch: 60
0.3295, 0.3034, 0.3235, 0.3130, 0.3296, 0.3083, 0.3030, 0.3199, 0.3004, 0.3381, **Epoch: 70
0.3431, 0.3041, 0.2917, 0.3423, 0.3314, 0.2995, 0.3524, 0.3135, 0.2990, 0.3216, **Epoch: 80
Validation Loss: 
1.9240, 1.8765, 1.8193, 1.7524, 1.6813, 1.6102, 1.5367, 1.4773, 1.4058, 1.3499, **Epoch: 10
1.3107, 1.2635, 1.2237, 1.1827, 1.1532, 1.1254, 1.1114, 1.0915, 1.0528, 1.0483, **Epoch: 20
1.0163, 0.9952, 0.9774, 0.9662, 0.9569, 0.9394, 0.9389, 0.9403, 0.9240, 0.8984, **Epoch: 30
0.8889, 0.8961, 0.8883, 0.8636, 0.8700, 0.8436, 0.8486, 0.8453, 0.8156, 0.8251, **Epoch: 40
0.8263, 0.8044, 0.7941, 0.7846, 0.7881, 0.7899, 0.7613, 0.7829, 0.7907, 0.7680, **Epoch: 50
0.7642, 0.7741, 0.7530, 0.7455, 0.7576, 0.7314, 0.7540, 0.7520, 0.7374, 0.7319, **Epoch: 60
0.7422, 0.7241, 0.7384, 0.7380, 0.7247, 0.7309, 0.7384, 0.7245, 0.7252, 0.7342, **Epoch: 70
0.7197, 0.7239, 0.7301, 0.7354, 0.7121, 0.7180, 0.7099, 0.7155, 0.7125, 0.7219, **Epoch: 80
Training Accuracy: 
0.4889, 0.4630, 0.4556, 0.4630, 0.4704, 0.5148, 0.6037, 0.6407, 0.6593, 0.6519, **Epoch: 10
0.6926, 0.6889, 0.7370, 0.7778, 0.8037, 0.8111, 0.8000, 0.8185, 0.8222, 0.8185, **Epoch: 20
0.8296, 0.8259, 0.8296, 0.8259, 0.8296, 0.8333, 0.8185, 0.8185, 0.8222, 0.8148, **Epoch: 30
0.8556, 0.8444, 0.8667, 0.8889, 0.8778, 0.8926, 0.9111, 0.9259, 0.9407, 0.9370, **Epoch: 40
0.9519, 0.9519, 0.9630, 0.9481, 0.9519, 0.9556, 0.9704, 0.9481, 0.9741, 0.9593, **Epoch: 50
0.9630, 0.9704, 0.9630, 0.9593, 0.9704, 0.9741, 0.9481, 0.9556, 0.9593, 0.9667, **Epoch: 60
0.9630, 0.9704, 0.9444, 0.9593, 0.9704, 0.9704, 0.9667, 0.9704, 0.9630, 0.9593, **Epoch: 70
0.9667, 0.9704, 0.9704, 0.9667, 0.9630, 0.9667, 0.9741, 0.9519, 0.9741, 0.9704, **Epoch: 80
Validation Accuracy: 
0.4549, 0.3914, 0.3671, 0.3877, 0.4158, 0.4660, 0.5340, 0.5790, 0.5916, 0.6019, **Epoch: 10
0.6189, 0.6388, 0.6610, 0.6876, 0.6972, 0.7038, 0.7120, 0.7061, 0.7164, 0.7149, **Epoch: 20
0.7179, 0.7164, 0.7171, 0.7164, 0.7260, 0.7290, 0.7179, 0.7186, 0.7149, 0.7157, **Epoch: 30
0.7186, 0.7253, 0.7334, 0.7511, 0.7555, 0.7592, 0.7688, 0.7903, 0.7903, 0.7962, **Epoch: 40
0.7991, 0.7932, 0.7851, 0.7903, 0.7954, 0.8109, 0.8028, 0.8035, 0.7932, 0.8050, **Epoch: 50
0.8013, 0.8043, 0.8021, 0.8080, 0.8117, 0.7962, 0.7984, 0.7976, 0.8161, 0.8183, **Epoch: 60
0.8065, 0.8080, 0.8087, 0.8191, 0.8235, 0.8124, 0.8191, 0.8168, 0.8154, 0.8161, **Epoch: 70
0.8191, 0.8139, 0.8161, 0.8168, 0.8095, 0.8139, 0.8161, 0.8131, 0.8072, 0.8080, **Epoch: 80
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 80
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1446
Training Loss: 
1.9461, 1.9037, 1.8410, 1.7642, 1.6865, 1.5945, 1.5145, 1.4255, 1.3389, 1.2471, **Epoch: 10
1.1960, 1.1223, 1.0705, 0.9967, 0.9459, 0.9434, 0.8726, 0.8334, 0.8278, 0.7776, **Epoch: 20
0.7112, 0.7007, 0.6849, 0.6307, 0.6366, 0.6058, 0.5737, 0.5712, 0.5131, 0.5359, **Epoch: 30
0.4934, 0.4967, 0.4635, 0.4448, 0.4370, 0.4370, 0.4412, 0.4033, 0.4097, 0.3888, **Epoch: 40
0.4031, 0.3730, 0.3883, 0.3514, 0.3616, 0.3420, 0.3733, 0.3491, 0.3358, 0.3066, **Epoch: 50
0.3644, 0.3496, 0.3304, 0.3205, 0.3458, 0.3269, 0.3034, 0.3599, 0.3291, 0.3513, **Epoch: 60
0.3301, 0.3137, 0.3014, 0.3288, 0.3608, 0.3252, 0.3136, 0.2895, 0.3122, 0.3417, **Epoch: 70
0.3071, 0.3297, 0.3119, 0.3070, 0.3217, 0.3393, 0.3477, 0.3408, 0.2912, 0.3584, **Epoch: 80
Validation Loss: 
1.9124, 1.8607, 1.8023, 1.7416, 1.6783, 1.6127, 1.5477, 1.4912, 1.4309, 1.3810, **Epoch: 10
1.3231, 1.2759, 1.2446, 1.2065, 1.1687, 1.1412, 1.1057, 1.0952, 1.0367, 1.0299, **Epoch: 20
1.0070, 0.9859, 0.9586, 0.9317, 0.9073, 0.9170, 0.9036, 0.8825, 0.8694, 0.8465, **Epoch: 30
0.8352, 0.8230, 0.8198, 0.7993, 0.7905, 0.8028, 0.7888, 0.7716, 0.7632, 0.7484, **Epoch: 40
0.7554, 0.7525, 0.7540, 0.7230, 0.7369, 0.7324, 0.7469, 0.7362, 0.7219, 0.7316, **Epoch: 50
0.7429, 0.7224, 0.7233, 0.7270, 0.7230, 0.7195, 0.7143, 0.7098, 0.7037, 0.7180, **Epoch: 60
0.7117, 0.7186, 0.7161, 0.7136, 0.7394, 0.7224, 0.7256, 0.7285, 0.7095, 0.7180, **Epoch: 70
0.7203, 0.7399, 0.7155, 0.7351, 0.7134, 0.7176, 0.7265, 0.7109, 0.7154, 0.7181, **Epoch: 80
Training Accuracy: 
0.3778, 0.3630, 0.4148, 0.4481, 0.4889, 0.5593, 0.6593, 0.6926, 0.7185, 0.7148, **Epoch: 10
0.7296, 0.7296, 0.7630, 0.7741, 0.8111, 0.8185, 0.8481, 0.8519, 0.8296, 0.8704, **Epoch: 20
0.8519, 0.8667, 0.8926, 0.8852, 0.8778, 0.8852, 0.8889, 0.8889, 0.8852, 0.8741, **Epoch: 30
0.9296, 0.9296, 0.9481, 0.9630, 0.9556, 0.9444, 0.9556, 0.9519, 0.9519, 0.9593, **Epoch: 40
0.9593, 0.9519, 0.9407, 0.9593, 0.9741, 0.9593, 0.9593, 0.9593, 0.9704, 0.9593, **Epoch: 50
0.9630, 0.9593, 0.9667, 0.9667, 0.9630, 0.9704, 0.9704, 0.9593, 0.9704, 0.9593, **Epoch: 60
0.9741, 0.9630, 0.9741, 0.9667, 0.9704, 0.9704, 0.9704, 0.9704, 0.9667, 0.9667, **Epoch: 70
0.9741, 0.9741, 0.9667, 0.9630, 0.9704, 0.9630, 0.9852, 0.9741, 0.9630, 0.9630, **Epoch: 80
Validation Accuracy: 
0.3597, 0.3442, 0.3781, 0.4084, 0.4439, 0.4941, 0.5716, 0.6049, 0.6204, 0.6285, **Epoch: 10
0.6300, 0.6359, 0.6477, 0.6536, 0.6891, 0.6979, 0.7061, 0.7075, 0.7290, 0.7223, **Epoch: 20
0.7275, 0.7326, 0.7415, 0.7386, 0.7408, 0.7526, 0.7518, 0.7511, 0.7533, 0.7555, **Epoch: 30
0.7659, 0.7777, 0.7829, 0.7999, 0.7962, 0.8028, 0.8035, 0.8028, 0.8102, 0.8161, **Epoch: 40
0.8117, 0.8168, 0.8021, 0.8102, 0.8058, 0.8087, 0.8065, 0.8154, 0.8087, 0.8176, **Epoch: 50
0.8161, 0.8146, 0.8139, 0.8058, 0.8087, 0.8117, 0.8117, 0.8213, 0.8183, 0.8168, **Epoch: 60
0.8102, 0.8072, 0.8050, 0.8124, 0.8028, 0.8131, 0.8072, 0.8095, 0.8087, 0.8131, **Epoch: 70
0.8213, 0.8139, 0.8161, 0.8072, 0.8021, 0.8139, 0.8072, 0.8139, 0.8146, 0.8065, **Epoch: 80
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 80
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1450
Training Loss: 
1.9459, 1.9442, 1.9424, 1.9405, 1.9385, 1.9361, 1.9333, 1.9304, 1.9277, 1.9238, **Epoch: 10
1.9209, 1.9171, 1.9143, 1.9094, 1.9046, 1.9037, 1.8989, 1.8951, 1.8909, 1.8841, **Epoch: 20
1.8803, 1.8752, 1.8710, 1.8687, 1.8592, 1.8568, 1.8521, 1.8460, 1.8411, 1.8380, **Epoch: 30
1.8259, 1.8250, 1.8205, 1.8143, 1.8082, 1.7980, 1.7974, 1.7878, 1.7764, 1.7765, **Epoch: 40
1.7684, 1.7566, 1.7582, 1.7452, 1.7448, 1.7261, 1.7252, 1.7257, 1.7179, 1.7081, **Epoch: 50
1.7010, 1.6850, 1.6892, 1.6855, 1.6633, 1.6540, 1.6554, 1.6469, 1.6405, 1.6221, **Epoch: 60
1.6272, 1.6268, 1.6084, 1.6091, 1.5831, 1.5916, 1.5731, 1.5734, 1.5716, 1.5510, **Epoch: 70
1.5302, 1.5395, 1.5408, 1.5268, 1.5218, 1.5135, 1.4994, 1.4772, 1.5012, 1.4868, **Epoch: 80
1.4730, 1.4772, 1.4713, 1.4576, 1.4527, 1.4434, 1.4227, 1.4303, 1.4219, 1.4138, **Epoch: 90
1.4034, 1.4104, 1.3894, 1.4059, 1.3833, 1.3898, 1.3510, 1.3572, 1.3583, 1.3506, **Epoch: 100
1.3314, 1.3178, 1.3237, 1.3335, 1.2959, 1.3113, 1.3192, 1.2912, 1.2983, 1.2895, **Epoch: 110
1.2792, 1.2826, 1.2682, 1.2463, 1.2543, 1.2574, 1.2537, 1.2555, 1.2343, 1.2318, **Epoch: 120
1.2270, 1.2178, 1.2047, 1.2275, 1.1824, 1.2070, 1.1934, 1.1779, 1.1858, 1.1859, **Epoch: 130
1.1632, 1.1813, 1.1545, 1.1386, 1.1399, 1.1391, 1.1348, 1.1358, 1.1346, 1.1244, **Epoch: 140
1.1311, 1.1211, 1.1085, 1.1109, 1.0845, 1.1206, 1.1094, 1.0985, 1.0751, 1.0913, **Epoch: 150
1.0775, 1.0578, 1.0783, 1.0603, 1.0481, 1.0250, 1.0705, 1.0634, 1.0506, 1.0178, **Epoch: 160
1.0377, 1.0443, 0.9936, 1.0104, 0.9927, 1.0181, 1.0181, 1.0146, 0.9888, 0.9999, **Epoch: 170
0.9978, 0.9766, 0.9846, 0.9801, 0.9541, 0.9867, 0.9946, 0.9508, 0.9335, 0.9446, **Epoch: 180
0.9555, 0.9835, 0.9477, 0.9600, 0.9494, 0.9459, 0.9257, 0.9085, 0.9309, 0.9381, **Epoch: 190
0.9449, 0.9188, 0.9133, 0.9079, 0.9159, 0.8879, 0.8854, 0.8622, 0.8894, 0.8885, **Epoch: 200
Validation Loss: 
1.9448, 1.9436, 1.9422, 1.9404, 1.9386, 1.9364, 1.9341, 1.9318, 1.9294, 1.9268, **Epoch: 10
1.9243, 1.9212, 1.9188, 1.9157, 1.9135, 1.9098, 1.9068, 1.9032, 1.8997, 1.8968, **Epoch: 20
1.8939, 1.8887, 1.8854, 1.8832, 1.8776, 1.8746, 1.8712, 1.8633, 1.8627, 1.8576, **Epoch: 30
1.8523, 1.8484, 1.8442, 1.8419, 1.8337, 1.8300, 1.8266, 1.8211, 1.8150, 1.8100, **Epoch: 40
1.8039, 1.8006, 1.7948, 1.7914, 1.7855, 1.7779, 1.7740, 1.7692, 1.7604, 1.7568, **Epoch: 50
1.7520, 1.7407, 1.7396, 1.7336, 1.7304, 1.7249, 1.7173, 1.7131, 1.7094, 1.6991, **Epoch: 60
1.6921, 1.6951, 1.6865, 1.6766, 1.6721, 1.6672, 1.6604, 1.6575, 1.6549, 1.6457, **Epoch: 70
1.6407, 1.6376, 1.6256, 1.6220, 1.6179, 1.6087, 1.6031, 1.6046, 1.5926, 1.5851, **Epoch: 80
1.5774, 1.5786, 1.5720, 1.5601, 1.5628, 1.5638, 1.5481, 1.5558, 1.5416, 1.5336, **Epoch: 90
1.5342, 1.5323, 1.5165, 1.5134, 1.5139, 1.5080, 1.5032, 1.5007, 1.4954, 1.4870, **Epoch: 100
1.4841, 1.4806, 1.4732, 1.4725, 1.4657, 1.4568, 1.4463, 1.4493, 1.4531, 1.4387, **Epoch: 110
1.4393, 1.4359, 1.4261, 1.4302, 1.4159, 1.4191, 1.4113, 1.4057, 1.3956, 1.4000, **Epoch: 120
1.3870, 1.3834, 1.3775, 1.3792, 1.3695, 1.3661, 1.3649, 1.3590, 1.3582, 1.3516, **Epoch: 130
1.3430, 1.3461, 1.3503, 1.3320, 1.3390, 1.3307, 1.3358, 1.3248, 1.3201, 1.3160, **Epoch: 140
1.3146, 1.3198, 1.3023, 1.3058, 1.3054, 1.2981, 1.2945, 1.2896, 1.2969, 1.2847, **Epoch: 150
1.2724, 1.2753, 1.2791, 1.2609, 1.2727, 1.2604, 1.2652, 1.2569, 1.2524, 1.2527, **Epoch: 160
1.2430, 1.2445, 1.2375, 1.2389, 1.2307, 1.2254, 1.2265, 1.2206, 1.2250, 1.2255, **Epoch: 170
1.2166, 1.2037, 1.2085, 1.1987, 1.1990, 1.1958, 1.1980, 1.1898, 1.1893, 1.1909, **Epoch: 180
1.1743, 1.1840, 1.1727, 1.1836, 1.1797, 1.1750, 1.1754, 1.1624, 1.1672, 1.1599, **Epoch: 190
1.1601, 1.1497, 1.1487, 1.1670, 1.1529, 1.1499, 1.1474, 1.1379, 1.1420, 1.1348, **Epoch: 200
Training Accuracy: 
0.3222, 0.4296, 0.5185, 0.5407, 0.5407, 0.5481, 0.5407, 0.5111, 0.4704, 0.4704, **Epoch: 10
0.4704, 0.4704, 0.4556, 0.4444, 0.4630, 0.4630, 0.4556, 0.4593, 0.4556, 0.4704, **Epoch: 20
0.4519, 0.4630, 0.4741, 0.4741, 0.4667, 0.4630, 0.4741, 0.4630, 0.4741, 0.4741, **Epoch: 30
0.4704, 0.4704, 0.4667, 0.4741, 0.4741, 0.4741, 0.4778, 0.4741, 0.4667, 0.4667, **Epoch: 40
0.4704, 0.4704, 0.4741, 0.4556, 0.4593, 0.4778, 0.4815, 0.4815, 0.4704, 0.4667, **Epoch: 50
0.4778, 0.4815, 0.4889, 0.4926, 0.4963, 0.4963, 0.5074, 0.4963, 0.4963, 0.5000, **Epoch: 60
0.5074, 0.5296, 0.5148, 0.5481, 0.5333, 0.5370, 0.5222, 0.5222, 0.5593, 0.5556, **Epoch: 70
0.5556, 0.5704, 0.5815, 0.5852, 0.5741, 0.5852, 0.5963, 0.5963, 0.6037, 0.6111, **Epoch: 80
0.6037, 0.6222, 0.6370, 0.6370, 0.6407, 0.6370, 0.6630, 0.6704, 0.6630, 0.6556, **Epoch: 90
0.6852, 0.6704, 0.6926, 0.6852, 0.6926, 0.7037, 0.7037, 0.7148, 0.7111, 0.7185, **Epoch: 100
0.7074, 0.7111, 0.7259, 0.7259, 0.7481, 0.7333, 0.7481, 0.7370, 0.7444, 0.7593, **Epoch: 110
0.7556, 0.7630, 0.7630, 0.7630, 0.7630, 0.7444, 0.7519, 0.7741, 0.7741, 0.7852, **Epoch: 120
0.7593, 0.7778, 0.7889, 0.7778, 0.8037, 0.7889, 0.7741, 0.8074, 0.7815, 0.8148, **Epoch: 130
0.8111, 0.8148, 0.8222, 0.8000, 0.8259, 0.8222, 0.8185, 0.8296, 0.8111, 0.8222, **Epoch: 140
0.8111, 0.8185, 0.8148, 0.8407, 0.8481, 0.8222, 0.8296, 0.8333, 0.8222, 0.8333, **Epoch: 150
0.8222, 0.8370, 0.8296, 0.8333, 0.8333, 0.8481, 0.8296, 0.8370, 0.8148, 0.8407, **Epoch: 160
0.8444, 0.8444, 0.8444, 0.8185, 0.8259, 0.8481, 0.8407, 0.8370, 0.8593, 0.8259, **Epoch: 170
0.8370, 0.8444, 0.8407, 0.8407, 0.8444, 0.8481, 0.8593, 0.8333, 0.8259, 0.8481, **Epoch: 180
0.8593, 0.8407, 0.8630, 0.8556, 0.8593, 0.8407, 0.8519, 0.8519, 0.8556, 0.8481, **Epoch: 190
0.8593, 0.8444, 0.8519, 0.8667, 0.8444, 0.8444, 0.8778, 0.8593, 0.8630, 0.8481, **Epoch: 200
Validation Accuracy: 
0.2223, 0.3146, 0.3877, 0.4195, 0.4424, 0.4313, 0.4306, 0.4188, 0.4143, 0.3951, **Epoch: 10
0.4018, 0.4003, 0.3973, 0.4032, 0.3966, 0.4077, 0.4032, 0.3996, 0.4010, 0.4129, **Epoch: 20
0.4165, 0.4106, 0.4121, 0.4143, 0.4114, 0.4136, 0.4151, 0.4188, 0.4180, 0.4180, **Epoch: 30
0.4210, 0.4232, 0.4254, 0.4202, 0.4306, 0.4217, 0.4165, 0.4225, 0.4254, 0.4247, **Epoch: 40
0.4247, 0.4232, 0.4217, 0.4247, 0.4269, 0.4195, 0.4291, 0.4247, 0.4261, 0.4261, **Epoch: 50
0.4328, 0.4321, 0.4387, 0.4350, 0.4321, 0.4306, 0.4313, 0.4357, 0.4357, 0.4431, **Epoch: 60
0.4387, 0.4372, 0.4431, 0.4439, 0.4468, 0.4572, 0.4549, 0.4586, 0.4631, 0.4645, **Epoch: 70
0.4734, 0.4786, 0.4808, 0.4845, 0.4867, 0.5007, 0.5052, 0.5126, 0.5111, 0.5162, **Epoch: 80
0.5273, 0.5236, 0.5281, 0.5421, 0.5406, 0.5487, 0.5451, 0.5532, 0.5547, 0.5620, **Epoch: 90
0.5702, 0.5665, 0.5790, 0.5835, 0.5783, 0.5901, 0.5945, 0.5901, 0.5968, 0.5931, **Epoch: 100
0.6019, 0.6019, 0.5990, 0.6012, 0.6174, 0.6226, 0.6115, 0.6248, 0.6100, 0.6315, **Epoch: 110
0.6329, 0.6359, 0.6381, 0.6418, 0.6381, 0.6514, 0.6492, 0.6581, 0.6492, 0.6514, **Epoch: 120
0.6595, 0.6544, 0.6573, 0.6632, 0.6662, 0.6640, 0.6677, 0.6699, 0.6787, 0.6773, **Epoch: 130
0.6898, 0.6891, 0.6809, 0.6839, 0.6795, 0.6854, 0.6928, 0.6928, 0.6891, 0.6846, **Epoch: 140
0.6972, 0.6935, 0.6965, 0.7075, 0.6972, 0.6832, 0.7031, 0.7061, 0.7001, 0.7075, **Epoch: 150
0.7068, 0.7112, 0.7053, 0.7038, 0.7016, 0.7194, 0.7075, 0.7053, 0.7046, 0.7068, **Epoch: 160
0.7171, 0.7112, 0.7142, 0.7142, 0.7112, 0.7061, 0.7142, 0.7171, 0.7164, 0.7171, **Epoch: 170
0.7201, 0.7179, 0.7260, 0.7164, 0.7267, 0.7238, 0.7282, 0.7267, 0.7112, 0.7201, **Epoch: 180
0.7290, 0.7208, 0.7171, 0.7208, 0.7290, 0.7245, 0.7260, 0.7194, 0.7245, 0.7290, **Epoch: 190
0.7253, 0.7326, 0.7223, 0.7260, 0.7282, 0.7253, 0.7260, 0.7230, 0.7275, 0.7341, **Epoch: 200
Learning rate: 0.005
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1453
Training Loss: 
1.9451, 1.9411, 1.9360, 1.9308, 1.9245, 1.9176, 1.9101, 1.9025, 1.8935, 1.8854, **Epoch: 10
1.8747, 1.8676, 1.8579, 1.8479, 1.8336, 1.8252, 1.8149, 1.7983, 1.7960, 1.7766, **Epoch: 20
1.7624, 1.7538, 1.7466, 1.7318, 1.7187, 1.6977, 1.6932, 1.6707, 1.6734, 1.6500, **Epoch: 30
1.6318, 1.6222, 1.6139, 1.5947, 1.5780, 1.5673, 1.5287, 1.5328, 1.5207, 1.5145, **Epoch: 40
1.4876, 1.4715, 1.4812, 1.4468, 1.4426, 1.4225, 1.4012, 1.3959, 1.3848, 1.3880, **Epoch: 50
1.3477, 1.3451, 1.3411, 1.3095, 1.3175, 1.2825, 1.2795, 1.2642, 1.2572, 1.2429, **Epoch: 60
1.2315, 1.2413, 1.2019, 1.1885, 1.1975, 1.1625, 1.1663, 1.1448, 1.1439, 1.1270, **Epoch: 70
1.1063, 1.1199, 1.0948, 1.0811, 1.1022, 1.0788, 1.0342, 1.0776, 1.0582, 1.0445, **Epoch: 80
1.0188, 1.0162, 1.0101, 1.0055, 0.9882, 0.9783, 0.9970, 0.9306, 0.9808, 0.9606, **Epoch: 90
0.9570, 0.9437, 0.9576, 0.9251, 0.9091, 0.9220, 0.9008, 0.9130, 0.9064, 0.8805, **Epoch: 100
0.8907, 0.8613, 0.8649, 0.8779, 0.8754, 0.8637, 0.8378, 0.8287, 0.8714, 0.8645, **Epoch: 110
0.8528, 0.8381, 0.8192, 0.7975, 0.7984, 0.7940, 0.7956, 0.7836, 0.7866, 0.7843, **Epoch: 120
0.7780, 0.7599, 0.7579, 0.7865, 0.7658, 0.7595, 0.7495, 0.7711, 0.7466, 0.7337, **Epoch: 130
0.7158, 0.7348, 0.7305, 0.7095, 0.7131, 0.7197, 0.7040, 0.6918, 0.7169, 0.6998, **Epoch: 140
0.7002, 0.6992, 0.6917, 0.6658, 0.7075, 0.6819, 0.6814, 0.6663, 0.6696, 0.6571, **Epoch: 150
0.6536, 0.6302, 0.6598, 0.6235, 0.6543, 0.6225, 0.6324, 0.6331, 0.6220, 0.6525, **Epoch: 160
0.6096, 0.6223, 0.5881, 0.6177, 0.6127, 0.6208, 0.6192, 0.5632, 0.5804, 0.5867, **Epoch: 170
0.6079, 0.6223, 0.6019, 0.6045, 0.6232, 0.6109, 0.6036, 0.6269, 0.6008, 0.5932, **Epoch: 180
0.6271, 0.6111, 0.5976, 0.6220, 0.6359, 0.6263, 0.5960, 0.6292, 0.6062, 0.5932, **Epoch: 190
0.5962, 0.6135, 0.6206, 0.6113, 0.5947, 0.5810, 0.5998, 0.6118, 0.6040, 0.5879, **Epoch: 200
Validation Loss: 
1.9422, 1.9384, 1.9339, 1.9293, 1.9244, 1.9185, 1.9123, 1.9063, 1.8996, 1.8919, **Epoch: 10
1.8858, 1.8779, 1.8701, 1.8621, 1.8529, 1.8440, 1.8363, 1.8269, 1.8173, 1.8089, **Epoch: 20
1.7962, 1.7934, 1.7824, 1.7699, 1.7655, 1.7485, 1.7399, 1.7303, 1.7181, 1.7044, **Epoch: 30
1.6970, 1.6897, 1.6757, 1.6644, 1.6552, 1.6417, 1.6335, 1.6267, 1.6203, 1.6034, **Epoch: 40
1.5918, 1.5840, 1.5682, 1.5581, 1.5576, 1.5454, 1.5277, 1.5182, 1.5085, 1.4929, **Epoch: 50
1.4824, 1.4762, 1.4684, 1.4585, 1.4574, 1.4409, 1.4251, 1.4232, 1.4088, 1.3973, **Epoch: 60
1.4014, 1.3842, 1.3756, 1.3664, 1.3522, 1.3504, 1.3417, 1.3296, 1.3196, 1.3141, **Epoch: 70
1.3040, 1.3049, 1.2902, 1.2895, 1.2744, 1.2729, 1.2677, 1.2574, 1.2508, 1.2419, **Epoch: 80
1.2320, 1.2195, 1.2344, 1.2072, 1.2044, 1.2062, 1.2010, 1.1941, 1.1845, 1.1669, **Epoch: 90
1.1670, 1.1558, 1.1585, 1.1607, 1.1469, 1.1509, 1.1352, 1.1351, 1.1273, 1.1184, **Epoch: 100
1.1172, 1.1128, 1.1154, 1.1065, 1.0990, 1.0865, 1.0900, 1.1017, 1.0796, 1.0853, **Epoch: 110
1.0734, 1.0708, 1.0610, 1.0594, 1.0499, 1.0555, 1.0511, 1.0471, 1.0401, 1.0385, **Epoch: 120
1.0315, 1.0355, 1.0362, 1.0301, 1.0230, 1.0329, 1.0272, 1.0157, 1.0215, 1.0135, **Epoch: 130
1.0117, 0.9994, 0.9869, 0.9952, 0.9946, 0.9798, 0.9844, 0.9813, 0.9742, 0.9684, **Epoch: 140
0.9681, 0.9759, 0.9638, 0.9678, 0.9711, 0.9511, 0.9595, 0.9423, 0.9379, 0.9507, **Epoch: 150
0.9445, 0.9395, 0.9402, 0.9346, 0.9451, 0.9195, 0.9387, 0.9244, 0.9348, 0.9194, **Epoch: 160
0.9221, 0.9118, 0.9156, 0.9214, 0.9142, 0.9143, 0.9114, 0.9143, 0.8995, 0.9159, **Epoch: 170
0.9039, 0.9014, 0.9022, 0.9073, 0.9065, 0.9127, 0.9111, 0.9065, 0.9138, 0.9115, **Epoch: 180
0.9121, 0.9072, 0.9165, 0.9152, 0.9171, 0.9102, 0.9040, 0.9164, 0.9109, 0.9072, **Epoch: 190
0.9112, 0.9043, 0.9080, 0.9081, 0.9049, 0.9015, 0.9222, 0.9136, 0.9081, 0.8950, **Epoch: 200
Training Accuracy: 
0.3778, 0.3852, 0.3926, 0.4000, 0.4148, 0.4333, 0.4185, 0.4296, 0.4296, 0.4259, **Epoch: 10
0.4333, 0.4519, 0.4222, 0.4556, 0.4519, 0.4593, 0.4741, 0.4741, 0.4556, 0.4741, **Epoch: 20
0.4778, 0.4889, 0.5111, 0.4778, 0.5148, 0.5074, 0.5333, 0.5370, 0.5333, 0.5333, **Epoch: 30
0.5481, 0.5778, 0.5778, 0.6074, 0.6185, 0.6148, 0.6481, 0.6741, 0.6852, 0.6630, **Epoch: 40
0.7000, 0.7111, 0.7259, 0.7481, 0.7407, 0.7333, 0.7556, 0.7519, 0.7667, 0.7741, **Epoch: 50
0.7815, 0.7815, 0.7889, 0.7963, 0.7815, 0.7889, 0.7815, 0.7852, 0.7963, 0.7963, **Epoch: 60
0.7926, 0.7926, 0.7963, 0.8037, 0.7889, 0.7963, 0.7963, 0.8000, 0.8111, 0.8111, **Epoch: 70
0.7963, 0.7963, 0.8222, 0.7963, 0.8037, 0.8000, 0.8111, 0.8148, 0.8037, 0.8148, **Epoch: 80
0.8222, 0.8148, 0.8111, 0.8148, 0.8222, 0.8148, 0.8333, 0.8296, 0.8333, 0.8222, **Epoch: 90
0.8222, 0.8259, 0.8222, 0.8296, 0.8333, 0.8333, 0.8185, 0.8370, 0.8407, 0.8370, **Epoch: 100
0.8370, 0.8481, 0.8259, 0.8444, 0.8444, 0.8444, 0.8333, 0.8444, 0.8444, 0.8222, **Epoch: 110
0.8556, 0.8667, 0.8593, 0.8370, 0.8556, 0.8704, 0.8815, 0.8741, 0.8815, 0.8815, **Epoch: 120
0.8815, 0.8852, 0.8926, 0.8815, 0.8778, 0.8889, 0.8889, 0.8852, 0.8963, 0.8926, **Epoch: 130
0.9037, 0.8926, 0.9074, 0.8963, 0.9000, 0.8926, 0.8963, 0.9111, 0.8926, 0.9148, **Epoch: 140
0.9000, 0.9037, 0.9037, 0.9000, 0.9000, 0.9037, 0.9074, 0.8852, 0.9074, 0.9185, **Epoch: 150
0.9111, 0.9185, 0.9000, 0.9111, 0.8963, 0.9259, 0.9259, 0.8963, 0.9296, 0.9185, **Epoch: 160
0.9037, 0.9074, 0.9185, 0.9185, 0.9222, 0.9222, 0.9259, 0.9222, 0.9296, 0.9333, **Epoch: 170
0.9333, 0.9370, 0.9222, 0.9259, 0.9222, 0.9259, 0.9333, 0.9222, 0.9296, 0.9333, **Epoch: 180
0.9185, 0.9185, 0.9333, 0.9222, 0.9296, 0.9259, 0.9222, 0.9222, 0.9148, 0.9148, **Epoch: 190
0.9407, 0.9185, 0.9333, 0.9222, 0.9222, 0.9148, 0.9074, 0.9296, 0.9074, 0.9296, **Epoch: 200
Validation Accuracy: 
0.3663, 0.3700, 0.3656, 0.3685, 0.3693, 0.3789, 0.3848, 0.3833, 0.3900, 0.3885, **Epoch: 10
0.3863, 0.3907, 0.3914, 0.3936, 0.3944, 0.3922, 0.4018, 0.4010, 0.4032, 0.4047, **Epoch: 20
0.4106, 0.4055, 0.4195, 0.4158, 0.4195, 0.4298, 0.4313, 0.4343, 0.4417, 0.4623, **Epoch: 30
0.4601, 0.4668, 0.4815, 0.5007, 0.5103, 0.5170, 0.5391, 0.5569, 0.5657, 0.5753, **Epoch: 40
0.5746, 0.5953, 0.5982, 0.6049, 0.6160, 0.6160, 0.6307, 0.6403, 0.6241, 0.6536, **Epoch: 50
0.6337, 0.6617, 0.6529, 0.6647, 0.6581, 0.6706, 0.6662, 0.6662, 0.6728, 0.6765, **Epoch: 60
0.6780, 0.6787, 0.6809, 0.6869, 0.6839, 0.6839, 0.6920, 0.6965, 0.6987, 0.6891, **Epoch: 70
0.6913, 0.7038, 0.7016, 0.7009, 0.6979, 0.7009, 0.7112, 0.7068, 0.7009, 0.7083, **Epoch: 80
0.7046, 0.7001, 0.7090, 0.7053, 0.7164, 0.7016, 0.7142, 0.7164, 0.7149, 0.7120, **Epoch: 90
0.7179, 0.7179, 0.7171, 0.7120, 0.7179, 0.7164, 0.7186, 0.7208, 0.7157, 0.7127, **Epoch: 100
0.7112, 0.7157, 0.7186, 0.7230, 0.7253, 0.7282, 0.7341, 0.7349, 0.7290, 0.7341, **Epoch: 110
0.7282, 0.7312, 0.7253, 0.7334, 0.7223, 0.7349, 0.7408, 0.7341, 0.7393, 0.7312, **Epoch: 120
0.7408, 0.7349, 0.7378, 0.7393, 0.7386, 0.7482, 0.7356, 0.7445, 0.7445, 0.7459, **Epoch: 130
0.7400, 0.7445, 0.7474, 0.7437, 0.7541, 0.7482, 0.7614, 0.7600, 0.7644, 0.7474, **Epoch: 140
0.7607, 0.7622, 0.7607, 0.7518, 0.7666, 0.7651, 0.7578, 0.7629, 0.7607, 0.7659, **Epoch: 150
0.7703, 0.7644, 0.7725, 0.7703, 0.7644, 0.7681, 0.7777, 0.7718, 0.7710, 0.7740, **Epoch: 160
0.7806, 0.7792, 0.7762, 0.7777, 0.7799, 0.7829, 0.7799, 0.7762, 0.7821, 0.7718, **Epoch: 170
0.7829, 0.7784, 0.7858, 0.7851, 0.7806, 0.7784, 0.7843, 0.7792, 0.7814, 0.7829, **Epoch: 180
0.7910, 0.7799, 0.7821, 0.7777, 0.7836, 0.7784, 0.7836, 0.7866, 0.7866, 0.7843, **Epoch: 190
0.7858, 0.7917, 0.7799, 0.7755, 0.7873, 0.7843, 0.7814, 0.7755, 0.7784, 0.7747, **Epoch: 200
Learning rate: 0.01
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1454
Training Loss: 
1.9468, 1.9437, 1.9406, 1.9364, 1.9321, 1.9268, 1.9206, 1.9164, 1.9091, 1.9019, **Epoch: 10
1.8969, 1.8888, 1.8807, 1.8766, 1.8644, 1.8579, 1.8493, 1.8432, 1.8340, 1.8234, **Epoch: 20
1.8139, 1.8017, 1.7909, 1.7841, 1.7688, 1.7602, 1.7434, 1.7285, 1.7189, 1.7049, **Epoch: 30
1.6832, 1.6739, 1.6588, 1.6592, 1.6383, 1.6226, 1.6105, 1.5958, 1.5808, 1.5625, **Epoch: 40
1.5404, 1.5350, 1.5252, 1.5002, 1.4714, 1.4627, 1.4606, 1.4439, 1.4219, 1.3960, **Epoch: 50
1.3943, 1.3833, 1.3736, 1.3401, 1.3317, 1.3209, 1.3241, 1.2915, 1.2793, 1.2637, **Epoch: 60
1.2557, 1.2076, 1.2222, 1.2052, 1.2052, 1.1975, 1.1889, 1.1737, 1.1584, 1.1626, **Epoch: 70
1.1282, 1.1311, 1.1071, 1.1255, 1.0940, 1.0901, 1.0815, 1.0683, 1.0661, 1.0107, **Epoch: 80
1.0237, 1.0490, 1.0082, 0.9929, 1.0100, 0.9797, 0.9811, 0.9743, 0.9625, 0.9649, **Epoch: 90
0.9504, 0.9757, 0.9303, 0.8996, 0.9209, 0.9299, 0.8868, 0.9076, 0.8902, 0.8748, **Epoch: 100
0.8854, 0.8831, 0.8735, 0.8581, 0.8635, 0.8594, 0.8288, 0.8458, 0.8488, 0.8426, **Epoch: 110
0.8205, 0.8148, 0.8149, 0.8293, 0.8044, 0.8013, 0.7948, 0.7769, 0.7977, 0.8120, **Epoch: 120
0.7590, 0.7638, 0.7695, 0.7592, 0.7592, 0.7812, 0.7174, 0.7378, 0.7250, 0.7301, **Epoch: 130
0.7591, 0.7357, 0.7153, 0.7134, 0.7022, 0.6953, 0.6752, 0.7091, 0.7320, 0.6686, **Epoch: 140
0.6685, 0.7032, 0.6780, 0.6768, 0.6879, 0.7098, 0.6770, 0.6630, 0.6723, 0.6589, **Epoch: 150
0.6619, 0.6702, 0.6736, 0.6568, 0.6425, 0.6517, 0.6151, 0.6183, 0.6585, 0.5966, **Epoch: 160
0.6829, 0.6361, 0.6280, 0.6244, 0.6357, 0.6117, 0.6048, 0.5979, 0.6130, 0.6145, **Epoch: 170
0.5991, 0.5807, 0.6184, 0.5637, 0.5794, 0.5922, 0.6097, 0.6054, 0.5981, 0.5830, **Epoch: 180
0.5605, 0.5822, 0.5822, 0.5763, 0.5406, 0.5576, 0.5699, 0.5545, 0.5344, 0.5347, **Epoch: 190
0.5638, 0.5266, 0.5674, 0.5068, 0.5390, 0.5283, 0.5426, 0.5328, 0.5309, 0.5368, **Epoch: 200
Validation Loss: 
1.9444, 1.9419, 1.9389, 1.9354, 1.9318, 1.9278, 1.9234, 1.9193, 1.9151, 1.9098, **Epoch: 10
1.9041, 1.8984, 1.8926, 1.8866, 1.8800, 1.8731, 1.8659, 1.8613, 1.8532, 1.8470, **Epoch: 20
1.8380, 1.8309, 1.8228, 1.8134, 1.8046, 1.7965, 1.7873, 1.7749, 1.7662, 1.7608, **Epoch: 30
1.7472, 1.7367, 1.7273, 1.7128, 1.7037, 1.6893, 1.6817, 1.6665, 1.6571, 1.6464, **Epoch: 40
1.6355, 1.6199, 1.6159, 1.6026, 1.5875, 1.5792, 1.5670, 1.5518, 1.5404, 1.5285, **Epoch: 50
1.5205, 1.5015, 1.4966, 1.4866, 1.4766, 1.4722, 1.4491, 1.4428, 1.4376, 1.4252, **Epoch: 60
1.4130, 1.4042, 1.4009, 1.3875, 1.3787, 1.3636, 1.3570, 1.3420, 1.3391, 1.3278, **Epoch: 70
1.3233, 1.3153, 1.3088, 1.2885, 1.2852, 1.2759, 1.2738, 1.2667, 1.2540, 1.2572, **Epoch: 80
1.2514, 1.2326, 1.2322, 1.2300, 1.2180, 1.2070, 1.2080, 1.2136, 1.1951, 1.1934, **Epoch: 90
1.1810, 1.1754, 1.1649, 1.1664, 1.1578, 1.1590, 1.1535, 1.1512, 1.1401, 1.1388, **Epoch: 100
1.1278, 1.1262, 1.1205, 1.1092, 1.1091, 1.1165, 1.1000, 1.0905, 1.0997, 1.0821, **Epoch: 110
1.0859, 1.0781, 1.0670, 1.0729, 1.0798, 1.0687, 1.0711, 1.0552, 1.0446, 1.0424, **Epoch: 120
1.0411, 1.0452, 1.0442, 1.0376, 1.0198, 1.0336, 1.0276, 1.0259, 1.0153, 1.0114, **Epoch: 130
1.0106, 1.0094, 1.0005, 0.9921, 0.9940, 0.9928, 0.9889, 0.9782, 0.9796, 0.9847, **Epoch: 140
0.9762, 0.9746, 0.9680, 0.9598, 0.9747, 0.9612, 0.9588, 0.9664, 0.9532, 0.9594, **Epoch: 150
0.9415, 0.9443, 0.9505, 0.9456, 0.9347, 0.9290, 0.9340, 0.9267, 0.9363, 0.9261, **Epoch: 160
0.9102, 0.9251, 0.9141, 0.9198, 0.9144, 0.9015, 0.9098, 0.9152, 0.9035, 0.9123, **Epoch: 170
0.8984, 0.8980, 0.8993, 0.8839, 0.8960, 0.8830, 0.8884, 0.8850, 0.8878, 0.8821, **Epoch: 180
0.8885, 0.8879, 0.8758, 0.8650, 0.8780, 0.8775, 0.8776, 0.8727, 0.8706, 0.8766, **Epoch: 190
0.8751, 0.8553, 0.8679, 0.8746, 0.8641, 0.8651, 0.8615, 0.8499, 0.8661, 0.8648, **Epoch: 200
Training Accuracy: 
0.4741, 0.5889, 0.6074, 0.6519, 0.7037, 0.7296, 0.7556, 0.7593, 0.8074, 0.7815, **Epoch: 10
0.7704, 0.7852, 0.7630, 0.7481, 0.7481, 0.7481, 0.7259, 0.7370, 0.7296, 0.7259, **Epoch: 20
0.6963, 0.7185, 0.7148, 0.7074, 0.7111, 0.7259, 0.7333, 0.7148, 0.7074, 0.7444, **Epoch: 30
0.7333, 0.7370, 0.7296, 0.7370, 0.7259, 0.7407, 0.7259, 0.7556, 0.7333, 0.7519, **Epoch: 40
0.7630, 0.7704, 0.7259, 0.7704, 0.7778, 0.7704, 0.7704, 0.7926, 0.7926, 0.8111, **Epoch: 50
0.7926, 0.8074, 0.7926, 0.8222, 0.8000, 0.8037, 0.8185, 0.8148, 0.8148, 0.8185, **Epoch: 60
0.8074, 0.8185, 0.8222, 0.8259, 0.8296, 0.8111, 0.8074, 0.8148, 0.8259, 0.8370, **Epoch: 70
0.8222, 0.8296, 0.8111, 0.8259, 0.8296, 0.8222, 0.8333, 0.8296, 0.8259, 0.8333, **Epoch: 80
0.8333, 0.8333, 0.8333, 0.8296, 0.8333, 0.8519, 0.8556, 0.8296, 0.8370, 0.8481, **Epoch: 90
0.8370, 0.8519, 0.8593, 0.8444, 0.8519, 0.8333, 0.8444, 0.8630, 0.8593, 0.8444, **Epoch: 100
0.8593, 0.8815, 0.8704, 0.8778, 0.8630, 0.8815, 0.8778, 0.8778, 0.8778, 0.9037, **Epoch: 110
0.8815, 0.8889, 0.8963, 0.9000, 0.8852, 0.8852, 0.9000, 0.8926, 0.9037, 0.9222, **Epoch: 120
0.9074, 0.9111, 0.8926, 0.9185, 0.9111, 0.9185, 0.9185, 0.9259, 0.9000, 0.9037, **Epoch: 130
0.8926, 0.8889, 0.9222, 0.9074, 0.9148, 0.9222, 0.9037, 0.9074, 0.9296, 0.8926, **Epoch: 140
0.9407, 0.9074, 0.9074, 0.9111, 0.9333, 0.9222, 0.9222, 0.9185, 0.9148, 0.9185, **Epoch: 150
0.9148, 0.9296, 0.9185, 0.9370, 0.9370, 0.9259, 0.9444, 0.9370, 0.9370, 0.9333, **Epoch: 160
0.9222, 0.9444, 0.9556, 0.9519, 0.9296, 0.9333, 0.9333, 0.9444, 0.9407, 0.9444, **Epoch: 170
0.9333, 0.9333, 0.9481, 0.9444, 0.9519, 0.9444, 0.9481, 0.9481, 0.9333, 0.9370, **Epoch: 180
0.9407, 0.9407, 0.9444, 0.9259, 0.9444, 0.9296, 0.9556, 0.9333, 0.9519, 0.9519, **Epoch: 190
0.9370, 0.9481, 0.9407, 0.9481, 0.9481, 0.9481, 0.9519, 0.9370, 0.9481, 0.9556, **Epoch: 200
Validation Accuracy: 
0.3752, 0.4756, 0.4911, 0.5207, 0.5465, 0.5753, 0.5982, 0.6160, 0.6167, 0.6196, **Epoch: 10
0.6034, 0.6137, 0.5938, 0.5842, 0.5835, 0.5871, 0.5731, 0.5746, 0.5761, 0.5739, **Epoch: 20
0.5775, 0.5739, 0.5761, 0.5613, 0.5716, 0.5665, 0.5768, 0.5783, 0.5746, 0.5827, **Epoch: 30
0.5775, 0.5739, 0.5916, 0.5938, 0.5901, 0.5894, 0.5938, 0.6049, 0.6056, 0.6100, **Epoch: 40
0.6152, 0.6174, 0.6278, 0.6278, 0.6411, 0.6315, 0.6499, 0.6470, 0.6588, 0.6558, **Epoch: 50
0.6617, 0.6691, 0.6691, 0.6795, 0.6765, 0.6824, 0.6928, 0.6950, 0.6942, 0.6972, **Epoch: 60
0.7046, 0.6979, 0.7024, 0.7053, 0.7053, 0.7001, 0.7083, 0.7090, 0.7061, 0.7134, **Epoch: 70
0.7090, 0.7201, 0.7164, 0.7230, 0.7245, 0.7201, 0.7164, 0.7223, 0.7267, 0.7171, **Epoch: 80
0.7142, 0.7356, 0.7253, 0.7386, 0.7312, 0.7304, 0.7282, 0.7312, 0.7422, 0.7312, **Epoch: 90
0.7393, 0.7282, 0.7371, 0.7319, 0.7297, 0.7275, 0.7378, 0.7378, 0.7356, 0.7356, **Epoch: 100
0.7393, 0.7356, 0.7371, 0.7386, 0.7459, 0.7459, 0.7386, 0.7445, 0.7489, 0.7526, **Epoch: 110
0.7511, 0.7452, 0.7459, 0.7474, 0.7592, 0.7482, 0.7541, 0.7533, 0.7585, 0.7563, **Epoch: 120
0.7578, 0.7592, 0.7681, 0.7651, 0.7747, 0.7747, 0.7651, 0.7651, 0.7666, 0.7777, **Epoch: 130
0.7725, 0.7740, 0.7725, 0.7747, 0.7681, 0.7725, 0.7718, 0.7836, 0.7821, 0.7910, **Epoch: 140
0.7873, 0.7895, 0.7873, 0.7777, 0.7880, 0.7969, 0.7851, 0.7932, 0.7866, 0.7917, **Epoch: 150
0.7895, 0.7843, 0.7939, 0.7895, 0.7873, 0.7903, 0.7917, 0.7947, 0.7895, 0.7873, **Epoch: 160
0.7939, 0.7910, 0.7947, 0.8013, 0.7976, 0.8080, 0.8043, 0.8021, 0.8050, 0.7939, **Epoch: 170
0.8050, 0.7976, 0.7939, 0.7954, 0.7999, 0.8043, 0.8080, 0.7925, 0.8028, 0.8072, **Epoch: 180
0.7954, 0.8021, 0.8021, 0.8058, 0.8035, 0.8058, 0.8013, 0.7999, 0.8117, 0.8102, **Epoch: 190
0.8006, 0.8124, 0.8050, 0.8095, 0.8006, 0.7984, 0.8050, 0.7999, 0.8131, 0.8117, **Epoch: 200
Learning rate: 0.01
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1454
Training Loss: 
1.9464, 1.9309, 1.9042, 1.8725, 1.8337, 1.7917, 1.7334, 1.6987, 1.6432, 1.5911, **Epoch: 10
1.5361, 1.4574, 1.4230, 1.3729, 1.3256, 1.2445, 1.2184, 1.1717, 1.1285, 1.0756, **Epoch: 20
1.0453, 0.9950, 0.9821, 0.9197, 0.9410, 0.8964, 0.8395, 0.8503, 0.8007, 0.8008, **Epoch: 30
0.7811, 0.7309, 0.7209, 0.7105, 0.6789, 0.6711, 0.6748, 0.6627, 0.6337, 0.6314, **Epoch: 40
0.5873, 0.6055, 0.5700, 0.5764, 0.5648, 0.5393, 0.5559, 0.5367, 0.5405, 0.5303, **Epoch: 50
0.5167, 0.4780, 0.5103, 0.4834, 0.4587, 0.4550, 0.4557, 0.4881, 0.4348, 0.4302, **Epoch: 60
0.4088, 0.4406, 0.4001, 0.4109, 0.3985, 0.4219, 0.4332, 0.4227, 0.4175, 0.4024, **Epoch: 70
0.3775, 0.3700, 0.3947, 0.3765, 0.3950, 0.3811, 0.3869, 0.3836, 0.3658, 0.3611, **Epoch: 80
0.3612, 0.3777, 0.3668, 0.3700, 0.3688, 0.3461, 0.3657, 0.3730, 0.3366, 0.3428, **Epoch: 90
0.3631, 0.3903, 0.3412, 0.3861, 0.3568, 0.3603, 0.3765, 0.3450, 0.3438, 0.3533, **Epoch: 100
0.3622, 0.3892, 0.3488, 0.3586, 0.3595, 0.3405, 0.3633, 0.3479, 0.3690, 0.3387, **Epoch: 110
0.3735, 0.3848, 0.3458, 0.3371, 0.3594, 0.3558, 0.3746, 0.3689, 0.4014, 0.3446, **Epoch: 120
0.3306, 0.3701, 0.3575, 0.3668, 0.3570, 0.3750, 0.3642, 0.3247, 0.3521, 0.3855, **Epoch: 130
0.3778, 0.3540, 0.3643, 0.3675, 0.3756, 0.3689, 0.3699, 0.3568, 0.3658, 0.3347, **Epoch: 140
0.3616, 0.3549, 0.3850, 0.3601, 0.3582, 0.3572, 0.4027, 0.3643, 0.3520, 0.3521, **Epoch: 150
0.3697, 0.3544, 0.3664, 0.3742, 0.3439, 0.3693, 0.3837, 0.3441, 0.3659, 0.3519, **Epoch: 160
0.3751, 0.3576, 0.3513, 0.3697, 0.3323, 0.3222, 0.3671, 0.3675, 0.3828, 0.3552, **Epoch: 170
0.3658, 0.3933, 0.3520, 0.3522, 0.4113, 0.3349, 0.3601, 0.3506, 0.3626, 0.3545, **Epoch: 180
0.3597, 0.3437, 0.3581, 0.3710, 0.3354, 0.3401, 0.3795, 0.3570, 0.3440, 0.3730, **Epoch: 190
0.3727, 0.3720, 0.3756, 0.4090, 0.3628, 0.3677, 0.3630, 0.3860, 0.3869, 0.3855, **Epoch: 200
Validation Loss: 
1.9333, 1.9113, 1.8826, 1.8536, 1.8149, 1.7840, 1.7370, 1.7020, 1.6586, 1.6228, **Epoch: 10
1.5870, 1.5383, 1.4958, 1.4575, 1.4234, 1.3894, 1.3512, 1.3174, 1.2933, 1.2656, **Epoch: 20
1.2432, 1.2232, 1.1894, 1.1615, 1.1426, 1.1283, 1.1043, 1.0945, 1.0662, 1.0588, **Epoch: 30
1.0460, 1.0359, 1.0065, 0.9887, 0.9741, 0.9714, 0.9701, 0.9554, 0.9348, 0.9260, **Epoch: 40
0.9170, 0.9124, 0.8883, 0.8823, 0.8760, 0.8761, 0.8686, 0.8574, 0.8435, 0.8486, **Epoch: 50
0.8255, 0.8338, 0.8187, 0.8117, 0.8073, 0.7997, 0.8121, 0.8042, 0.7879, 0.7835, **Epoch: 60
0.7969, 0.7960, 0.7893, 0.7748, 0.7834, 0.7693, 0.7683, 0.7652, 0.7567, 0.7508, **Epoch: 70
0.7557, 0.7610, 0.7469, 0.7341, 0.7393, 0.7273, 0.7427, 0.7488, 0.7418, 0.7373, **Epoch: 80
0.7463, 0.7455, 0.7409, 0.7468, 0.7561, 0.7454, 0.7361, 0.7381, 0.7490, 0.7338, **Epoch: 90
0.7380, 0.7314, 0.7377, 0.7345, 0.7445, 0.7329, 0.7352, 0.7304, 0.7340, 0.7320, **Epoch: 100
0.7580, 0.7369, 0.7420, 0.7237, 0.7257, 0.7402, 0.7464, 0.7388, 0.7380, 0.7424, **Epoch: 110
0.7351, 0.7450, 0.7343, 0.7441, 0.7385, 0.7312, 0.7366, 0.7448, 0.7469, 0.7400, **Epoch: 120
0.7361, 0.7492, 0.7396, 0.7447, 0.7235, 0.7479, 0.7219, 0.7470, 0.7368, 0.7324, **Epoch: 130
0.7420, 0.7460, 0.7434, 0.7377, 0.7528, 0.7418, 0.7447, 0.7521, 0.7359, 0.7343, **Epoch: 140
0.7182, 0.7539, 0.7364, 0.7342, 0.7444, 0.7384, 0.7298, 0.7503, 0.7388, 0.7460, **Epoch: 150
0.7290, 0.7391, 0.7439, 0.7312, 0.7381, 0.7425, 0.7320, 0.7451, 0.7393, 0.7360, **Epoch: 160
0.7289, 0.7354, 0.7372, 0.7323, 0.7378, 0.7384, 0.7298, 0.7468, 0.7206, 0.7394, **Epoch: 170
0.7262, 0.7382, 0.7272, 0.7310, 0.7472, 0.7216, 0.7360, 0.7721, 0.7359, 0.7410, **Epoch: 180
0.7327, 0.7421, 0.7509, 0.7295, 0.7326, 0.7338, 0.7360, 0.7521, 0.7301, 0.7365, **Epoch: 190
0.7294, 0.7382, 0.7377, 0.7377, 0.7406, 0.7312, 0.7288, 0.7337, 0.7258, 0.7452, **Epoch: 200
Training Accuracy: 
0.3185, 0.3000, 0.2852, 0.2926, 0.3037, 0.3185, 0.3444, 0.3778, 0.4037, 0.4704, **Epoch: 10
0.5630, 0.6481, 0.7222, 0.7407, 0.7444, 0.7556, 0.7778, 0.7852, 0.8000, 0.8000, **Epoch: 20
0.8111, 0.8111, 0.8037, 0.8222, 0.8185, 0.8222, 0.8296, 0.8333, 0.8370, 0.8370, **Epoch: 30
0.8259, 0.8481, 0.8333, 0.8556, 0.8556, 0.8704, 0.8852, 0.8852, 0.8815, 0.8852, **Epoch: 40
0.9074, 0.9111, 0.9148, 0.9185, 0.9111, 0.9222, 0.9444, 0.9259, 0.9259, 0.9481, **Epoch: 50
0.9296, 0.9370, 0.9407, 0.9370, 0.9296, 0.9481, 0.9370, 0.9407, 0.9407, 0.9222, **Epoch: 60
0.9630, 0.9556, 0.9556, 0.9519, 0.9519, 0.9519, 0.9556, 0.9593, 0.9519, 0.9593, **Epoch: 70
0.9667, 0.9630, 0.9519, 0.9556, 0.9630, 0.9481, 0.9593, 0.9704, 0.9667, 0.9593, **Epoch: 80
0.9667, 0.9741, 0.9667, 0.9741, 0.9556, 0.9519, 0.9407, 0.9667, 0.9704, 0.9593, **Epoch: 90
0.9556, 0.9630, 0.9519, 0.9556, 0.9593, 0.9519, 0.9741, 0.9556, 0.9519, 0.9556, **Epoch: 100
0.9519, 0.9630, 0.9593, 0.9630, 0.9556, 0.9556, 0.9407, 0.9556, 0.9593, 0.9667, **Epoch: 110
0.9556, 0.9519, 0.9667, 0.9630, 0.9481, 0.9593, 0.9630, 0.9667, 0.9593, 0.9556, **Epoch: 120
0.9630, 0.9556, 0.9667, 0.9593, 0.9778, 0.9593, 0.9444, 0.9519, 0.9741, 0.9519, **Epoch: 130
0.9630, 0.9630, 0.9667, 0.9593, 0.9630, 0.9667, 0.9593, 0.9593, 0.9481, 0.9556, **Epoch: 140
0.9741, 0.9741, 0.9704, 0.9630, 0.9444, 0.9630, 0.9444, 0.9704, 0.9741, 0.9630, **Epoch: 150
0.9741, 0.9593, 0.9519, 0.9593, 0.9519, 0.9778, 0.9667, 0.9556, 0.9704, 0.9704, **Epoch: 160
0.9593, 0.9704, 0.9630, 0.9667, 0.9704, 0.9667, 0.9519, 0.9630, 0.9704, 0.9704, **Epoch: 170
0.9593, 0.9630, 0.9519, 0.9519, 0.9704, 0.9741, 0.9556, 0.9481, 0.9593, 0.9593, **Epoch: 180
0.9593, 0.9556, 0.9593, 0.9481, 0.9556, 0.9556, 0.9556, 0.9630, 0.9556, 0.9741, **Epoch: 190
0.9556, 0.9667, 0.9481, 0.9593, 0.9556, 0.9630, 0.9519, 0.9519, 0.9704, 0.9630, **Epoch: 200
Validation Accuracy: 
0.3272, 0.3191, 0.3183, 0.3198, 0.3220, 0.3316, 0.3449, 0.3619, 0.3936, 0.4424, **Epoch: 10
0.4970, 0.5576, 0.5953, 0.6307, 0.6411, 0.6566, 0.6677, 0.6691, 0.6677, 0.6736, **Epoch: 20
0.6802, 0.6898, 0.7016, 0.6994, 0.7068, 0.7061, 0.6987, 0.7031, 0.7024, 0.7194, **Epoch: 30
0.7171, 0.7061, 0.7282, 0.7223, 0.7267, 0.7290, 0.7326, 0.7393, 0.7349, 0.7437, **Epoch: 40
0.7541, 0.7496, 0.7511, 0.7585, 0.7688, 0.7755, 0.7814, 0.7770, 0.7770, 0.7821, **Epoch: 50
0.7829, 0.7873, 0.7880, 0.7888, 0.7991, 0.7954, 0.7954, 0.8087, 0.8013, 0.8043, **Epoch: 60
0.8072, 0.8006, 0.8102, 0.8198, 0.8072, 0.8095, 0.8058, 0.8117, 0.8131, 0.8154, **Epoch: 70
0.8139, 0.8146, 0.8124, 0.7984, 0.8087, 0.8035, 0.8154, 0.8102, 0.8124, 0.8154, **Epoch: 80
0.8109, 0.8058, 0.8006, 0.8095, 0.8065, 0.8080, 0.8146, 0.8131, 0.7999, 0.8095, **Epoch: 90
0.8102, 0.7976, 0.8117, 0.8102, 0.7999, 0.8131, 0.8183, 0.8117, 0.8117, 0.7962, **Epoch: 100
0.8072, 0.8043, 0.8139, 0.8080, 0.8050, 0.8124, 0.8109, 0.8087, 0.8050, 0.8117, **Epoch: 110
0.8050, 0.8095, 0.8183, 0.8102, 0.8131, 0.8080, 0.8080, 0.8013, 0.8227, 0.8139, **Epoch: 120
0.8109, 0.8072, 0.8058, 0.8006, 0.8050, 0.8043, 0.8198, 0.8124, 0.8154, 0.8154, **Epoch: 130
0.8161, 0.8131, 0.8072, 0.8087, 0.8264, 0.7969, 0.8087, 0.8102, 0.8154, 0.8183, **Epoch: 140
0.8028, 0.8080, 0.8087, 0.8035, 0.8146, 0.8124, 0.8124, 0.8198, 0.8117, 0.8146, **Epoch: 150
0.8109, 0.8050, 0.8035, 0.8139, 0.8117, 0.8102, 0.8131, 0.8065, 0.8117, 0.8161, **Epoch: 160
0.8131, 0.8072, 0.8131, 0.8080, 0.8183, 0.8035, 0.8168, 0.8095, 0.8095, 0.8102, **Epoch: 170
0.8065, 0.8146, 0.8176, 0.8109, 0.8095, 0.8080, 0.8139, 0.8154, 0.8043, 0.8183, **Epoch: 180
0.8146, 0.8124, 0.8095, 0.8117, 0.8183, 0.8146, 0.8102, 0.8183, 0.8050, 0.8279, **Epoch: 190
0.8146, 0.8124, 0.8198, 0.8095, 0.8021, 0.8095, 0.8117, 0.8058, 0.8035, 0.8154, **Epoch: 200
Learning rate: 0.05
Weight decay: 0.0005
Drop rate: 0.2
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1456
Training Loss: 
1.9462, 1.9411, 1.9304, 1.9220, 1.9067, 1.8889, 1.8692, 1.8529, 1.8231, 1.7933, **Epoch: 10
1.7713, 1.7439, 1.7150, 1.6822, 1.6621, 1.6255, 1.5919, 1.5722, 1.5533, 1.5010, **Epoch: 20
1.5117, 1.5012, 1.4903, 1.4146, 1.4250, 1.3606, 1.3412, 1.3456, 1.3419, 1.3535, **Epoch: 30
1.2935, 1.2516, 1.2438, 1.2308, 1.2426, 1.2309, 1.2378, 1.2087, 1.1598, 1.1779, **Epoch: 40
1.1427, 1.1570, 1.1140, 1.1132, 1.1079, 1.0838, 1.0661, 1.0751, 1.0329, 1.0278, **Epoch: 50
1.0476, 1.0453, 1.0093, 1.0038, 1.0019, 0.9576, 0.9354, 1.0011, 0.9978, 1.0042, **Epoch: 60
0.9228, 0.9251, 0.9467, 0.9643, 0.9471, 0.9349, 0.9200, 0.9053, 0.9384, 0.9489, **Epoch: 70
0.8939, 0.8865, 0.9042, 0.8662, 0.8553, 0.8622, 0.9044, 0.8228, 0.8514, 0.8456, **Epoch: 80
0.8299, 0.8701, 0.8446, 0.8290, 0.8378, 0.8511, 0.8462, 0.7933, 0.7849, 0.8315, **Epoch: 90
0.7880, 0.8393, 0.8248, 0.8081, 0.8410, 0.8352, 0.8207, 0.8381, 0.8105, 0.8127, **Epoch: 100
0.7837, 0.8306, 0.8209, 0.8139, 0.8482, 0.8016, 0.8049, 0.8349, 0.8233, 0.8278, **Epoch: 110
0.8148, 0.8161, 0.7673, 0.8355, 0.8517, 0.8174, 0.8175, 0.8188, 0.8165, 0.8161, **Epoch: 120
0.7938, 0.8185, 0.8586, 0.8181, 0.8203, 0.8143, 0.8132, 0.8077, 0.7859, 0.8192, **Epoch: 130
0.8340, 0.7696, 0.8266, 0.8058, 0.7992, 0.7982, 0.8103, 0.8203, 0.7754, 0.7687, **Epoch: 140
0.8185, 0.8032, 0.8131, 0.8131, 0.7825, 0.8310, 0.7887, 0.8309, 0.8268, 0.8191, **Epoch: 150
0.8234, 0.8055, 0.8200, 0.8077, 0.7717, 0.8007, 0.8213, 0.7758, 0.8169, 0.8595, **Epoch: 160
0.7884, 0.8449, 0.7569, 0.7880, 0.8292, 0.8099, 0.8021, 0.8324, 0.8032, 0.7991, **Epoch: 170
0.8301, 0.8767, 0.8413, 0.7737, 0.8429, 0.7820, 0.7949, 0.7644, 0.7858, 0.8286, **Epoch: 180
0.7678, 0.8162, 0.8508, 0.7826, 0.7778, 0.7846, 0.7979, 0.8100, 0.7837, 0.8739, **Epoch: 190
0.7745, 0.8844, 0.8214, 0.7756, 0.8544, 0.7982, 0.8253, 0.8734, 0.7895, 0.7967, **Epoch: 200
Validation Loss: 
1.9427, 1.9358, 1.9266, 1.9152, 1.9033, 1.8884, 1.8728, 1.8537, 1.8317, 1.8082, **Epoch: 10
1.7866, 1.7649, 1.7399, 1.7207, 1.6989, 1.6744, 1.6561, 1.6312, 1.6103, 1.5970, **Epoch: 20
1.5846, 1.5578, 1.5451, 1.5425, 1.5039, 1.4947, 1.4731, 1.4764, 1.4576, 1.4441, **Epoch: 30
1.4283, 1.4193, 1.3924, 1.3678, 1.3849, 1.3556, 1.3498, 1.3365, 1.3293, 1.3298, **Epoch: 40
1.3088, 1.3132, 1.2924, 1.2990, 1.2844, 1.2701, 1.2640, 1.2589, 1.2387, 1.2373, **Epoch: 50
1.2229, 1.2086, 1.2196, 1.2210, 1.2235, 1.2106, 1.1927, 1.1427, 1.1796, 1.1733, **Epoch: 60
1.1645, 1.1793, 1.1738, 1.1551, 1.1423, 1.1615, 1.1201, 1.1327, 1.1588, 1.1406, **Epoch: 70
1.0963, 1.1346, 1.1037, 1.0936, 1.1021, 1.0945, 1.1086, 1.0627, 1.1092, 1.0838, **Epoch: 80
1.0978, 1.0906, 1.0826, 1.0661, 1.0611, 1.1092, 1.0808, 1.0741, 1.0728, 1.0662, **Epoch: 90
1.0771, 1.0710, 1.0560, 1.0865, 1.0648, 1.0794, 1.0849, 1.0638, 1.0730, 1.0593, **Epoch: 100
1.0479, 1.0771, 1.0718, 1.0693, 1.0731, 1.0500, 1.0789, 1.0688, 1.0534, 1.0517, **Epoch: 110
1.0624, 1.0686, 1.0585, 1.0615, 1.0455, 1.0666, 1.0857, 1.0490, 1.0844, 1.0735, **Epoch: 120
1.0591, 1.0474, 1.0748, 1.0637, 1.0512, 1.0647, 1.0728, 1.0570, 1.0703, 1.0570, **Epoch: 130
1.0617, 1.0620, 1.0808, 1.0767, 1.0725, 1.0442, 1.0685, 1.0707, 1.0544, 1.0564, **Epoch: 140
1.0669, 1.0754, 1.0958, 1.0620, 1.0626, 1.0764, 1.0612, 1.0759, 1.0679, 1.0656, **Epoch: 150
1.0547, 1.0637, 1.0723, 1.0956, 1.0560, 1.0519, 1.0712, 1.0678, 1.0797, 1.0706, **Epoch: 160
1.0579, 1.0636, 1.0943, 1.0498, 1.0300, 1.0571, 1.0929, 1.0835, 1.0793, 1.0429, **Epoch: 170
1.0771, 1.0699, 1.0543, 1.0707, 1.0703, 1.0766, 1.0672, 1.0627, 1.0518, 1.0598, **Epoch: 180
1.0534, 1.0708, 1.0849, 1.0609, 1.0745, 1.0497, 1.0349, 1.0790, 1.0690, 1.0479, **Epoch: 190
1.0592, 1.0466, 1.0757, 1.0492, 1.0701, 1.0736, 1.0646, 1.0544, 1.0910, 1.0456, **Epoch: 200
Training Accuracy: 
0.3481, 0.3037, 0.2630, 0.2667, 0.2963, 0.3185, 0.3296, 0.3444, 0.3963, 0.3963, **Epoch: 10
0.4296, 0.4407, 0.5185, 0.5037, 0.5222, 0.5519, 0.5370, 0.5741, 0.5963, 0.6000, **Epoch: 20
0.6111, 0.6630, 0.6185, 0.6222, 0.6185, 0.6370, 0.6593, 0.6963, 0.6667, 0.7111, **Epoch: 30
0.6593, 0.7037, 0.7000, 0.7222, 0.7185, 0.7037, 0.7519, 0.7519, 0.7593, 0.7296, **Epoch: 40
0.7222, 0.7519, 0.7111, 0.7407, 0.7815, 0.7704, 0.7667, 0.7481, 0.7704, 0.7519, **Epoch: 50
0.7519, 0.7667, 0.7667, 0.7667, 0.7630, 0.7852, 0.7667, 0.7963, 0.7704, 0.7963, **Epoch: 60
0.7852, 0.8000, 0.8000, 0.7926, 0.7852, 0.7778, 0.7889, 0.7667, 0.8111, 0.8037, **Epoch: 70
0.8074, 0.7926, 0.8333, 0.7963, 0.8111, 0.7667, 0.8296, 0.8370, 0.8074, 0.8037, **Epoch: 80
0.8185, 0.8185, 0.8037, 0.8481, 0.8148, 0.8222, 0.8074, 0.8185, 0.8185, 0.8370, **Epoch: 90
0.8259, 0.8333, 0.8370, 0.8074, 0.8481, 0.8111, 0.8148, 0.8074, 0.8296, 0.8000, **Epoch: 100
0.8444, 0.8185, 0.8519, 0.8222, 0.8000, 0.7963, 0.8111, 0.8222, 0.8037, 0.8259, **Epoch: 110
0.8037, 0.8481, 0.8222, 0.8111, 0.8185, 0.8333, 0.8407, 0.8111, 0.8370, 0.8370, **Epoch: 120
0.8444, 0.8519, 0.8037, 0.8000, 0.8296, 0.8111, 0.8037, 0.8407, 0.8259, 0.8370, **Epoch: 130
0.8296, 0.8333, 0.8000, 0.8296, 0.8296, 0.8259, 0.8407, 0.8111, 0.8407, 0.8370, **Epoch: 140
0.8370, 0.8333, 0.8185, 0.8074, 0.8185, 0.8370, 0.8185, 0.8407, 0.8333, 0.8000, **Epoch: 150
0.8333, 0.8370, 0.7889, 0.8185, 0.8222, 0.8148, 0.8185, 0.8370, 0.8519, 0.8111, **Epoch: 160
0.8111, 0.8333, 0.8037, 0.8444, 0.8407, 0.8259, 0.8222, 0.8370, 0.8259, 0.8259, **Epoch: 170
0.8296, 0.8407, 0.8148, 0.8259, 0.8148, 0.8148, 0.8296, 0.8222, 0.8370, 0.7963, **Epoch: 180
0.8148, 0.8333, 0.8074, 0.8296, 0.8556, 0.8519, 0.8259, 0.8407, 0.8148, 0.8370, **Epoch: 190
0.8481, 0.8333, 0.8259, 0.8222, 0.8185, 0.8222, 0.8333, 0.8000, 0.8111, 0.8222, **Epoch: 200
Validation Accuracy: 
0.2496, 0.2157, 0.1913, 0.2001, 0.2149, 0.2290, 0.2408, 0.2710, 0.2843, 0.3242, **Epoch: 10
0.3560, 0.3744, 0.4254, 0.4542, 0.4823, 0.4852, 0.5118, 0.5177, 0.5295, 0.5391, **Epoch: 20
0.5384, 0.5606, 0.5480, 0.5532, 0.5657, 0.5650, 0.5665, 0.5864, 0.5908, 0.5916, **Epoch: 30
0.5990, 0.5960, 0.6137, 0.6034, 0.6078, 0.6049, 0.6145, 0.6337, 0.6359, 0.6307, **Epoch: 40
0.6381, 0.6285, 0.6292, 0.6440, 0.6551, 0.6551, 0.6617, 0.6558, 0.6654, 0.6581, **Epoch: 50
0.6499, 0.6691, 0.6706, 0.6566, 0.6691, 0.6743, 0.6728, 0.6854, 0.6773, 0.6758, **Epoch: 60
0.6765, 0.6662, 0.6721, 0.6743, 0.6758, 0.6854, 0.6765, 0.6883, 0.6647, 0.6935, **Epoch: 70
0.6891, 0.6898, 0.6869, 0.6965, 0.7134, 0.6942, 0.6979, 0.7024, 0.6979, 0.7016, **Epoch: 80
0.6957, 0.6891, 0.7046, 0.7031, 0.6898, 0.7120, 0.7171, 0.7038, 0.7075, 0.7186, **Epoch: 90
0.7194, 0.7016, 0.7090, 0.7046, 0.7016, 0.7179, 0.7046, 0.7142, 0.7083, 0.7097, **Epoch: 100
0.7120, 0.7053, 0.7031, 0.7090, 0.7083, 0.7075, 0.7105, 0.7179, 0.7179, 0.7149, **Epoch: 110
0.7046, 0.7075, 0.7134, 0.7149, 0.6957, 0.7031, 0.7016, 0.7216, 0.7171, 0.7053, **Epoch: 120
0.7142, 0.7009, 0.7068, 0.7134, 0.7201, 0.7031, 0.7090, 0.7230, 0.7038, 0.7097, **Epoch: 130
0.7164, 0.7024, 0.6957, 0.7016, 0.7142, 0.7134, 0.7297, 0.7024, 0.7112, 0.7061, **Epoch: 140
0.7001, 0.7061, 0.7112, 0.7245, 0.7134, 0.6965, 0.7105, 0.7024, 0.7164, 0.7127, **Epoch: 150
0.7134, 0.7024, 0.7031, 0.7046, 0.7068, 0.7127, 0.7179, 0.7083, 0.7038, 0.7024, **Epoch: 160
0.7105, 0.6972, 0.7038, 0.7201, 0.7134, 0.7068, 0.7038, 0.6965, 0.6972, 0.6891, **Epoch: 170
0.7001, 0.7179, 0.7038, 0.7090, 0.7075, 0.7120, 0.7208, 0.7061, 0.6994, 0.7090, **Epoch: 180
0.6994, 0.7127, 0.7090, 0.6905, 0.7097, 0.7016, 0.7083, 0.6979, 0.7157, 0.7061, **Epoch: 190
0.7046, 0.7201, 0.6905, 0.6965, 0.7031, 0.7024, 0.7097, 0.7038, 0.7260, 0.7009, **Epoch: 200
Learning rate: 0.05
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1456
Training Loss: 
1.9460, 1.9320, 1.9083, 1.8760, 1.8446, 1.7946, 1.7500, 1.6972, 1.6645, 1.6089, **Epoch: 10
1.5559, 1.5019, 1.4393, 1.4082, 1.3546, 1.3142, 1.3138, 1.2556, 1.1736, 1.1984, **Epoch: 20
1.1192, 1.0906, 1.0793, 1.0746, 1.0491, 1.0342, 1.0083, 1.0006, 0.9524, 0.9495, **Epoch: 30
0.9744, 0.9468, 0.9551, 0.9202, 0.8668, 0.8649, 0.9100, 0.8262, 0.8830, 0.8561, **Epoch: 40
0.8596, 0.8073, 0.8201, 0.7994, 0.8406, 0.8098, 0.7931, 0.7865, 0.8041, 0.7406, **Epoch: 50
0.7844, 0.8071, 0.7451, 0.7659, 0.7342, 0.7711, 0.7609, 0.7494, 0.7091, 0.7515, **Epoch: 60
0.7091, 0.7624, 0.7362, 0.7451, 0.7319, 0.7339, 0.6883, 0.7155, 0.7755, 0.6732, **Epoch: 70
0.7386, 0.7130, 0.6910, 0.7137, 0.7382, 0.7023, 0.7385, 0.6841, 0.7495, 0.7551, **Epoch: 80
0.7104, 0.7830, 0.7346, 0.7055, 0.7207, 0.7102, 0.7066, 0.7432, 0.6347, 0.7026, **Epoch: 90
0.6759, 0.7559, 0.7500, 0.7255, 0.6466, 0.6636, 0.7490, 0.6506, 0.7023, 0.7380, **Epoch: 100
0.7046, 0.6989, 0.6902, 0.7221, 0.7029, 0.6866, 0.7065, 0.7010, 0.7250, 0.6874, **Epoch: 110
0.7055, 0.6320, 0.7189, 0.6915, 0.7595, 0.6764, 0.7818, 0.6840, 0.6651, 0.7073, **Epoch: 120
0.6677, 0.6934, 0.7231, 0.7232, 0.7224, 0.6877, 0.7006, 0.7125, 0.6836, 0.7235, **Epoch: 130
0.6898, 0.6992, 0.6839, 0.7188, 0.6984, 0.7334, 0.7314, 0.7252, 0.7074, 0.6762, **Epoch: 140
0.7075, 0.7186, 0.6892, 0.7051, 0.7181, 0.6943, 0.7070, 0.7506, 0.6931, 0.6746, **Epoch: 150
0.6891, 0.6732, 0.6945, 0.7000, 0.7095, 0.6468, 0.6817, 0.6822, 0.7022, 0.6775, **Epoch: 160
0.7298, 0.7388, 0.7203, 0.6753, 0.6844, 0.7230, 0.6970, 0.6873, 0.6993, 0.7164, **Epoch: 170
0.7318, 0.6816, 0.7104, 0.7201, 0.7458, 0.6733, 0.6906, 0.6693, 0.7256, 0.7161, **Epoch: 180
0.6895, 0.7314, 0.6947, 0.7171, 0.7135, 0.6605, 0.7125, 0.6587, 0.6835, 0.6930, **Epoch: 190
0.6697, 0.6771, 0.6573, 0.7112, 0.7135, 0.7065, 0.6164, 0.6765, 0.7144, 0.6999, **Epoch: 200
Validation Loss: 
1.9310, 1.9102, 1.8820, 1.8484, 1.8201, 1.7757, 1.7382, 1.7036, 1.6686, 1.6267, **Epoch: 10
1.5857, 1.5647, 1.5274, 1.4702, 1.4549, 1.4406, 1.4146, 1.3667, 1.3490, 1.3360, **Epoch: 20
1.3244, 1.2866, 1.2627, 1.2546, 1.2543, 1.2377, 1.2231, 1.2090, 1.1996, 1.1706, **Epoch: 30
1.1804, 1.1742, 1.1484, 1.1493, 1.1491, 1.1368, 1.1197, 1.1114, 1.0995, 1.1328, **Epoch: 40
1.0725, 1.0863, 1.0752, 1.0616, 1.0805, 1.0448, 1.0596, 1.0661, 1.0598, 1.0334, **Epoch: 50
1.0354, 1.0219, 1.0289, 1.0188, 1.0141, 1.0044, 1.0328, 1.0149, 0.9944, 1.0210, **Epoch: 60
0.9882, 1.0148, 1.0203, 1.0276, 0.9887, 1.0070, 0.9946, 0.9827, 1.0030, 0.9725, **Epoch: 70
0.9927, 0.9875, 0.9856, 0.9954, 0.9909, 1.0035, 1.0072, 0.9826, 0.9714, 1.0098, **Epoch: 80
0.9801, 0.9743, 0.9871, 0.9808, 0.9831, 0.9824, 0.9732, 0.9937, 0.9650, 0.9614, **Epoch: 90
0.9741, 0.9789, 0.9701, 0.9808, 0.9897, 0.9660, 0.9834, 0.9662, 0.9965, 0.9644, **Epoch: 100
0.9858, 0.9692, 0.9743, 0.9853, 0.9650, 0.9809, 0.9917, 1.0000, 0.9605, 0.9881, **Epoch: 110
0.9769, 0.9827, 0.9888, 0.9717, 0.9863, 0.9972, 0.9704, 0.9905, 0.9953, 0.9656, **Epoch: 120
0.9720, 0.9830, 0.9749, 0.9726, 1.0073, 0.9732, 0.9914, 0.9989, 0.9697, 0.9783, **Epoch: 130
0.9807, 0.9733, 0.9759, 0.9691, 0.9777, 0.9966, 0.9669, 0.9868, 0.9704, 0.9819, **Epoch: 140
0.9623, 0.9712, 0.9805, 0.9838, 0.9945, 0.9609, 0.9930, 0.9934, 0.9910, 0.9735, **Epoch: 150
0.9665, 0.9591, 0.9874, 0.9771, 0.9577, 0.9693, 0.9780, 0.9869, 0.9892, 0.9808, **Epoch: 160
0.9548, 0.9642, 0.9917, 0.9618, 0.9899, 0.9862, 0.9654, 0.9706, 0.9903, 0.9930, **Epoch: 170
0.9767, 0.9946, 0.9918, 0.9846, 0.9749, 0.9840, 0.9904, 0.9886, 0.9797, 0.9561, **Epoch: 180
0.9932, 0.9986, 0.9690, 0.9849, 0.9849, 0.9738, 0.9952, 0.9628, 0.9704, 1.0044, **Epoch: 190
0.9853, 0.9909, 0.9858, 0.9783, 0.9690, 0.9438, 0.9869, 0.9488, 0.9778, 0.9546, **Epoch: 200
Training Accuracy: 
0.2852, 0.2370, 0.2556, 0.2630, 0.2778, 0.2630, 0.2704, 0.2963, 0.3111, 0.4185, **Epoch: 10
0.5111, 0.5704, 0.6593, 0.6667, 0.7222, 0.7111, 0.7407, 0.7333, 0.7444, 0.7481, **Epoch: 20
0.7296, 0.7704, 0.7333, 0.7741, 0.7630, 0.7556, 0.7667, 0.7370, 0.7704, 0.7667, **Epoch: 30
0.7926, 0.7667, 0.7741, 0.7741, 0.8074, 0.7519, 0.7852, 0.7630, 0.7889, 0.8185, **Epoch: 40
0.7926, 0.8185, 0.8000, 0.8296, 0.8185, 0.8148, 0.8148, 0.8333, 0.8444, 0.8185, **Epoch: 50
0.8519, 0.8630, 0.8444, 0.8333, 0.8630, 0.8556, 0.8481, 0.8407, 0.8370, 0.8556, **Epoch: 60
0.8667, 0.8481, 0.8370, 0.8519, 0.8593, 0.8519, 0.8704, 0.8815, 0.8556, 0.8778, **Epoch: 70
0.8667, 0.8852, 0.8556, 0.8852, 0.8815, 0.8815, 0.8926, 0.8481, 0.8481, 0.8407, **Epoch: 80
0.8815, 0.8852, 0.8667, 0.8556, 0.8815, 0.8667, 0.8481, 0.8630, 0.8778, 0.8741, **Epoch: 90
0.8593, 0.8778, 0.8778, 0.8630, 0.8630, 0.8667, 0.8556, 0.8630, 0.8815, 0.9037, **Epoch: 100
0.8963, 0.8667, 0.8630, 0.8963, 0.8556, 0.8444, 0.8778, 0.8704, 0.8630, 0.8593, **Epoch: 110
0.8593, 0.8963, 0.8741, 0.8889, 0.8741, 0.8667, 0.8519, 0.8815, 0.8556, 0.8889, **Epoch: 120
0.8593, 0.8852, 0.8704, 0.8741, 0.8593, 0.8741, 0.8593, 0.8778, 0.8815, 0.8963, **Epoch: 130
0.8741, 0.8778, 0.8963, 0.8519, 0.8556, 0.8741, 0.8519, 0.8778, 0.8630, 0.8519, **Epoch: 140
0.8741, 0.8889, 0.8852, 0.8519, 0.9000, 0.8704, 0.8963, 0.8852, 0.8444, 0.8926, **Epoch: 150
0.8556, 0.8889, 0.8815, 0.8741, 0.8741, 0.8778, 0.8556, 0.8741, 0.8889, 0.8667, **Epoch: 160
0.8778, 0.8407, 0.8926, 0.8778, 0.8519, 0.8926, 0.8519, 0.8852, 0.8741, 0.8296, **Epoch: 170
0.8481, 0.8704, 0.8778, 0.8630, 0.8815, 0.8593, 0.8963, 0.8667, 0.8630, 0.8741, **Epoch: 180
0.8704, 0.8667, 0.8741, 0.8852, 0.8667, 0.9000, 0.8963, 0.8704, 0.8667, 0.8593, **Epoch: 190
0.8519, 0.8889, 0.9037, 0.8593, 0.8667, 0.8889, 0.8444, 0.8926, 0.8667, 0.8667, **Epoch: 200
Validation Accuracy: 
0.3043, 0.3102, 0.2969, 0.3058, 0.2954, 0.2969, 0.2954, 0.3124, 0.3338, 0.4025, **Epoch: 10
0.4609, 0.5207, 0.5465, 0.5746, 0.6027, 0.6137, 0.6130, 0.6344, 0.6344, 0.6418, **Epoch: 20
0.6418, 0.6640, 0.6573, 0.6640, 0.6558, 0.6632, 0.6640, 0.6706, 0.6647, 0.6566, **Epoch: 30
0.6743, 0.6669, 0.6728, 0.6654, 0.6706, 0.6713, 0.6699, 0.6654, 0.6743, 0.6669, **Epoch: 40
0.6558, 0.6905, 0.6817, 0.6832, 0.7016, 0.6957, 0.7171, 0.6891, 0.7090, 0.7061, **Epoch: 50
0.7149, 0.7334, 0.7134, 0.7319, 0.7363, 0.7408, 0.7297, 0.7260, 0.7179, 0.7297, **Epoch: 60
0.7186, 0.7282, 0.7253, 0.7275, 0.7386, 0.7238, 0.7378, 0.7415, 0.7555, 0.7415, **Epoch: 70
0.7371, 0.7297, 0.7393, 0.7422, 0.7570, 0.7585, 0.7430, 0.7393, 0.7393, 0.7437, **Epoch: 80
0.7349, 0.7326, 0.7334, 0.7518, 0.7171, 0.7474, 0.7445, 0.7474, 0.7496, 0.7334, **Epoch: 90
0.7312, 0.7400, 0.7622, 0.7489, 0.7408, 0.7415, 0.7378, 0.7474, 0.7356, 0.7518, **Epoch: 100
0.7393, 0.7378, 0.7415, 0.7452, 0.7511, 0.7408, 0.7518, 0.7393, 0.7400, 0.7570, **Epoch: 110
0.7349, 0.7334, 0.7304, 0.7437, 0.7422, 0.7282, 0.7245, 0.7437, 0.7430, 0.7319, **Epoch: 120
0.7378, 0.7482, 0.7422, 0.7386, 0.7356, 0.7275, 0.7378, 0.7504, 0.7474, 0.7518, **Epoch: 130
0.7452, 0.7541, 0.7393, 0.7445, 0.7386, 0.7474, 0.7408, 0.7548, 0.7541, 0.7400, **Epoch: 140
0.7400, 0.7312, 0.7430, 0.7223, 0.7474, 0.7378, 0.7504, 0.7452, 0.7459, 0.7430, **Epoch: 150
0.7334, 0.7578, 0.7430, 0.7422, 0.7393, 0.7371, 0.7349, 0.7496, 0.7371, 0.7496, **Epoch: 160
0.7312, 0.7341, 0.7467, 0.7378, 0.7430, 0.7563, 0.7592, 0.7467, 0.7341, 0.7445, **Epoch: 170
0.7467, 0.7511, 0.7614, 0.7518, 0.7526, 0.7474, 0.7326, 0.7430, 0.7334, 0.7326, **Epoch: 180
0.7363, 0.7474, 0.7445, 0.7482, 0.7437, 0.7371, 0.7400, 0.7334, 0.7326, 0.7430, **Epoch: 190
0.7393, 0.7312, 0.7474, 0.7533, 0.7445, 0.7378, 0.7445, 0.7482, 0.7474, 0.7341, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1457
Training Loss: 
1.9457, 1.9313, 1.9081, 1.8801, 1.8417, 1.7908, 1.7475, 1.6823, 1.6276, 1.5934, **Epoch: 10
1.5512, 1.5180, 1.4757, 1.4118, 1.3598, 1.3794, 1.3106, 1.2667, 1.2449, 1.2555, **Epoch: 20
1.2117, 1.1659, 1.1841, 1.1590, 1.1292, 1.0933, 1.0716, 1.0417, 1.0128, 0.9727, **Epoch: 30
1.0115, 0.9541, 0.9866, 0.9475, 0.8981, 0.9286, 0.9426, 0.9033, 0.9229, 0.8579, **Epoch: 40
0.8887, 0.8778, 0.8463, 0.8475, 0.8357, 0.8331, 0.8195, 0.8280, 0.8262, 0.8463, **Epoch: 50
0.8237, 0.8293, 0.7893, 0.8036, 0.7565, 0.7493, 0.7887, 0.7576, 0.7433, 0.7858, **Epoch: 60
0.7828, 0.7562, 0.7246, 0.7393, 0.7637, 0.7183, 0.6878, 0.7064, 0.7454, 0.7749, **Epoch: 70
0.6960, 0.7205, 0.7156, 0.7255, 0.7003, 0.7310, 0.6781, 0.6513, 0.7364, 0.7452, **Epoch: 80
0.6948, 0.7220, 0.6929, 0.6609, 0.7169, 0.7494, 0.7145, 0.6759, 0.6726, 0.6992, **Epoch: 90
0.7388, 0.7075, 0.6686, 0.6743, 0.6860, 0.6738, 0.6911, 0.6730, 0.6968, 0.6848, **Epoch: 100
0.6911, 0.6342, 0.6768, 0.6908, 0.7088, 0.6864, 0.6757, 0.7070, 0.6764, 0.7506, **Epoch: 110
0.6573, 0.7401, 0.6605, 0.6961, 0.7225, 0.6683, 0.7020, 0.6497, 0.6551, 0.6768, **Epoch: 120
0.6680, 0.7325, 0.6662, 0.6966, 0.6986, 0.7227, 0.6192, 0.6702, 0.6647, 0.6768, **Epoch: 130
0.6892, 0.6210, 0.7046, 0.6982, 0.6592, 0.6372, 0.6529, 0.7078, 0.6830, 0.6881, **Epoch: 140
0.6550, 0.7241, 0.6909, 0.6646, 0.6701, 0.6765, 0.6939, 0.6859, 0.6595, 0.7010, **Epoch: 150
0.7034, 0.7027, 0.6727, 0.6397, 0.6965, 0.6615, 0.6549, 0.7044, 0.6794, 0.6929, **Epoch: 160
0.7398, 0.6832, 0.6939, 0.7404, 0.7314, 0.6687, 0.7251, 0.6588, 0.6714, 0.6827, **Epoch: 170
0.6314, 0.6430, 0.6889, 0.6493, 0.7348, 0.6577, 0.6485, 0.7044, 0.7082, 0.6561, **Epoch: 180
0.6675, 0.6363, 0.7446, 0.6753, 0.6743, 0.6568, 0.6589, 0.7019, 0.6924, 0.6915, **Epoch: 190
0.6954, 0.7010, 0.6697, 0.7024, 0.6643, 0.6871, 0.6839, 0.7609, 0.6814, 0.6861, **Epoch: 200
Validation Loss: 
1.9333, 1.9142, 1.8930, 1.8593, 1.8237, 1.7906, 1.7438, 1.6971, 1.6562, 1.6300, **Epoch: 10
1.5858, 1.5616, 1.5309, 1.5019, 1.4836, 1.4500, 1.4392, 1.4115, 1.3950, 1.3682, **Epoch: 20
1.3340, 1.3276, 1.3306, 1.3097, 1.2548, 1.2498, 1.2524, 1.2657, 1.2603, 1.2253, **Epoch: 30
1.2048, 1.1989, 1.1779, 1.1592, 1.1481, 1.1660, 1.1418, 1.1261, 1.1347, 1.1615, **Epoch: 40
1.1275, 1.1172, 1.1306, 1.1001, 1.0788, 1.0853, 1.1073, 1.0863, 1.0802, 1.0555, **Epoch: 50
1.0717, 1.0612, 1.0296, 1.0358, 1.0433, 1.0486, 1.0415, 1.0373, 0.9949, 1.0276, **Epoch: 60
1.0158, 1.0289, 1.0287, 1.0033, 1.0229, 1.0088, 1.0093, 0.9941, 0.9948, 0.9912, **Epoch: 70
1.0142, 1.0080, 1.0003, 1.0006, 0.9873, 0.9943, 0.9903, 0.9997, 0.9599, 0.9836, **Epoch: 80
0.9871, 0.9857, 0.9953, 0.9792, 0.9706, 0.9696, 0.9687, 0.9634, 0.9505, 0.9417, **Epoch: 90
0.9579, 0.9751, 1.0018, 0.9602, 0.9897, 0.9753, 0.9694, 0.9865, 0.9778, 0.9735, **Epoch: 100
0.9650, 0.9855, 0.9672, 0.9319, 0.9779, 0.9847, 0.9630, 0.9732, 0.9923, 0.9410, **Epoch: 110
0.9571, 0.9827, 0.9718, 0.9812, 0.9613, 0.9651, 0.9732, 0.9701, 0.9697, 0.9669, **Epoch: 120
0.9495, 0.9626, 0.9595, 0.9546, 0.9714, 0.9569, 0.9704, 0.9841, 0.9490, 0.9753, **Epoch: 130
0.9848, 0.9735, 0.9600, 0.9686, 0.9880, 0.9595, 0.9603, 0.9937, 0.9436, 0.9764, **Epoch: 140
0.9901, 0.9489, 0.9787, 0.9680, 0.9513, 0.9854, 0.9659, 0.9713, 0.9712, 0.9689, **Epoch: 150
0.9594, 0.9969, 0.9523, 0.9309, 0.9598, 0.9388, 0.9638, 1.0012, 0.9677, 0.9666, **Epoch: 160
0.9901, 0.9624, 0.9535, 0.9867, 0.9825, 0.9618, 0.9760, 0.9668, 0.9376, 0.9603, **Epoch: 170
0.9713, 0.9623, 0.9837, 0.9531, 0.9901, 0.9380, 0.9545, 0.9684, 0.9451, 0.9792, **Epoch: 180
0.9594, 0.9968, 0.9703, 0.9572, 0.9505, 0.9592, 0.9503, 0.9629, 0.9684, 0.9576, **Epoch: 190
0.9885, 0.9644, 0.9662, 0.9464, 0.9519, 0.9721, 0.9701, 0.9803, 0.9765, 0.9694, **Epoch: 200
Training Accuracy: 
0.3296, 0.3704, 0.4296, 0.3741, 0.3704, 0.3778, 0.3481, 0.4148, 0.4037, 0.4593, **Epoch: 10
0.5148, 0.5889, 0.6296, 0.6444, 0.6556, 0.6370, 0.6741, 0.6741, 0.6963, 0.7074, **Epoch: 20
0.6815, 0.6815, 0.6963, 0.7333, 0.7111, 0.7074, 0.7037, 0.7037, 0.7222, 0.7407, **Epoch: 30
0.7519, 0.7593, 0.7519, 0.7519, 0.7593, 0.7815, 0.7593, 0.7481, 0.7519, 0.7741, **Epoch: 40
0.7778, 0.7704, 0.7667, 0.8037, 0.7963, 0.7852, 0.8259, 0.8148, 0.8222, 0.8296, **Epoch: 50
0.8185, 0.8000, 0.8222, 0.8111, 0.8333, 0.8222, 0.8481, 0.8333, 0.8074, 0.8556, **Epoch: 60
0.8296, 0.7926, 0.8259, 0.8370, 0.8111, 0.8519, 0.7926, 0.8148, 0.8444, 0.8296, **Epoch: 70
0.8630, 0.8370, 0.8704, 0.8519, 0.8444, 0.8704, 0.8741, 0.8630, 0.8630, 0.8593, **Epoch: 80
0.8704, 0.8630, 0.8630, 0.8593, 0.8963, 0.8630, 0.9074, 0.8815, 0.8889, 0.8778, **Epoch: 90
0.9000, 0.8519, 0.8852, 0.8741, 0.8889, 0.8963, 0.8778, 0.8704, 0.9037, 0.8852, **Epoch: 100
0.8667, 0.8926, 0.8741, 0.8481, 0.8815, 0.8889, 0.8519, 0.8741, 0.8815, 0.8259, **Epoch: 110
0.8593, 0.8852, 0.8815, 0.8963, 0.8630, 0.8741, 0.8889, 0.9037, 0.8926, 0.8556, **Epoch: 120
0.8741, 0.8556, 0.8704, 0.8704, 0.8556, 0.8630, 0.8704, 0.8741, 0.8926, 0.8926, **Epoch: 130
0.8778, 0.8667, 0.8630, 0.9148, 0.8963, 0.8704, 0.8704, 0.8593, 0.8667, 0.8407, **Epoch: 140
0.8593, 0.8630, 0.8926, 0.8778, 0.8704, 0.8630, 0.9000, 0.8741, 0.9000, 0.8519, **Epoch: 150
0.8778, 0.8815, 0.8778, 0.8704, 0.8852, 0.8704, 0.8815, 0.8630, 0.8778, 0.8778, **Epoch: 160
0.8889, 0.8815, 0.8741, 0.8444, 0.8704, 0.8519, 0.8704, 0.8778, 0.8815, 0.8741, **Epoch: 170
0.8667, 0.9000, 0.8778, 0.8963, 0.8778, 0.8926, 0.8852, 0.8741, 0.9074, 0.8519, **Epoch: 180
0.8741, 0.8815, 0.8704, 0.9000, 0.8815, 0.8963, 0.9074, 0.9148, 0.9185, 0.8815, **Epoch: 190
0.8852, 0.8778, 0.8741, 0.8889, 0.8481, 0.8815, 0.8963, 0.8296, 0.8889, 0.8889, **Epoch: 200
Validation Accuracy: 
0.3449, 0.3442, 0.3722, 0.3648, 0.3397, 0.3538, 0.3678, 0.3789, 0.3863, 0.4180, **Epoch: 10
0.4771, 0.5244, 0.5384, 0.5576, 0.5561, 0.5620, 0.5790, 0.5953, 0.5894, 0.5886, **Epoch: 20
0.5945, 0.6012, 0.5923, 0.6064, 0.6064, 0.6189, 0.6307, 0.6211, 0.5982, 0.6226, **Epoch: 30
0.6196, 0.6359, 0.6411, 0.6507, 0.6396, 0.6610, 0.6470, 0.6551, 0.6588, 0.6647, **Epoch: 40
0.6603, 0.6854, 0.6773, 0.6824, 0.6802, 0.6736, 0.6809, 0.7038, 0.6891, 0.7031, **Epoch: 50
0.7001, 0.7120, 0.6987, 0.7061, 0.7127, 0.6950, 0.7120, 0.7134, 0.7142, 0.7134, **Epoch: 60
0.7134, 0.7024, 0.7194, 0.6994, 0.7194, 0.7009, 0.7038, 0.7127, 0.7120, 0.7223, **Epoch: 70
0.7230, 0.7282, 0.7422, 0.7415, 0.7164, 0.7142, 0.7334, 0.7304, 0.7386, 0.7459, **Epoch: 80
0.7585, 0.7445, 0.7238, 0.7437, 0.7356, 0.7422, 0.7422, 0.7267, 0.7459, 0.7459, **Epoch: 90
0.7452, 0.7511, 0.7371, 0.7437, 0.7430, 0.7400, 0.7614, 0.7541, 0.7548, 0.7386, **Epoch: 100
0.7474, 0.7541, 0.7304, 0.7393, 0.7430, 0.7518, 0.7297, 0.7304, 0.7533, 0.7496, **Epoch: 110
0.7356, 0.7518, 0.7710, 0.7459, 0.7445, 0.7482, 0.7489, 0.7304, 0.7459, 0.7482, **Epoch: 120
0.7437, 0.7349, 0.7437, 0.7386, 0.7445, 0.7430, 0.7371, 0.7400, 0.7445, 0.7526, **Epoch: 130
0.7459, 0.7341, 0.7548, 0.7297, 0.7474, 0.7304, 0.7371, 0.7400, 0.7459, 0.7482, **Epoch: 140
0.7504, 0.7555, 0.7319, 0.7459, 0.7393, 0.7518, 0.7482, 0.7592, 0.7518, 0.7563, **Epoch: 150
0.7548, 0.7282, 0.7415, 0.7459, 0.7563, 0.7541, 0.7386, 0.7555, 0.7533, 0.7326, **Epoch: 160
0.7526, 0.7319, 0.7555, 0.7341, 0.7518, 0.7474, 0.7430, 0.7326, 0.7607, 0.7482, **Epoch: 170
0.7570, 0.7607, 0.7459, 0.7607, 0.7445, 0.7570, 0.7386, 0.7467, 0.7585, 0.7592, **Epoch: 180
0.7585, 0.7474, 0.7541, 0.7326, 0.7518, 0.7533, 0.7422, 0.7378, 0.7312, 0.7430, **Epoch: 190
0.7541, 0.7541, 0.7297, 0.7496, 0.7496, 0.7622, 0.7386, 0.7474, 0.7334, 0.7415, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1517
Training Loss: 
1.9349, 1.5976, 1.4771, 1.3333, 1.2276, 1.1459, 1.0415, 0.9117, 0.8188, 0.8142, **Epoch: 10
0.7319, 0.6965, 0.7172, 0.7012, 0.5455, 0.5789, 0.5460, 0.5261, 0.4852, 0.4662, **Epoch: 20
0.4093, 0.4106, 0.4676, 0.3959, 0.4261, 0.3968, 0.4163, 0.4137, 0.4032, 0.3885, **Epoch: 30
0.3932, 0.3503, 0.3653, 0.3202, 0.3505, 0.2705, 0.3295, 0.3527, 0.3627, 0.3431, **Epoch: 40
0.3062, 0.3481, 0.2747, 0.2973, 0.3434, 0.3119, 0.2742, 0.3192, 0.3410, 0.3507, **Epoch: 50
0.2815, 0.2999, 0.3388, 0.3089, 0.2927, 0.3345, 0.3447, 0.2665, 0.2976, 0.3174, **Epoch: 60
0.3072, 0.3136, 0.3832, 0.3301, 0.2965, 0.3373, 0.2774, 0.3253, 0.3005, 0.3157, **Epoch: 70
0.3388, 0.2605, 0.2851, 0.2616, 0.2981, 0.2481, 0.2984, 0.3017, 0.3100, 0.3290, **Epoch: 80
0.3203, 0.3227, 0.3096, 0.2820, 0.2495, 0.3129, 0.3169, 0.2945, 0.2918, 0.2605, **Epoch: 90
0.2966, 0.3035, 0.3445, 0.3334, 0.3084, 0.3132, 0.2622, 0.3475, 0.3085, 0.3056, **Epoch: 100
0.3572, 0.2888, 0.2854, 0.3406, 0.3531, 0.2851, 0.3360, 0.3488, 0.3474, 0.2578, **Epoch: 110
0.2981, 0.2759, 0.2647, 0.3101, 0.3119, 0.3159, 0.3491, 0.2912, 0.2999, 0.2835, **Epoch: 120
0.2719, 0.3429, 0.3020, 0.2749, 0.2824, 0.2666, 0.2982, 0.3152, 0.3055, 0.3017, **Epoch: 130
0.3295, 0.2549, 0.2833, 0.2887, 0.3318, 0.3181, 0.3210, 0.3383, 0.2641, 0.3038, **Epoch: 140
0.3270, 0.2679, 0.2617, 0.2973, 0.2523, 0.3108, 0.2694, 0.3193, 0.3297, 0.3216, **Epoch: 150
0.2665, 0.3147, 0.2879, 0.2910, 0.3254, 0.3446, 0.2421, 0.3504, 0.2924, 0.3312, **Epoch: 160
0.2153, 0.2658, 0.2586, 0.3107, 0.2893, 0.3068, 0.3084, 0.2726, 0.3346, 0.2508, **Epoch: 170
0.3846, 0.3173, 0.2727, 0.2917, 0.3099, 0.2937, 0.3085, 0.3019, 0.2845, 0.3415, **Epoch: 180
0.3313, 0.3547, 0.2694, 0.2470, 0.3298, 0.3255, 0.2961, 0.3406, 0.2926, 0.3196, **Epoch: 190
0.3531, 0.3279, 0.3196, 0.3112, 0.2386, 0.2902, 0.3243, 0.2873, 0.2969, 0.3035, **Epoch: 200
Validation Loss: 
1.7295, 1.6614, 1.5852, 1.5241, 1.4711, 1.4225, 1.3878, 1.3178, 1.3035, 1.2753, **Epoch: 10
1.2459, 1.1728, 1.1645, 1.1422, 1.1591, 1.1447, 1.1443, 1.1517, 1.0918, 1.1076, **Epoch: 20
1.1030, 1.1085, 1.0900, 1.0965, 1.1210, 1.0924, 1.1293, 1.0716, 1.1094, 1.0934, **Epoch: 30
1.0641, 1.1065, 1.1125, 1.0725, 1.0695, 1.0841, 1.0919, 1.0942, 1.1119, 1.1218, **Epoch: 40
1.1275, 1.1104, 1.0577, 1.0674, 1.0431, 1.0684, 1.0324, 0.9890, 0.9825, 0.9676, **Epoch: 50
0.9680, 1.0419, 1.0244, 1.0251, 1.0799, 0.9901, 1.0469, 1.0681, 1.0566, 1.1042, **Epoch: 60
1.0798, 1.0741, 1.0809, 1.0301, 1.0534, 1.0306, 1.0424, 1.0263, 1.0280, 1.0454, **Epoch: 70
1.0173, 1.0412, 1.0374, 1.0598, 1.0030, 0.9987, 1.0293, 1.0035, 0.9553, 0.9656, **Epoch: 80
0.9920, 0.9785, 1.0027, 0.9787, 0.9928, 0.9689, 1.0282, 1.0239, 0.9989, 1.0215, **Epoch: 90
0.9901, 1.0247, 1.0530, 1.0203, 1.0571, 1.0477, 1.1166, 1.0358, 1.0695, 1.0508, **Epoch: 100
1.0006, 0.9993, 0.9779, 0.9757, 1.0114, 1.0004, 0.9718, 0.9407, 0.9647, 0.9793, **Epoch: 110
0.9616, 0.9647, 1.0043, 1.0024, 1.0084, 1.0301, 0.9977, 0.9537, 0.9971, 1.0649, **Epoch: 120
0.9828, 1.0152, 0.9914, 1.0296, 1.0422, 1.0358, 1.0152, 1.0252, 1.0331, 1.0403, **Epoch: 130
0.9890, 1.0335, 0.9981, 0.9993, 0.9793, 1.0340, 1.0381, 1.0210, 0.9943, 1.0082, **Epoch: 140
1.0309, 1.0220, 1.0138, 1.0053, 1.0333, 1.0328, 1.0679, 1.0817, 1.0661, 1.0586, **Epoch: 150
1.0262, 0.9879, 0.9917, 0.9693, 1.0149, 0.9626, 1.0249, 0.9946, 1.0432, 1.0375, **Epoch: 160
1.0406, 1.0513, 1.1007, 1.0404, 1.0588, 1.0577, 1.0363, 1.0529, 1.0009, 0.9963, **Epoch: 170
1.0026, 1.0307, 0.9893, 0.9602, 0.9900, 1.0036, 0.9896, 1.0013, 1.0067, 1.0173, **Epoch: 180
0.9993, 1.0192, 0.9772, 1.0083, 1.0119, 1.0317, 1.0584, 1.0445, 1.0192, 1.0253, **Epoch: 190
1.0647, 1.0756, 1.0578, 1.0720, 1.0051, 1.0445, 1.0025, 0.9909, 1.0211, 0.9970, **Epoch: 200
Training Accuracy: 
0.7630, 0.7926, 0.8333, 0.8519, 0.8593, 0.9000, 0.8889, 0.8444, 0.8667, 0.8963, **Epoch: 10
0.8815, 0.9111, 0.8963, 0.8963, 0.9000, 0.8963, 0.9296, 0.8963, 0.9037, 0.9222, **Epoch: 20
0.9444, 0.9222, 0.9111, 0.9370, 0.9370, 0.9185, 0.9111, 0.9519, 0.9370, 0.9074, **Epoch: 30
0.9444, 0.9259, 0.9185, 0.9222, 0.9148, 0.9407, 0.9222, 0.9259, 0.9222, 0.9407, **Epoch: 40
0.9259, 0.9111, 0.9296, 0.9185, 0.9333, 0.9481, 0.9519, 0.9296, 0.9185, 0.9185, **Epoch: 50
0.9148, 0.9407, 0.9370, 0.9074, 0.9370, 0.9111, 0.9444, 0.9037, 0.9630, 0.9111, **Epoch: 60
0.9111, 0.9333, 0.9519, 0.9185, 0.9593, 0.9222, 0.9444, 0.9185, 0.9370, 0.9074, **Epoch: 70
0.9296, 0.9111, 0.9259, 0.9259, 0.9296, 0.9481, 0.9593, 0.9296, 0.9259, 0.9222, **Epoch: 80
0.8889, 0.9259, 0.9259, 0.9185, 0.9407, 0.9296, 0.9185, 0.9407, 0.9519, 0.9519, **Epoch: 90
0.9185, 0.9481, 0.9000, 0.9333, 0.9444, 0.9444, 0.9481, 0.9370, 0.9333, 0.9444, **Epoch: 100
0.9000, 0.9185, 0.9111, 0.9148, 0.9148, 0.9556, 0.9407, 0.9259, 0.9222, 0.9259, **Epoch: 110
0.9185, 0.9296, 0.9444, 0.9000, 0.9185, 0.9222, 0.9333, 0.9333, 0.9222, 0.9037, **Epoch: 120
0.9185, 0.9333, 0.9185, 0.9185, 0.9593, 0.9333, 0.9259, 0.9333, 0.9556, 0.9556, **Epoch: 130
0.9296, 0.9148, 0.9000, 0.9407, 0.9222, 0.9148, 0.9074, 0.9259, 0.9481, 0.9111, **Epoch: 140
0.9407, 0.9407, 0.9407, 0.9333, 0.9556, 0.9370, 0.9037, 0.9407, 0.9333, 0.9481, **Epoch: 150
0.9444, 0.8963, 0.9222, 0.9259, 0.9222, 0.9148, 0.8963, 0.9222, 0.9444, 0.9185, **Epoch: 160
0.9407, 0.9148, 0.9185, 0.9259, 0.9296, 0.9444, 0.9370, 0.9519, 0.9185, 0.9148, **Epoch: 170
0.9370, 0.9222, 0.9074, 0.9296, 0.9444, 0.9444, 0.9296, 0.9481, 0.9185, 0.9333, **Epoch: 180
0.9333, 0.9481, 0.9593, 0.9222, 0.9444, 0.9296, 0.9259, 0.9148, 0.9185, 0.9259, **Epoch: 190
0.9556, 0.9370, 0.9222, 0.9259, 0.9407, 0.9444, 0.9259, 0.9259, 0.9111, 0.9444, **Epoch: 200
Validation Accuracy: 
0.6019, 0.6418, 0.6573, 0.6677, 0.6765, 0.6854, 0.6965, 0.6758, 0.6758, 0.6957, **Epoch: 10
0.6883, 0.6677, 0.6987, 0.6861, 0.6802, 0.6846, 0.6935, 0.6957, 0.6965, 0.7186, **Epoch: 20
0.6965, 0.6950, 0.6898, 0.6950, 0.6905, 0.6721, 0.6817, 0.6780, 0.6780, 0.6713, **Epoch: 30
0.6957, 0.6876, 0.6994, 0.6869, 0.6780, 0.6994, 0.6920, 0.6832, 0.6839, 0.6950, **Epoch: 40
0.6669, 0.6883, 0.6994, 0.6957, 0.7208, 0.7164, 0.7216, 0.7230, 0.7201, 0.7194, **Epoch: 50
0.7208, 0.7216, 0.7127, 0.7024, 0.7179, 0.7304, 0.7157, 0.7016, 0.7186, 0.7253, **Epoch: 60
0.7253, 0.6972, 0.6979, 0.7075, 0.7053, 0.7194, 0.6942, 0.7194, 0.7282, 0.7083, **Epoch: 70
0.7068, 0.6935, 0.7120, 0.7260, 0.7349, 0.7134, 0.7053, 0.7445, 0.7356, 0.7201, **Epoch: 80
0.7179, 0.7016, 0.7164, 0.7053, 0.7216, 0.7216, 0.7068, 0.7208, 0.7038, 0.7068, **Epoch: 90
0.7142, 0.7201, 0.7149, 0.7149, 0.6942, 0.6809, 0.6876, 0.7090, 0.7120, 0.7127, **Epoch: 100
0.7142, 0.7179, 0.7216, 0.7356, 0.7201, 0.7157, 0.7260, 0.7186, 0.7253, 0.7230, **Epoch: 110
0.7400, 0.7312, 0.7186, 0.7157, 0.7290, 0.7223, 0.7208, 0.7260, 0.7260, 0.7105, **Epoch: 120
0.7201, 0.7201, 0.7230, 0.7164, 0.7186, 0.7134, 0.7179, 0.7267, 0.7194, 0.7186, **Epoch: 130
0.7157, 0.7112, 0.7112, 0.7142, 0.7097, 0.7157, 0.7127, 0.7230, 0.7260, 0.7216, **Epoch: 140
0.7386, 0.7120, 0.7149, 0.7334, 0.7267, 0.7157, 0.7238, 0.7164, 0.7194, 0.7105, **Epoch: 150
0.7097, 0.7009, 0.7083, 0.7275, 0.7127, 0.7142, 0.7230, 0.7238, 0.7253, 0.7112, **Epoch: 160
0.7216, 0.7157, 0.7290, 0.7282, 0.7312, 0.7260, 0.7105, 0.7142, 0.7201, 0.7282, **Epoch: 170
0.7430, 0.7127, 0.7334, 0.7386, 0.7319, 0.7075, 0.7238, 0.7290, 0.7179, 0.7171, **Epoch: 180
0.7097, 0.7253, 0.7326, 0.7223, 0.7090, 0.7097, 0.7194, 0.7149, 0.7120, 0.7068, **Epoch: 190
0.7326, 0.6905, 0.7120, 0.7134, 0.7112, 0.7127, 0.7164, 0.7142, 0.7083, 0.7208, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1519
Training Loss: 
1.9463, 1.6236, 1.4646, 1.3658, 1.2287, 1.1338, 1.0749, 0.9945, 0.9313, 0.8375, **Epoch: 10
0.7743, 0.7117, 0.6573, 0.5875, 0.5670, 0.5511, 0.5281, 0.5229, 0.4724, 0.4740, **Epoch: 20
0.4520, 0.4202, 0.3519, 0.4232, 0.3694, 0.3675, 0.4486, 0.3589, 0.3674, 0.3386, **Epoch: 30
0.4098, 0.3682, 0.3834, 0.3792, 0.3328, 0.2958, 0.3553, 0.3719, 0.3018, 0.3811, **Epoch: 40
0.2506, 0.3334, 0.2964, 0.3270, 0.2661, 0.2847, 0.2714, 0.3291, 0.3288, 0.3646, **Epoch: 50
0.3222, 0.2977, 0.3708, 0.3221, 0.3417, 0.3400, 0.3000, 0.3463, 0.3099, 0.3241, **Epoch: 60
0.3041, 0.3184, 0.2960, 0.3374, 0.3470, 0.3192, 0.2816, 0.3333, 0.2991, 0.3090, **Epoch: 70
0.3392, 0.2941, 0.2727, 0.2748, 0.3293, 0.3352, 0.2927, 0.2504, 0.2788, 0.3276, **Epoch: 80
0.3503, 0.3216, 0.2851, 0.3283, 0.3281, 0.3219, 0.3574, 0.3582, 0.2777, 0.3053, **Epoch: 90
0.3425, 0.3721, 0.2688, 0.2448, 0.3287, 0.2668, 0.2678, 0.3071, 0.3079, 0.3290, **Epoch: 100
0.2796, 0.2721, 0.3388, 0.3277, 0.2591, 0.2385, 0.3396, 0.2492, 0.3017, 0.2916, **Epoch: 110
0.2920, 0.2766, 0.3224, 0.3202, 0.3415, 0.3305, 0.2964, 0.3188, 0.3416, 0.2881, **Epoch: 120
0.3271, 0.3352, 0.3368, 0.3008, 0.3253, 0.3413, 0.3021, 0.2775, 0.2994, 0.3213, **Epoch: 130
0.2931, 0.2794, 0.2882, 0.2927, 0.3016, 0.3580, 0.3168, 0.3174, 0.3059, 0.3073, **Epoch: 140
0.2862, 0.2929, 0.3064, 0.2824, 0.2969, 0.2781, 0.3144, 0.2773, 0.2966, 0.3162, **Epoch: 150
0.2849, 0.2834, 0.3306, 0.2467, 0.3442, 0.3177, 0.2974, 0.2913, 0.3094, 0.2359, **Epoch: 160
0.2885, 0.4269, 0.2844, 0.3227, 0.2489, 0.3049, 0.3112, 0.2775, 0.3050, 0.2518, **Epoch: 170
0.3153, 0.2953, 0.2713, 0.2327, 0.3106, 0.3522, 0.3424, 0.2758, 0.2675, 0.2616, **Epoch: 180
0.3685, 0.3044, 0.2704, 0.2778, 0.3148, 0.3172, 0.2907, 0.2773, 0.2922, 0.2938, **Epoch: 190
0.3034, 0.2930, 0.3185, 0.3199, 0.2408, 0.3265, 0.2803, 0.3190, 0.3359, 0.3254, **Epoch: 200
Validation Loss: 
1.7436, 1.6655, 1.5862, 1.5260, 1.4593, 1.4175, 1.3740, 1.3260, 1.3035, 1.2512, **Epoch: 10
1.2159, 1.1850, 1.1949, 1.1501, 1.1142, 1.1252, 1.1353, 1.1417, 1.0883, 1.1058, **Epoch: 20
1.1318, 1.1230, 1.1091, 1.1054, 1.0987, 1.1300, 1.1116, 1.0971, 1.1098, 1.1155, **Epoch: 30
1.0978, 1.1184, 1.1400, 1.0841, 1.0777, 1.0928, 1.1055, 1.0669, 1.0823, 1.0578, **Epoch: 40
1.0712, 1.1393, 1.1049, 1.1101, 1.0622, 1.0560, 1.0514, 1.0890, 1.0327, 1.0699, **Epoch: 50
1.0281, 1.0663, 1.0899, 1.0907, 1.0631, 1.0890, 1.0517, 1.0912, 1.0370, 1.0615, **Epoch: 60
1.0626, 1.0731, 1.0924, 1.0266, 1.0062, 1.0306, 1.0332, 1.0244, 1.0315, 1.0458, **Epoch: 70
1.0256, 1.0239, 1.0795, 1.0642, 1.0724, 1.0506, 1.1219, 1.0706, 1.0260, 1.0958, **Epoch: 80
1.0601, 1.0219, 1.0090, 0.9846, 1.0626, 1.0240, 1.0874, 1.0201, 1.0302, 1.1020, **Epoch: 90
1.0701, 1.0933, 1.0584, 1.0476, 1.0173, 1.0647, 1.0628, 1.0295, 0.9953, 1.0483, **Epoch: 100
0.9832, 1.0150, 0.9900, 0.9973, 1.0001, 1.0150, 0.9782, 1.0092, 0.9895, 1.0218, **Epoch: 110
1.0210, 1.0370, 1.0289, 1.0069, 1.0063, 1.0301, 0.9961, 1.0036, 0.9953, 1.0351, **Epoch: 120
1.0176, 1.0682, 1.0557, 1.0106, 1.0657, 1.0770, 1.0349, 1.0151, 1.0393, 1.0228, **Epoch: 130
1.0047, 1.0526, 1.0352, 1.0391, 1.0169, 1.0484, 0.9920, 1.0673, 1.0129, 1.0081, **Epoch: 140
1.0159, 1.0208, 0.9499, 1.0106, 0.9725, 1.0290, 0.9862, 0.9983, 0.9971, 1.0081, **Epoch: 150
1.0590, 1.0599, 1.0123, 1.0700, 1.0288, 0.9839, 1.0507, 1.0404, 1.0360, 1.0445, **Epoch: 160
0.9945, 1.0143, 0.9739, 1.0009, 0.9908, 0.9665, 1.0001, 1.0071, 0.9967, 1.0277, **Epoch: 170
1.0439, 1.0240, 0.9960, 1.0255, 0.9761, 0.9891, 1.0179, 1.0514, 1.0615, 1.0366, **Epoch: 180
1.0309, 1.0564, 1.0666, 0.9954, 0.9619, 1.0309, 1.0276, 1.0227, 1.0132, 1.0505, **Epoch: 190
1.0560, 0.9807, 1.0607, 0.9989, 1.0456, 1.0207, 1.0536, 1.0280, 1.0192, 0.9977, **Epoch: 200
Training Accuracy: 
0.7519, 0.7741, 0.8111, 0.8519, 0.8852, 0.8667, 0.8926, 0.8667, 0.9111, 0.8963, **Epoch: 10
0.8963, 0.8593, 0.9296, 0.8963, 0.8963, 0.9259, 0.9037, 0.9111, 0.9074, 0.9037, **Epoch: 20
0.9370, 0.9481, 0.9296, 0.9370, 0.9259, 0.9185, 0.9037, 0.8963, 0.8852, 0.8852, **Epoch: 30
0.9296, 0.9259, 0.9444, 0.9111, 0.9407, 0.9222, 0.9222, 0.9000, 0.9407, 0.9185, **Epoch: 40
0.9370, 0.9481, 0.9296, 0.9259, 0.9185, 0.9259, 0.9222, 0.9407, 0.9444, 0.8963, **Epoch: 50
0.9370, 0.9444, 0.9148, 0.9222, 0.9481, 0.9000, 0.9185, 0.9444, 0.9148, 0.9519, **Epoch: 60
0.9111, 0.9185, 0.9222, 0.9037, 0.9222, 0.9222, 0.9222, 0.9222, 0.9407, 0.9259, **Epoch: 70
0.9667, 0.9185, 0.9519, 0.9370, 0.9481, 0.9296, 0.9259, 0.9296, 0.9259, 0.8926, **Epoch: 80
0.9222, 0.9407, 0.9407, 0.9333, 0.9370, 0.9222, 0.9222, 0.9037, 0.9519, 0.9222, **Epoch: 90
0.9222, 0.9593, 0.9111, 0.9259, 0.9444, 0.9296, 0.9370, 0.9259, 0.9111, 0.9185, **Epoch: 100
0.9556, 0.9148, 0.9296, 0.9370, 0.9074, 0.9111, 0.9407, 0.9333, 0.9222, 0.9259, **Epoch: 110
0.9222, 0.9148, 0.8778, 0.9185, 0.9111, 0.9222, 0.9259, 0.9444, 0.9111, 0.9259, **Epoch: 120
0.9222, 0.9222, 0.8963, 0.9333, 0.9370, 0.9333, 0.9519, 0.9444, 0.9259, 0.9407, **Epoch: 130
0.9259, 0.9148, 0.9407, 0.8926, 0.9296, 0.9519, 0.9333, 0.9519, 0.9148, 0.9407, **Epoch: 140
0.9185, 0.9148, 0.9333, 0.9222, 0.9074, 0.9333, 0.9296, 0.9370, 0.9333, 0.9296, **Epoch: 150
0.9296, 0.9037, 0.9148, 0.9148, 0.9259, 0.9407, 0.9333, 0.9259, 0.9259, 0.9444, **Epoch: 160
0.9185, 0.9444, 0.9556, 0.9296, 0.9481, 0.9407, 0.9333, 0.9370, 0.9259, 0.9074, **Epoch: 170
0.9037, 0.9222, 0.9185, 0.9407, 0.9407, 0.9185, 0.9148, 0.9481, 0.9481, 0.9370, **Epoch: 180
0.9148, 0.9259, 0.9148, 0.9407, 0.9111, 0.9407, 0.9296, 0.9259, 0.9333, 0.9185, **Epoch: 190
0.9333, 0.9407, 0.9407, 0.9333, 0.9370, 0.9407, 0.9037, 0.9481, 0.9222, 0.9259, **Epoch: 200
Validation Accuracy: 
0.5945, 0.6300, 0.6337, 0.6691, 0.6743, 0.6869, 0.6832, 0.6758, 0.6861, 0.6950, **Epoch: 10
0.6950, 0.6905, 0.6905, 0.6898, 0.7031, 0.7009, 0.7009, 0.6950, 0.7075, 0.6706, **Epoch: 20
0.6994, 0.6898, 0.6905, 0.6691, 0.6529, 0.6780, 0.6691, 0.6728, 0.6728, 0.6677, **Epoch: 30
0.6654, 0.6499, 0.6640, 0.6846, 0.6736, 0.6610, 0.6809, 0.6677, 0.6832, 0.6773, **Epoch: 40
0.6765, 0.6787, 0.6972, 0.6905, 0.6965, 0.7009, 0.6935, 0.6861, 0.6928, 0.7075, **Epoch: 50
0.7075, 0.6994, 0.6987, 0.6979, 0.6950, 0.6920, 0.7061, 0.6809, 0.7112, 0.7083, **Epoch: 60
0.7061, 0.6987, 0.7105, 0.7031, 0.7186, 0.6987, 0.7134, 0.7105, 0.7208, 0.7134, **Epoch: 70
0.7001, 0.7038, 0.7120, 0.7112, 0.7031, 0.7097, 0.6861, 0.6913, 0.6869, 0.7016, **Epoch: 80
0.6928, 0.6957, 0.6972, 0.7009, 0.7001, 0.7157, 0.7127, 0.7260, 0.7061, 0.6920, **Epoch: 90
0.7105, 0.7068, 0.7046, 0.7245, 0.7186, 0.7016, 0.7046, 0.7267, 0.7001, 0.7267, **Epoch: 100
0.7194, 0.7053, 0.7253, 0.7142, 0.7201, 0.7245, 0.7194, 0.7245, 0.7164, 0.7001, **Epoch: 110
0.7157, 0.7097, 0.7097, 0.7053, 0.6979, 0.7127, 0.7031, 0.7208, 0.6928, 0.7038, **Epoch: 120
0.7216, 0.7083, 0.7134, 0.7157, 0.7186, 0.7075, 0.7090, 0.7061, 0.7061, 0.7068, **Epoch: 130
0.7267, 0.6965, 0.6869, 0.6928, 0.7009, 0.7024, 0.6950, 0.7275, 0.7046, 0.7068, **Epoch: 140
0.7245, 0.6965, 0.6957, 0.7157, 0.7009, 0.6987, 0.7120, 0.6979, 0.7016, 0.7053, **Epoch: 150
0.7290, 0.7127, 0.7179, 0.7120, 0.7009, 0.6817, 0.7031, 0.6898, 0.6972, 0.7142, **Epoch: 160
0.7149, 0.7238, 0.7164, 0.7142, 0.7127, 0.7297, 0.7194, 0.7194, 0.7016, 0.7105, **Epoch: 170
0.7290, 0.7142, 0.7186, 0.7356, 0.7223, 0.7201, 0.7445, 0.7208, 0.7061, 0.7061, **Epoch: 180
0.7223, 0.7290, 0.7260, 0.7171, 0.7230, 0.7230, 0.7105, 0.7053, 0.7267, 0.7038, **Epoch: 190
0.7016, 0.7024, 0.7075, 0.7142, 0.7171, 0.7112, 0.7282, 0.7157, 0.7275, 0.7334, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1519
Training Loss: 
1.9613, 1.6470, 1.4904, 1.4095, 1.2797, 1.1354, 1.0225, 0.9657, 0.8314, 0.8008, **Epoch: 10
0.7530, 0.6848, 0.7187, 0.5976, 0.5426, 0.4957, 0.5154, 0.4931, 0.4453, 0.4616, **Epoch: 20
0.4369, 0.3755, 0.3579, 0.4046, 0.3573, 0.4115, 0.3770, 0.3162, 0.3919, 0.3743, **Epoch: 30
0.3455, 0.3548, 0.3319, 0.3499, 0.3549, 0.3754, 0.3257, 0.3386, 0.3051, 0.2895, **Epoch: 40
0.3033, 0.2989, 0.2609, 0.2989, 0.3129, 0.3444, 0.2253, 0.3230, 0.3054, 0.2713, **Epoch: 50
0.3001, 0.3012, 0.3364, 0.2915, 0.2761, 0.2912, 0.2539, 0.2819, 0.2996, 0.3461, **Epoch: 60
0.2682, 0.2730, 0.2875, 0.2231, 0.2756, 0.2774, 0.2911, 0.3073, 0.2608, 0.3129, **Epoch: 70
0.3016, 0.2722, 0.2766, 0.2514, 0.2605, 0.3164, 0.2914, 0.3314, 0.3102, 0.2912, **Epoch: 80
0.3094, 0.2836, 0.2331, 0.3371, 0.2820, 0.3156, 0.2792, 0.2325, 0.3231, 0.3082, **Epoch: 90
0.2739, 0.2777, 0.3021, 0.2850, 0.2806, 0.2405, 0.3044, 0.3099, 0.3010, 0.2407, **Epoch: 100
0.3103, 0.2768, 0.2585, 0.2809, 0.2582, 0.3072, 0.2938, 0.2960, 0.2592, 0.2250, **Epoch: 110
0.3231, 0.2685, 0.3114, 0.3319, 0.3073, 0.2910, 0.3241, 0.3305, 0.3472, 0.2563, **Epoch: 120
0.3977, 0.3199, 0.2876, 0.2891, 0.2886, 0.2538, 0.2878, 0.2943, 0.2910, 0.3298, **Epoch: 130
0.2923, 0.2845, 0.3280, 0.3167, 0.3344, 0.3194, 0.2731, 0.3162, 0.3180, 0.2966, **Epoch: 140
0.3575, 0.2877, 0.2908, 0.3050, 0.3106, 0.2398, 0.3146, 0.2901, 0.2487, 0.3284, **Epoch: 150
0.2849, 0.2845, 0.2762, 0.2821, 0.3112, 0.3118, 0.3613, 0.2680, 0.2665, 0.2820, **Epoch: 160
0.2720, 0.2999, 0.2981, 0.3385, 0.2753, 0.3334, 0.3233, 0.3396, 0.2731, 0.3247, **Epoch: 170
0.2980, 0.3298, 0.2852, 0.2438, 0.2607, 0.3091, 0.2998, 0.2705, 0.2724, 0.2703, **Epoch: 180
0.3389, 0.3072, 0.2473, 0.2862, 0.3649, 0.3198, 0.2815, 0.2802, 0.2805, 0.2677, **Epoch: 190
0.2680, 0.4007, 0.2987, 0.2900, 0.2609, 0.3033, 0.2643, 0.2615, 0.2845, 0.3462, **Epoch: 200
Validation Loss: 
1.7488, 1.6490, 1.5850, 1.5171, 1.4408, 1.4042, 1.3550, 1.3014, 1.2556, 1.2224, **Epoch: 10
1.1876, 1.2004, 1.1293, 1.1118, 1.1019, 1.0937, 1.0610, 1.0506, 1.0449, 1.0439, **Epoch: 20
1.0198, 1.0425, 1.0469, 1.0161, 1.0814, 1.0475, 1.0463, 1.0380, 1.0592, 1.0390, **Epoch: 30
1.0474, 1.0611, 1.0445, 1.0028, 1.0566, 1.0568, 1.0181, 1.0766, 1.0313, 1.0100, **Epoch: 40
1.0569, 1.0101, 1.0206, 1.0288, 1.0174, 1.0432, 0.9926, 0.9976, 1.0484, 1.0346, **Epoch: 50
0.9934, 1.0074, 1.0005, 1.0323, 1.0209, 1.0364, 1.0014, 1.0159, 1.0392, 0.9596, **Epoch: 60
1.0917, 1.0432, 0.9855, 1.0202, 0.9796, 1.0299, 1.0366, 1.0340, 1.0270, 1.0086, **Epoch: 70
1.0037, 0.9966, 1.0283, 1.0615, 1.0271, 1.0465, 1.0609, 1.0447, 1.0338, 1.0302, **Epoch: 80
1.0078, 1.0375, 1.0042, 1.0567, 1.0173, 1.0539, 1.0124, 1.0274, 1.0761, 1.0382, **Epoch: 90
1.0279, 1.0228, 1.0404, 1.0068, 1.0617, 1.0397, 1.0383, 1.0276, 1.0089, 1.0437, **Epoch: 100
1.0520, 1.0305, 1.0229, 1.0204, 1.0472, 1.0205, 1.0014, 1.0580, 1.0082, 1.0303, **Epoch: 110
1.0075, 1.0180, 1.0368, 1.0319, 1.0497, 1.0099, 1.0197, 1.0343, 1.0108, 1.0384, **Epoch: 120
1.0104, 1.0281, 1.0176, 1.0218, 1.0334, 1.0216, 1.0064, 1.0485, 1.0037, 1.0053, **Epoch: 130
0.9969, 1.0299, 1.0167, 1.0398, 1.0209, 1.0267, 1.0313, 1.0041, 1.0344, 1.0162, **Epoch: 140
1.0451, 1.0190, 0.9973, 1.0218, 1.0285, 1.0250, 1.0379, 1.0133, 1.0264, 1.0150, **Epoch: 150
1.0041, 1.0458, 1.0360, 0.9978, 1.0072, 1.0271, 1.0276, 1.0283, 1.0070, 1.0203, **Epoch: 160
1.0385, 1.0375, 1.0104, 1.0350, 1.0231, 1.0219, 1.0078, 1.0148, 1.0128, 0.9777, **Epoch: 170
1.0760, 1.0485, 0.9995, 1.0649, 1.0724, 1.0140, 1.0453, 1.0620, 1.0014, 1.0255, **Epoch: 180
1.0117, 0.9897, 1.0188, 1.0267, 1.0714, 1.0463, 1.0482, 1.0354, 1.0303, 1.0234, **Epoch: 190
1.0335, 1.0193, 1.0168, 1.0754, 1.0246, 1.0215, 1.0517, 1.0203, 1.0387, 1.0251, **Epoch: 200
Training Accuracy: 
0.8222, 0.8444, 0.8778, 0.8815, 0.8630, 0.8852, 0.9037, 0.8556, 0.8889, 0.9000, **Epoch: 10
0.9111, 0.9000, 0.9111, 0.9222, 0.9222, 0.9148, 0.9222, 0.8889, 0.9333, 0.9074, **Epoch: 20
0.9259, 0.9333, 0.9259, 0.9037, 0.9222, 0.9481, 0.9333, 0.9074, 0.9296, 0.9481, **Epoch: 30
0.9074, 0.9074, 0.9000, 0.9296, 0.9111, 0.9259, 0.9296, 0.9148, 0.8963, 0.9296, **Epoch: 40
0.9630, 0.9481, 0.9185, 0.9370, 0.9296, 0.9222, 0.9000, 0.9370, 0.9407, 0.9370, **Epoch: 50
0.9370, 0.9111, 0.9222, 0.9333, 0.9222, 0.9148, 0.9296, 0.9222, 0.9444, 0.9222, **Epoch: 60
0.9148, 0.9296, 0.9370, 0.9370, 0.9333, 0.9333, 0.9407, 0.9370, 0.9407, 0.9370, **Epoch: 70
0.9148, 0.9296, 0.9407, 0.9407, 0.9444, 0.9407, 0.9000, 0.9370, 0.9296, 0.9259, **Epoch: 80
0.9407, 0.9519, 0.9370, 0.9407, 0.9000, 0.9333, 0.9222, 0.9074, 0.9407, 0.9259, **Epoch: 90
0.9148, 0.9407, 0.9296, 0.9333, 0.9148, 0.9444, 0.9481, 0.9370, 0.9111, 0.9222, **Epoch: 100
0.9481, 0.9519, 0.9222, 0.9185, 0.9259, 0.9296, 0.9407, 0.9259, 0.9481, 0.9519, **Epoch: 110
0.9370, 0.9370, 0.9037, 0.9333, 0.9222, 0.9370, 0.9185, 0.9444, 0.9481, 0.9296, **Epoch: 120
0.9222, 0.9259, 0.9296, 0.9222, 0.9296, 0.9444, 0.9185, 0.9481, 0.9370, 0.9407, **Epoch: 130
0.9370, 0.9185, 0.9259, 0.9148, 0.8963, 0.9407, 0.9333, 0.9259, 0.9148, 0.9333, **Epoch: 140
0.9185, 0.9370, 0.9667, 0.9333, 0.9222, 0.9556, 0.9259, 0.9148, 0.9185, 0.9259, **Epoch: 150
0.9148, 0.9111, 0.9296, 0.9185, 0.9370, 0.9481, 0.9407, 0.9296, 0.9444, 0.9481, **Epoch: 160
0.9407, 0.9481, 0.9370, 0.9444, 0.9370, 0.9222, 0.9296, 0.9259, 0.9481, 0.9333, **Epoch: 170
0.9370, 0.9444, 0.9407, 0.9148, 0.9259, 0.9407, 0.9407, 0.9407, 0.9407, 0.9667, **Epoch: 180
0.9519, 0.9444, 0.9296, 0.9370, 0.9296, 0.9111, 0.9370, 0.9333, 0.9296, 0.9370, **Epoch: 190
0.9519, 0.9259, 0.9222, 0.9407, 0.9259, 0.9370, 0.9296, 0.9370, 0.9296, 0.9481, **Epoch: 200
Validation Accuracy: 
0.6470, 0.6773, 0.7090, 0.6942, 0.6994, 0.7038, 0.7253, 0.7223, 0.7083, 0.7105, **Epoch: 10
0.7097, 0.7216, 0.6891, 0.7031, 0.7068, 0.7105, 0.7179, 0.7164, 0.7075, 0.7090, **Epoch: 20
0.7105, 0.7134, 0.7083, 0.7208, 0.7208, 0.7068, 0.7120, 0.6913, 0.7031, 0.7120, **Epoch: 30
0.7216, 0.6920, 0.6935, 0.7038, 0.7105, 0.7009, 0.6994, 0.7171, 0.6883, 0.6913, **Epoch: 40
0.7164, 0.7009, 0.6979, 0.7105, 0.7097, 0.6942, 0.7068, 0.7105, 0.7179, 0.7090, **Epoch: 50
0.7097, 0.6928, 0.7001, 0.7001, 0.7031, 0.7201, 0.7149, 0.7075, 0.6942, 0.6928, **Epoch: 60
0.7090, 0.7105, 0.6972, 0.6950, 0.7127, 0.6994, 0.6979, 0.7031, 0.7075, 0.7105, **Epoch: 70
0.6891, 0.7068, 0.7194, 0.7164, 0.7245, 0.7061, 0.7031, 0.7157, 0.7105, 0.7120, **Epoch: 80
0.7031, 0.6987, 0.7179, 0.7031, 0.7142, 0.7046, 0.7068, 0.7194, 0.7164, 0.7171, **Epoch: 90
0.7127, 0.7105, 0.7068, 0.6928, 0.7038, 0.7134, 0.6972, 0.6957, 0.6891, 0.7164, **Epoch: 100
0.6994, 0.7105, 0.7127, 0.7157, 0.7090, 0.7112, 0.7009, 0.7112, 0.7031, 0.7061, **Epoch: 110
0.7053, 0.6935, 0.7164, 0.7230, 0.7157, 0.7061, 0.7201, 0.6928, 0.7238, 0.7038, **Epoch: 120
0.7090, 0.7097, 0.7120, 0.7105, 0.7024, 0.7208, 0.7075, 0.7038, 0.7001, 0.7024, **Epoch: 130
0.6942, 0.7142, 0.7083, 0.7038, 0.7157, 0.7083, 0.6802, 0.7090, 0.7053, 0.7112, **Epoch: 140
0.7090, 0.7053, 0.7260, 0.6987, 0.7134, 0.7009, 0.7120, 0.7038, 0.6987, 0.7097, **Epoch: 150
0.7230, 0.6957, 0.7171, 0.7179, 0.7009, 0.6920, 0.7031, 0.6950, 0.7105, 0.7157, **Epoch: 160
0.7009, 0.6979, 0.6920, 0.6979, 0.6979, 0.7142, 0.7134, 0.7149, 0.6994, 0.7127, **Epoch: 170
0.7134, 0.6965, 0.6905, 0.7127, 0.7223, 0.6987, 0.7142, 0.7157, 0.6942, 0.7142, **Epoch: 180
0.7009, 0.7112, 0.7083, 0.6957, 0.7179, 0.7068, 0.6972, 0.6846, 0.7009, 0.6913, **Epoch: 190
0.7097, 0.7001, 0.7186, 0.7061, 0.6987, 0.7090, 0.7120, 0.7142, 0.7127, 0.7075, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1523
Training Loss: 
1.9668, 1.5609, 1.4345, 1.3085, 1.2030, 1.0872, 0.9619, 0.9262, 0.8324, 0.7390, **Epoch: 10
0.6996, 0.6584, 0.6325, 0.6041, 0.5475, 0.5007, 0.4885, 0.4859, 0.4938, 0.3727, **Epoch: 20
0.3979, 0.3858, 0.3496, 0.4051, 0.4374, 0.4002, 0.2621, 0.3783, 0.2981, 0.4188, **Epoch: 30
0.3162, 0.3373, 0.3619, 0.3427, 0.3224, 0.2741, 0.3583, 0.3210, 0.3605, 0.3364, **Epoch: 40
0.2677, 0.3030, 0.3210, 0.3019, 0.3529, 0.2838, 0.3012, 0.2741, 0.2687, 0.3232, **Epoch: 50
0.3384, 0.3120, 0.2671, 0.2783, 0.2947, 0.3089, 0.2445, 0.2503, 0.2791, 0.2814, **Epoch: 60
0.2896, 0.2643, 0.2797, 0.2277, 0.2490, 0.2954, 0.3153, 0.2606, 0.2106, 0.2663, **Epoch: 70
0.3348, 0.2660, 0.2603, 0.3131, 0.2794, 0.3156, 0.2668, 0.2606, 0.3478, 0.2691, **Epoch: 80
0.2850, 0.2799, 0.3307, 0.2596, 0.3010, 0.3576, 0.2345, 0.2548, 0.2643, 0.3043, **Epoch: 90
0.2544, 0.3083, 0.2472, 0.2826, 0.2611, 0.2976, 0.2691, 0.2517, 0.2829, 0.2243, **Epoch: 100
0.2857, 0.3298, 0.3063, 0.3121, 0.2398, 0.2997, 0.2742, 0.2859, 0.3006, 0.2559, **Epoch: 110
0.2640, 0.2671, 0.2861, 0.2849, 0.2772, 0.3092, 0.2953, 0.2961, 0.2714, 0.2612, **Epoch: 120
0.2772, 0.3128, 0.2746, 0.2391, 0.2859, 0.3167, 0.2833, 0.2835, 0.2694, 0.2770, **Epoch: 130
0.3313, 0.2719, 0.2736, 0.2548, 0.2787, 0.2403, 0.2966, 0.2745, 0.2555, 0.2986, **Epoch: 140
0.2595, 0.2227, 0.2892, 0.2920, 0.3047, 0.2956, 0.3056, 0.2692, 0.3243, 0.3074, **Epoch: 150
0.3093, 0.3182, 0.2710, 0.2997, 0.2671, 0.3038, 0.3423, 0.2884, 0.3250, 0.2750, **Epoch: 160
0.3263, 0.3245, 0.2716, 0.2544, 0.3113, 0.3215, 0.3141, 0.3029, 0.2361, 0.3221, **Epoch: 170
0.2893, 0.2928, 0.3528, 0.2975, 0.3223, 0.2947, 0.3017, 0.2825, 0.2751, 0.2912, **Epoch: 180
0.2399, 0.2790, 0.2809, 0.3212, 0.3079, 0.2625, 0.3078, 0.3126, 0.2868, 0.3220, **Epoch: 190
0.2630, 0.2749, 0.2904, 0.3031, 0.3031, 0.2968, 0.2694, 0.2330, 0.2581, 0.2322, **Epoch: 200
Validation Loss: 
1.7000, 1.6272, 1.5502, 1.4896, 1.4360, 1.3698, 1.3166, 1.2923, 1.2257, 1.2067, **Epoch: 10
1.1733, 1.1511, 1.1396, 1.0949, 1.0747, 1.0568, 1.0817, 1.0471, 1.0642, 1.0197, **Epoch: 20
1.0504, 1.0378, 1.0614, 1.0696, 1.0272, 1.0803, 1.0508, 1.0166, 1.0119, 1.0175, **Epoch: 30
1.0232, 1.0563, 1.0508, 0.9946, 1.0365, 1.0199, 1.0429, 1.0129, 0.9886, 1.0228, **Epoch: 40
1.0307, 0.9763, 1.0027, 1.0078, 1.0284, 1.0007, 1.0135, 1.0129, 0.9810, 1.0090, **Epoch: 50
0.9691, 0.9939, 1.0328, 1.0142, 1.0204, 1.0181, 0.9811, 1.0036, 1.0236, 1.0163, **Epoch: 60
1.0182, 1.0159, 1.0139, 1.0252, 1.0477, 1.0188, 1.0423, 1.0362, 0.9866, 1.0325, **Epoch: 70
1.0526, 1.0519, 1.0056, 1.0228, 1.0421, 1.0216, 1.0365, 1.0373, 0.9983, 1.0226, **Epoch: 80
1.0339, 1.0326, 1.0204, 1.0032, 0.9803, 1.0290, 0.9970, 0.9999, 1.0191, 0.9927, **Epoch: 90
1.0070, 0.9953, 1.0123, 1.0037, 0.9950, 1.0274, 1.0161, 0.9912, 1.0641, 1.0378, **Epoch: 100
1.0039, 0.9995, 0.9976, 1.0474, 1.0126, 0.9934, 1.0077, 0.9980, 1.0351, 1.0247, **Epoch: 110
1.0379, 1.0319, 1.0161, 1.0017, 1.0581, 1.0071, 0.9934, 1.0003, 1.0320, 1.0052, **Epoch: 120
1.0046, 1.0316, 1.0102, 0.9924, 1.0268, 1.0223, 0.9896, 0.9926, 1.0113, 1.0308, **Epoch: 130
1.0129, 1.0269, 0.9964, 0.9967, 0.9954, 1.0043, 1.0611, 1.0072, 0.9969, 1.0238, **Epoch: 140
0.9799, 1.0274, 1.0368, 1.0329, 1.0242, 0.9944, 1.0450, 0.9881, 0.9954, 1.0271, **Epoch: 150
1.0204, 1.0342, 1.0262, 1.0189, 0.9981, 1.0364, 1.0011, 1.0026, 1.0156, 1.0206, **Epoch: 160
1.0111, 1.0047, 1.0472, 1.0094, 1.0182, 1.0487, 0.9763, 1.0289, 1.0541, 1.0281, **Epoch: 170
0.9798, 1.0437, 0.9899, 1.0062, 1.0078, 0.9848, 1.0247, 0.9976, 1.0084, 1.0329, **Epoch: 180
1.0280, 1.0070, 1.0210, 1.0232, 0.9855, 1.0002, 1.0111, 1.0396, 0.9873, 1.0282, **Epoch: 190
1.0028, 1.0172, 1.0366, 1.0493, 1.0172, 1.0057, 0.9996, 1.0138, 1.0366, 1.0150, **Epoch: 200
Training Accuracy: 
0.7778, 0.8444, 0.8407, 0.8630, 0.8667, 0.8889, 0.8963, 0.8519, 0.8630, 0.8630, **Epoch: 10
0.8889, 0.9148, 0.8963, 0.9296, 0.9370, 0.9259, 0.9148, 0.8926, 0.9185, 0.9074, **Epoch: 20
0.9185, 0.9148, 0.9222, 0.9222, 0.9296, 0.9296, 0.9519, 0.9185, 0.9333, 0.9407, **Epoch: 30
0.9370, 0.9370, 0.9296, 0.9481, 0.9185, 0.9519, 0.9296, 0.9148, 0.9222, 0.9444, **Epoch: 40
0.9259, 0.9259, 0.9333, 0.9630, 0.9556, 0.9185, 0.9481, 0.9481, 0.9296, 0.9444, **Epoch: 50
0.9333, 0.9333, 0.9370, 0.9481, 0.9296, 0.9333, 0.9407, 0.9407, 0.9333, 0.9185, **Epoch: 60
0.9407, 0.9370, 0.9333, 0.9519, 0.9296, 0.9296, 0.9333, 0.9481, 0.9333, 0.9481, **Epoch: 70
0.9333, 0.9074, 0.8926, 0.9296, 0.9037, 0.9407, 0.9667, 0.9185, 0.9333, 0.9481, **Epoch: 80
0.9370, 0.9333, 0.9407, 0.9519, 0.9333, 0.9407, 0.9593, 0.9481, 0.9519, 0.9630, **Epoch: 90
0.9593, 0.9519, 0.9407, 0.9407, 0.9407, 0.9444, 0.9333, 0.9407, 0.9556, 0.9333, **Epoch: 100
0.9444, 0.9370, 0.9556, 0.9407, 0.9296, 0.9370, 0.9259, 0.9111, 0.9407, 0.9407, **Epoch: 110
0.9481, 0.9407, 0.9370, 0.9370, 0.9444, 0.9407, 0.9481, 0.9444, 0.9074, 0.9407, **Epoch: 120
0.9370, 0.9296, 0.9333, 0.9519, 0.9519, 0.9519, 0.9148, 0.9519, 0.9593, 0.9222, **Epoch: 130
0.9259, 0.9556, 0.9444, 0.9296, 0.9481, 0.9333, 0.9111, 0.9481, 0.9556, 0.9630, **Epoch: 140
0.9556, 0.9370, 0.9074, 0.9407, 0.9370, 0.9148, 0.9444, 0.9296, 0.9333, 0.9370, **Epoch: 150
0.9222, 0.9370, 0.9519, 0.9333, 0.9481, 0.9593, 0.9259, 0.9259, 0.9370, 0.9222, **Epoch: 160
0.9296, 0.9407, 0.9630, 0.9296, 0.9296, 0.9296, 0.9259, 0.9444, 0.9407, 0.9333, **Epoch: 170
0.9407, 0.9556, 0.9259, 0.9222, 0.9519, 0.9259, 0.9148, 0.9259, 0.9185, 0.9259, **Epoch: 180
0.9222, 0.9593, 0.9556, 0.9148, 0.9481, 0.9444, 0.9296, 0.9444, 0.9296, 0.9593, **Epoch: 190
0.9556, 0.9259, 0.9296, 0.9259, 0.9407, 0.9333, 0.9185, 0.9481, 0.9519, 0.9296, **Epoch: 200
Validation Accuracy: 
0.6337, 0.6883, 0.6876, 0.6846, 0.7061, 0.7127, 0.7075, 0.7164, 0.7053, 0.7171, **Epoch: 10
0.7120, 0.7127, 0.7097, 0.7142, 0.7275, 0.7068, 0.7016, 0.7208, 0.7134, 0.7009, **Epoch: 20
0.7238, 0.7194, 0.7134, 0.7009, 0.7149, 0.6987, 0.7016, 0.6972, 0.6920, 0.6987, **Epoch: 30
0.7068, 0.6965, 0.7134, 0.6994, 0.7097, 0.7068, 0.7186, 0.7046, 0.7164, 0.7223, **Epoch: 40
0.7216, 0.7075, 0.7179, 0.7009, 0.7120, 0.7216, 0.7194, 0.7201, 0.7097, 0.7112, **Epoch: 50
0.7127, 0.7127, 0.7127, 0.7157, 0.7230, 0.7208, 0.7068, 0.6994, 0.7097, 0.7157, **Epoch: 60
0.7186, 0.7075, 0.7171, 0.7105, 0.7216, 0.7171, 0.7194, 0.7127, 0.7223, 0.7171, **Epoch: 70
0.7186, 0.7149, 0.7134, 0.7194, 0.7149, 0.7297, 0.7349, 0.7319, 0.7171, 0.7216, **Epoch: 80
0.7245, 0.7290, 0.7142, 0.6994, 0.7112, 0.7120, 0.7001, 0.7201, 0.7097, 0.7282, **Epoch: 90
0.7223, 0.7164, 0.7208, 0.7267, 0.7083, 0.7201, 0.7157, 0.7097, 0.7223, 0.7186, **Epoch: 100
0.7105, 0.7164, 0.7186, 0.7142, 0.7127, 0.7245, 0.7075, 0.7253, 0.7053, 0.7275, **Epoch: 110
0.7142, 0.7061, 0.7371, 0.7186, 0.7304, 0.7216, 0.7046, 0.6987, 0.7097, 0.7216, **Epoch: 120
0.7112, 0.7090, 0.7223, 0.7223, 0.7245, 0.7149, 0.7186, 0.7341, 0.7127, 0.7164, **Epoch: 130
0.7164, 0.7363, 0.7031, 0.7208, 0.7282, 0.7186, 0.7120, 0.7090, 0.7297, 0.7105, **Epoch: 140
0.7282, 0.7238, 0.7068, 0.7157, 0.7319, 0.7179, 0.7157, 0.7194, 0.7046, 0.7312, **Epoch: 150
0.7105, 0.7068, 0.7134, 0.7297, 0.7149, 0.7260, 0.7127, 0.6935, 0.7260, 0.7090, **Epoch: 160
0.7142, 0.7179, 0.7149, 0.7238, 0.7024, 0.7341, 0.7260, 0.7216, 0.7105, 0.7142, **Epoch: 170
0.7312, 0.7179, 0.7120, 0.7304, 0.7208, 0.7171, 0.7186, 0.7194, 0.7112, 0.7097, **Epoch: 180
0.7230, 0.7216, 0.7216, 0.7112, 0.7282, 0.7134, 0.7253, 0.7216, 0.7230, 0.7061, **Epoch: 190
0.7253, 0.7075, 0.7083, 0.7171, 0.7201, 0.7046, 0.7230, 0.7260, 0.7157, 0.7090, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1523
Training Loss: 
1.9488, 1.6493, 1.5315, 1.4324, 1.3254, 1.2434, 1.0922, 1.0181, 0.9551, 0.8681, **Epoch: 10
0.7886, 0.7460, 0.6818, 0.6180, 0.6440, 0.5811, 0.5832, 0.4856, 0.4711, 0.4837, **Epoch: 20
0.4447, 0.4444, 0.4327, 0.4490, 0.3060, 0.3994, 0.3328, 0.4007, 0.3727, 0.3632, **Epoch: 30
0.3628, 0.3483, 0.2944, 0.3266, 0.3033, 0.3289, 0.3208, 0.3304, 0.3151, 0.3143, **Epoch: 40
0.3329, 0.3301, 0.2965, 0.2809, 0.3150, 0.3052, 0.3436, 0.2936, 0.2957, 0.3374, **Epoch: 50
0.2989, 0.3194, 0.2839, 0.2801, 0.3256, 0.3112, 0.3523, 0.3241, 0.3392, 0.2673, **Epoch: 60
0.2582, 0.3217, 0.3064, 0.2890, 0.2851, 0.3183, 0.2988, 0.2824, 0.2788, 0.3607, **Epoch: 70
0.3245, 0.3070, 0.3155, 0.2825, 0.3120, 0.3329, 0.2748, 0.3305, 0.2747, 0.2995, **Epoch: 80
0.3085, 0.2922, 0.3049, 0.3038, 0.3275, 0.3050, 0.2399, 0.3586, 0.2713, 0.2976, **Epoch: 90
0.2707, 0.2740, 0.3198, 0.2951, 0.2800, 0.3086, 0.3256, 0.2755, 0.2971, 0.2911, **Epoch: 100
0.3156, 0.2678, 0.3035, 0.3594, 0.3815, 0.2585, 0.2872, 0.2698, 0.3106, 0.3092, **Epoch: 110
0.3235, 0.3107, 0.2995, 0.2697, 0.2682, 0.3073, 0.2431, 0.2906, 0.3205, 0.3352, **Epoch: 120
0.2569, 0.3155, 0.2956, 0.3128, 0.3704, 0.2413, 0.2611, 0.3440, 0.2915, 0.3394, **Epoch: 130
0.2978, 0.2784, 0.3093, 0.3041, 0.3234, 0.3174, 0.2796, 0.2988, 0.2686, 0.3332, **Epoch: 140
0.3485, 0.3056, 0.3368, 0.3618, 0.2698, 0.2494, 0.3166, 0.3191, 0.2689, 0.3250, **Epoch: 150
0.3326, 0.3138, 0.3012, 0.2879, 0.3049, 0.3205, 0.3103, 0.3029, 0.3173, 0.3466, **Epoch: 160
0.3508, 0.3091, 0.2884, 0.3333, 0.2752, 0.2932, 0.2886, 0.3127, 0.3392, 0.2819, **Epoch: 170
0.2715, 0.3307, 0.3195, 0.3121, 0.3177, 0.3086, 0.2854, 0.3199, 0.2727, 0.2911, **Epoch: 180
0.2896, 0.2677, 0.3693, 0.3126, 0.2502, 0.2578, 0.2990, 0.2930, 0.2540, 0.2750, **Epoch: 190
0.3026, 0.3105, 0.2771, 0.2422, 0.2881, 0.2874, 0.2811, 0.3449, 0.3227, 0.2651, **Epoch: 200
Validation Loss: 
1.7223, 1.6363, 1.5536, 1.4932, 1.4208, 1.3496, 1.2758, 1.2232, 1.1828, 1.1371, **Epoch: 10
1.1045, 1.0664, 1.0475, 1.0271, 1.0080, 0.9826, 0.9504, 0.9723, 0.9503, 0.9430, **Epoch: 20
0.9466, 0.9081, 0.9131, 0.9276, 0.9013, 0.9120, 0.9218, 0.9134, 0.9318, 0.9455, **Epoch: 30
0.9818, 0.9903, 0.9679, 0.9655, 0.9334, 0.9800, 0.9575, 0.9625, 0.9831, 0.9355, **Epoch: 40
0.9488, 0.9619, 0.9387, 0.9463, 0.9239, 0.9744, 0.9819, 0.9898, 0.9199, 0.9544, **Epoch: 50
0.9879, 0.9436, 0.9411, 0.9291, 0.9536, 0.9311, 0.9484, 0.9442, 0.9341, 0.9433, **Epoch: 60
0.9507, 0.9634, 0.9461, 0.9426, 0.9394, 0.9896, 0.9899, 0.9762, 0.9840, 0.9534, **Epoch: 70
0.9473, 0.9479, 0.9561, 0.9431, 0.9673, 0.9784, 0.9559, 0.9566, 0.9296, 0.9415, **Epoch: 80
0.9604, 0.9773, 0.9561, 0.9285, 0.9612, 0.9692, 0.9222, 0.9482, 0.9958, 0.9313, **Epoch: 90
0.9631, 0.9225, 0.9350, 0.9211, 0.9001, 0.9784, 0.9150, 0.9033, 0.9842, 0.9705, **Epoch: 100
0.9260, 0.9774, 0.9287, 0.9562, 0.9257, 0.9595, 0.9451, 0.9699, 0.9177, 0.9617, **Epoch: 110
0.9634, 0.9022, 0.9343, 0.9782, 0.9714, 0.9330, 0.9531, 0.9602, 0.9496, 0.9606, **Epoch: 120
0.9652, 0.9335, 0.9435, 0.9577, 0.9645, 0.9789, 0.9767, 0.9446, 0.9634, 0.9651, **Epoch: 130
0.9926, 0.9471, 0.9698, 0.9440, 0.9420, 0.9820, 0.9450, 0.9458, 0.9582, 0.9576, **Epoch: 140
0.9392, 0.9810, 0.9480, 0.9257, 0.9731, 0.9759, 0.9409, 0.9624, 0.9648, 0.9783, **Epoch: 150
0.9372, 0.9532, 0.9652, 0.9582, 0.9521, 0.9644, 0.9944, 0.9283, 0.9749, 0.9535, **Epoch: 160
0.9549, 0.9305, 0.9281, 0.9724, 0.9506, 0.9546, 0.9463, 0.9815, 0.9572, 0.9501, **Epoch: 170
0.9458, 0.9420, 0.9623, 0.9746, 0.9649, 0.9852, 0.9490, 0.9409, 0.9573, 0.9587, **Epoch: 180
0.9209, 0.9492, 0.9211, 0.9559, 0.9518, 0.9647, 0.9499, 0.9446, 0.9073, 0.9457, **Epoch: 190
0.9396, 0.9497, 0.9453, 0.9330, 0.9359, 0.9193, 0.9784, 0.9291, 0.9357, 0.9779, **Epoch: 200
Training Accuracy: 
0.8037, 0.8407, 0.8741, 0.8815, 0.9111, 0.9296, 0.8889, 0.8926, 0.9074, 0.9148, **Epoch: 10
0.9074, 0.9333, 0.9259, 0.9222, 0.8963, 0.9037, 0.9148, 0.9111, 0.9148, 0.9074, **Epoch: 20
0.9148, 0.8963, 0.9296, 0.9481, 0.9370, 0.9333, 0.9222, 0.9481, 0.9296, 0.9444, **Epoch: 30
0.9185, 0.9481, 0.9148, 0.9370, 0.9074, 0.9630, 0.9148, 0.9481, 0.9481, 0.9481, **Epoch: 40
0.9148, 0.9259, 0.9333, 0.9370, 0.9556, 0.9222, 0.9222, 0.9444, 0.9222, 0.9148, **Epoch: 50
0.9333, 0.9444, 0.9519, 0.9444, 0.9407, 0.9407, 0.9222, 0.9111, 0.9519, 0.9407, **Epoch: 60
0.9222, 0.9296, 0.9296, 0.9259, 0.9370, 0.9370, 0.9519, 0.9407, 0.9370, 0.9333, **Epoch: 70
0.9444, 0.9481, 0.9074, 0.9407, 0.9074, 0.9185, 0.9519, 0.9222, 0.9593, 0.9481, **Epoch: 80
0.9259, 0.9370, 0.9333, 0.9259, 0.9370, 0.9259, 0.9333, 0.9481, 0.9481, 0.9444, **Epoch: 90
0.9667, 0.9370, 0.9296, 0.9148, 0.9185, 0.9370, 0.9444, 0.9407, 0.9074, 0.9259, **Epoch: 100
0.9407, 0.9407, 0.9185, 0.8963, 0.9333, 0.9222, 0.9444, 0.9185, 0.9259, 0.9222, **Epoch: 110
0.9407, 0.9259, 0.9259, 0.9259, 0.9519, 0.8963, 0.9593, 0.9667, 0.9333, 0.9259, **Epoch: 120
0.9481, 0.9111, 0.9481, 0.9296, 0.9519, 0.9296, 0.9222, 0.9370, 0.9407, 0.9593, **Epoch: 130
0.9481, 0.9519, 0.9444, 0.9370, 0.9000, 0.9259, 0.9444, 0.9296, 0.9481, 0.9481, **Epoch: 140
0.9519, 0.9259, 0.9481, 0.9407, 0.9296, 0.9296, 0.9481, 0.9370, 0.9333, 0.9444, **Epoch: 150
0.9185, 0.9111, 0.9259, 0.9259, 0.9185, 0.9481, 0.9370, 0.9370, 0.9148, 0.9222, **Epoch: 160
0.9296, 0.9296, 0.9222, 0.9481, 0.9407, 0.9407, 0.9370, 0.9296, 0.9444, 0.9259, **Epoch: 170
0.9259, 0.9593, 0.9444, 0.9519, 0.9519, 0.9296, 0.9481, 0.9593, 0.9370, 0.9370, **Epoch: 180
0.9481, 0.9296, 0.9037, 0.9444, 0.9407, 0.9407, 0.9407, 0.9407, 0.9407, 0.9333, **Epoch: 190
0.9259, 0.9333, 0.9296, 0.9444, 0.9370, 0.9556, 0.9037, 0.9407, 0.9259, 0.9296, **Epoch: 200
Validation Accuracy: 
0.6329, 0.6905, 0.7031, 0.7164, 0.7090, 0.7208, 0.7179, 0.7216, 0.7201, 0.7090, **Epoch: 10
0.7363, 0.7393, 0.7341, 0.7408, 0.7408, 0.7334, 0.7400, 0.7526, 0.7555, 0.7282, **Epoch: 20
0.7437, 0.7275, 0.7356, 0.7363, 0.7326, 0.7363, 0.7223, 0.7304, 0.7282, 0.7238, **Epoch: 30
0.7201, 0.7245, 0.7179, 0.7216, 0.7112, 0.7120, 0.7223, 0.7112, 0.7356, 0.7194, **Epoch: 40
0.7290, 0.7356, 0.7149, 0.7349, 0.7334, 0.7452, 0.7304, 0.7341, 0.7179, 0.7201, **Epoch: 50
0.7260, 0.7378, 0.7319, 0.7467, 0.7282, 0.7356, 0.7319, 0.7186, 0.7334, 0.7496, **Epoch: 60
0.7142, 0.7304, 0.7304, 0.7267, 0.7253, 0.7386, 0.7253, 0.7245, 0.7504, 0.7400, **Epoch: 70
0.7356, 0.7290, 0.7408, 0.7238, 0.7319, 0.7253, 0.7415, 0.7208, 0.7260, 0.7496, **Epoch: 80
0.7230, 0.7297, 0.7304, 0.7341, 0.7208, 0.7326, 0.7171, 0.7349, 0.7201, 0.7275, **Epoch: 90
0.7149, 0.7356, 0.7319, 0.7297, 0.7334, 0.7349, 0.7312, 0.7297, 0.7326, 0.7386, **Epoch: 100
0.7326, 0.7349, 0.7319, 0.7363, 0.7245, 0.7260, 0.7371, 0.7208, 0.7349, 0.7312, **Epoch: 110
0.7230, 0.7363, 0.7260, 0.7194, 0.7312, 0.7201, 0.7149, 0.7326, 0.7216, 0.7275, **Epoch: 120
0.7393, 0.7326, 0.7282, 0.7223, 0.7319, 0.7459, 0.7312, 0.7356, 0.7312, 0.7304, **Epoch: 130
0.7223, 0.7304, 0.7334, 0.7371, 0.7482, 0.7312, 0.7386, 0.7312, 0.7341, 0.7430, **Epoch: 140
0.7386, 0.7245, 0.7459, 0.7474, 0.7267, 0.7334, 0.7238, 0.7349, 0.7378, 0.7482, **Epoch: 150
0.7290, 0.7452, 0.7422, 0.7223, 0.7245, 0.7179, 0.7371, 0.7430, 0.7430, 0.7349, **Epoch: 160
0.7356, 0.7459, 0.7171, 0.7245, 0.7304, 0.7326, 0.7223, 0.7312, 0.7260, 0.7445, **Epoch: 170
0.7459, 0.7378, 0.7230, 0.7349, 0.7253, 0.7223, 0.7371, 0.7127, 0.7400, 0.7201, **Epoch: 180
0.7201, 0.7171, 0.7068, 0.7326, 0.7326, 0.7105, 0.7467, 0.7319, 0.7304, 0.7105, **Epoch: 190
0.7179, 0.7267, 0.7422, 0.7179, 0.7297, 0.7290, 0.7267, 0.7319, 0.7386, 0.7267, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1530
Training Loss: 
1.9712, 1.6647, 1.5593, 1.4883, 1.3788, 1.2620, 1.1550, 1.1157, 0.9810, 0.9198, **Epoch: 10
0.8876, 0.7918, 0.7543, 0.6495, 0.6426, 0.5235, 0.5971, 0.5535, 0.4975, 0.5200, **Epoch: 20
0.4340, 0.4650, 0.4244, 0.4411, 0.3729, 0.3987, 0.3580, 0.3302, 0.3662, 0.3770, **Epoch: 30
0.2845, 0.3294, 0.3434, 0.3885, 0.3173, 0.3161, 0.3378, 0.2871, 0.3100, 0.3044, **Epoch: 40
0.3625, 0.2674, 0.3601, 0.2906, 0.3319, 0.2983, 0.3234, 0.3247, 0.2793, 0.3167, **Epoch: 50
0.3289, 0.3087, 0.3093, 0.3345, 0.2984, 0.2993, 0.2710, 0.2313, 0.3278, 0.2711, **Epoch: 60
0.2995, 0.3167, 0.2629, 0.2602, 0.2997, 0.3214, 0.3108, 0.2934, 0.3436, 0.3281, **Epoch: 70
0.2978, 0.2673, 0.3534, 0.2810, 0.2866, 0.2713, 0.3084, 0.2980, 0.2852, 0.2848, **Epoch: 80
0.2942, 0.3400, 0.2602, 0.2371, 0.2893, 0.3318, 0.2837, 0.3503, 0.3070, 0.2640, **Epoch: 90
0.3130, 0.2216, 0.2379, 0.3162, 0.3135, 0.3362, 0.2823, 0.2831, 0.2992, 0.2859, **Epoch: 100
0.3331, 0.2957, 0.2694, 0.2882, 0.3161, 0.2540, 0.2574, 0.2999, 0.2829, 0.2770, **Epoch: 110
0.2813, 0.2766, 0.2772, 0.3087, 0.2820, 0.2918, 0.2821, 0.3016, 0.3034, 0.2769, **Epoch: 120
0.2874, 0.3082, 0.2609, 0.2917, 0.2612, 0.2945, 0.2662, 0.2976, 0.2597, 0.3222, **Epoch: 130
0.3250, 0.3229, 0.3035, 0.3047, 0.2758, 0.2994, 0.3308, 0.2451, 0.2760, 0.3173, **Epoch: 140
0.2668, 0.2978, 0.3147, 0.2688, 0.2524, 0.3561, 0.3180, 0.2648, 0.2629, 0.2756, **Epoch: 150
0.3016, 0.2539, 0.2733, 0.2755, 0.3088, 0.3382, 0.3254, 0.2686, 0.3081, 0.2868, **Epoch: 160
0.2606, 0.3510, 0.2458, 0.2936, 0.2595, 0.2615, 0.2597, 0.3100, 0.2495, 0.2762, **Epoch: 170
0.3167, 0.2728, 0.2977, 0.3453, 0.2694, 0.2391, 0.3385, 0.2927, 0.3317, 0.2894, **Epoch: 180
0.2791, 0.3051, 0.2925, 0.3532, 0.2915, 0.2915, 0.2760, 0.2604, 0.2924, 0.3241, **Epoch: 190
0.3046, 0.2532, 0.3078, 0.3122, 0.2499, 0.3196, 0.3357, 0.3148, 0.2714, 0.2470, **Epoch: 200
Validation Loss: 
1.7408, 1.6633, 1.5929, 1.5122, 1.4627, 1.4030, 1.3367, 1.2837, 1.2291, 1.1865, **Epoch: 10
1.1375, 1.0970, 1.0796, 1.0624, 1.0543, 1.0232, 0.9732, 1.0083, 0.9664, 0.9424, **Epoch: 20
0.9458, 0.9116, 0.9240, 0.9104, 0.9116, 0.9122, 0.9218, 0.9286, 0.8941, 0.9433, **Epoch: 30
0.9116, 0.9553, 0.9563, 0.9407, 0.9048, 0.9220, 0.9773, 0.9730, 0.9398, 0.9622, **Epoch: 40
0.9601, 0.9387, 0.9331, 0.9825, 0.9513, 0.9112, 0.9537, 0.9380, 0.9192, 0.9378, **Epoch: 50
0.9372, 0.9084, 0.9401, 0.9608, 0.8998, 0.9171, 0.9625, 0.9122, 0.9600, 0.9345, **Epoch: 60
0.9260, 0.9389, 0.9015, 0.9867, 0.9268, 0.9230, 0.9214, 0.9310, 0.9175, 0.9232, **Epoch: 70
0.9185, 0.9057, 0.9352, 0.9753, 0.9321, 0.9277, 0.9238, 0.9333, 0.9083, 0.9582, **Epoch: 80
0.9257, 0.9266, 0.9353, 0.9064, 0.9776, 0.8970, 0.9526, 0.9231, 0.9245, 0.9237, **Epoch: 90
0.9531, 0.9122, 0.9322, 0.9114, 0.8814, 0.9199, 0.8978, 0.9236, 0.9273, 0.9155, **Epoch: 100
0.8985, 0.9172, 0.9231, 0.9471, 0.9387, 0.9086, 0.8993, 0.9241, 0.9312, 0.9370, **Epoch: 110
0.9683, 0.9631, 0.9386, 0.9367, 0.9506, 0.9332, 0.9233, 0.9104, 0.9390, 0.9396, **Epoch: 120
0.9345, 0.9525, 0.9094, 0.9098, 0.9368, 0.9424, 0.9695, 0.9222, 0.9121, 0.9503, **Epoch: 130
0.9231, 0.9587, 0.9683, 0.9788, 0.9064, 0.9348, 0.9165, 0.9613, 0.9138, 0.9171, **Epoch: 140
0.9247, 0.9115, 0.9526, 0.9471, 0.9072, 0.9163, 0.9386, 0.9640, 0.9154, 0.9414, **Epoch: 150
0.9275, 0.8867, 0.9512, 0.9447, 0.9379, 0.9762, 0.9217, 0.9363, 0.9352, 0.9252, **Epoch: 160
0.9288, 0.9486, 0.9237, 0.9126, 0.8936, 0.9233, 0.9824, 0.9809, 0.9800, 0.9212, **Epoch: 170
0.9279, 0.9570, 0.9689, 0.9226, 0.9153, 0.9323, 0.9250, 0.9595, 0.9578, 0.9028, **Epoch: 180
0.9480, 0.9684, 0.9652, 0.9483, 0.9272, 0.9190, 0.9251, 0.9776, 0.9231, 0.9412, **Epoch: 190
0.9526, 0.9444, 0.9241, 0.9558, 0.9638, 0.8999, 0.9322, 0.9258, 0.9130, 0.9578, **Epoch: 200
Training Accuracy: 
0.7444, 0.8185, 0.8630, 0.8630, 0.8259, 0.8741, 0.8778, 0.8852, 0.8815, 0.9074, **Epoch: 10
0.8963, 0.8778, 0.9148, 0.9370, 0.9074, 0.9333, 0.9519, 0.9259, 0.9037, 0.9593, **Epoch: 20
0.9148, 0.9333, 0.9185, 0.9333, 0.9074, 0.9407, 0.9222, 0.9296, 0.9185, 0.9148, **Epoch: 30
0.9259, 0.9222, 0.9222, 0.9370, 0.8815, 0.9370, 0.9370, 0.8963, 0.9481, 0.9296, **Epoch: 40
0.9037, 0.9148, 0.9222, 0.9519, 0.9296, 0.9370, 0.9481, 0.9148, 0.9333, 0.9370, **Epoch: 50
0.9407, 0.9481, 0.9333, 0.9444, 0.9444, 0.9444, 0.9407, 0.9185, 0.9259, 0.9296, **Epoch: 60
0.9259, 0.9222, 0.9333, 0.9407, 0.9296, 0.9222, 0.9519, 0.9593, 0.9222, 0.9370, **Epoch: 70
0.9444, 0.9333, 0.9296, 0.9370, 0.9519, 0.9593, 0.9370, 0.9370, 0.9481, 0.9481, **Epoch: 80
0.9074, 0.9556, 0.9296, 0.9444, 0.9259, 0.9259, 0.9222, 0.9222, 0.9296, 0.9481, **Epoch: 90
0.9185, 0.9556, 0.9444, 0.9519, 0.9370, 0.9481, 0.9296, 0.9148, 0.9074, 0.9444, **Epoch: 100
0.9111, 0.9185, 0.9593, 0.9519, 0.9185, 0.9333, 0.9444, 0.9222, 0.9296, 0.9815, **Epoch: 110
0.9370, 0.9296, 0.9222, 0.9259, 0.9407, 0.9333, 0.9185, 0.9074, 0.9148, 0.9481, **Epoch: 120
0.9370, 0.9481, 0.9556, 0.9259, 0.9222, 0.9407, 0.9370, 0.9259, 0.9333, 0.9370, **Epoch: 130
0.9519, 0.9593, 0.9370, 0.9333, 0.9259, 0.9333, 0.9296, 0.9333, 0.9370, 0.9148, **Epoch: 140
0.9481, 0.9407, 0.9407, 0.9333, 0.9370, 0.9481, 0.9222, 0.9222, 0.9259, 0.9148, **Epoch: 150
0.9481, 0.8963, 0.9296, 0.9370, 0.9333, 0.9407, 0.9481, 0.9407, 0.9407, 0.9519, **Epoch: 160
0.9074, 0.9407, 0.9296, 0.9481, 0.9519, 0.9407, 0.9370, 0.9407, 0.9259, 0.9333, **Epoch: 170
0.9370, 0.9148, 0.9556, 0.9407, 0.9296, 0.9296, 0.9296, 0.9296, 0.9667, 0.9444, **Epoch: 180
0.9037, 0.9444, 0.9556, 0.9296, 0.9407, 0.9407, 0.9370, 0.9333, 0.9481, 0.9111, **Epoch: 190
0.9148, 0.9259, 0.9444, 0.9370, 0.8963, 0.9370, 0.9519, 0.9222, 0.9259, 0.9519, **Epoch: 200
Validation Accuracy: 
0.6049, 0.6521, 0.6610, 0.6713, 0.7001, 0.7053, 0.7016, 0.6802, 0.6994, 0.6869, **Epoch: 10
0.7090, 0.7275, 0.7134, 0.7097, 0.7068, 0.6987, 0.7149, 0.7112, 0.7179, 0.7230, **Epoch: 20
0.7245, 0.7186, 0.7127, 0.7312, 0.7260, 0.7363, 0.7282, 0.7208, 0.7326, 0.7290, **Epoch: 30
0.7194, 0.7164, 0.7134, 0.7371, 0.7216, 0.7149, 0.7290, 0.7304, 0.7208, 0.7260, **Epoch: 40
0.7164, 0.7459, 0.7363, 0.7297, 0.7201, 0.7275, 0.7312, 0.7341, 0.7496, 0.7356, **Epoch: 50
0.7304, 0.7356, 0.7386, 0.7267, 0.7304, 0.7194, 0.7290, 0.7297, 0.7326, 0.7304, **Epoch: 60
0.7097, 0.7282, 0.7253, 0.7312, 0.7275, 0.7371, 0.7504, 0.7186, 0.7201, 0.7371, **Epoch: 70
0.7201, 0.7179, 0.7208, 0.7459, 0.7297, 0.7319, 0.7282, 0.7164, 0.7230, 0.7290, **Epoch: 80
0.7386, 0.7275, 0.7238, 0.7230, 0.7326, 0.7245, 0.7452, 0.7230, 0.7208, 0.7393, **Epoch: 90
0.7245, 0.7208, 0.7253, 0.7371, 0.7363, 0.7171, 0.7304, 0.7319, 0.7230, 0.7267, **Epoch: 100
0.7312, 0.7164, 0.7179, 0.7245, 0.7208, 0.7097, 0.7393, 0.7201, 0.7341, 0.7290, **Epoch: 110
0.7179, 0.7179, 0.7134, 0.7312, 0.7297, 0.7319, 0.7378, 0.7341, 0.7230, 0.7304, **Epoch: 120
0.7363, 0.7341, 0.7282, 0.7105, 0.7363, 0.7363, 0.7127, 0.7142, 0.7319, 0.7260, **Epoch: 130
0.7290, 0.7378, 0.7312, 0.7400, 0.7482, 0.7208, 0.7363, 0.7075, 0.7341, 0.7452, **Epoch: 140
0.7415, 0.7105, 0.7297, 0.7208, 0.7260, 0.7282, 0.7363, 0.7127, 0.7312, 0.7238, **Epoch: 150
0.7437, 0.7378, 0.7238, 0.7386, 0.7223, 0.7312, 0.7326, 0.7245, 0.7216, 0.7319, **Epoch: 160
0.7349, 0.7363, 0.7275, 0.7326, 0.7194, 0.7363, 0.7290, 0.7164, 0.7245, 0.7238, **Epoch: 170
0.7260, 0.7356, 0.7326, 0.7267, 0.7260, 0.7171, 0.7230, 0.7179, 0.7297, 0.7378, **Epoch: 180
0.7290, 0.7194, 0.7290, 0.7171, 0.7312, 0.7238, 0.7363, 0.7157, 0.7334, 0.7290, **Epoch: 190
0.7304, 0.7194, 0.7290, 0.7194, 0.7356, 0.7393, 0.7216, 0.7326, 0.7238, 0.7356, **Epoch: 200
----------------------------------------------------------
Time: 0510-1530
Training Loss: 
1.9712, 1.7029, 1.5931, 1.4890, 1.3888, 1.2880, 1.1554, 1.0938, 1.0278, 0.9393, **Epoch: 10
0.8490, 0.7756, 0.6984, 0.6946, 0.6309, 0.5904, 0.5396, 0.5103, 0.5194, 0.5354, **Epoch: 20
0.3895, 0.4463, 0.4797, 0.4316, 0.3719, 0.4374, 0.3561, 0.3249, 0.3071, 0.3502, **Epoch: 30
0.3764, 0.3572, 0.3557, 0.4304, 0.3521, 0.3666, 0.3965, 0.3398, 0.3088, 0.2866, **Epoch: 40
0.3245, 0.2870, 0.4142, 0.2696, 0.3156, 0.3633, 0.3104, 0.2597, 0.2742, 0.2506, **Epoch: 50
0.3163, 0.3012, 0.3241, 0.2754, 0.3062, 0.2783, 0.3473, 0.3392, 0.2581, 0.3327, **Epoch: 60
0.3349, 0.3230, 0.3001, 0.2930, 0.3089, 0.2845, 0.2766, 0.3147, 0.3177, 0.2888, **Epoch: 70
0.2720, 0.2642, 0.2786, 0.3586, 0.3263, 0.3032, 0.2989, 0.3304, 0.2504, 0.2617, **Epoch: 80
0.2869, 0.2848, 0.3110, 0.3039, 0.2606, 0.3008, 0.3176, 0.2599, 0.2444, 0.2336, **Epoch: 90
0.3243, 0.2917, 0.2591, 0.2392, 0.3085, 0.2474, 0.3267, 0.2986, 0.2815, 0.3249, **Epoch: 100
0.3223, 0.2624, 0.2655, 0.2900, 0.2540, 0.2416, 0.3445, 0.2728, 0.2988, 0.3098, **Epoch: 110
0.2804, 0.3333, 0.2850, 0.3410, 0.3262, 0.2917, 0.2932, 0.3021, 0.3285, 0.3360, **Epoch: 120
0.3269, 0.3064, 0.3162, 0.3734, 0.3234, 0.2824, 0.3309, 0.2763, 0.2729, 0.3154, **Epoch: 130
0.2927, 0.2655, 0.2737, 0.2388, 0.2623, 0.3441, 0.2788, 0.2866, 0.2865, 0.2695, **Epoch: 140
0.2397, 0.3066, 0.2900, 0.2823, 0.2994, 0.2775, 0.2489, 0.2728, 0.2958, 0.3141, **Epoch: 150
0.2994, 0.3631, 0.3217, 0.2364, 0.3072, 0.2821, 0.3166, 0.2758, 0.3121, 0.3122, **Epoch: 160
0.2563, 0.2497, 0.2997, 0.3189, 0.2628, 0.2659, 0.2706, 0.2947, 0.3556, 0.3402, **Epoch: 170
0.2385, 0.3089, 0.2884, 0.2777, 0.2698, 0.2606, 0.3407, 0.3721, 0.2534, 0.2889, **Epoch: 180
0.3148, 0.3162, 0.3352, 0.2361, 0.2871, 0.2755, 0.2427, 0.2803, 0.3122, 0.2839, **Epoch: 190
0.3446, 0.3005, 0.2827, 0.2622, 0.3331, 0.2556, 0.2791, 0.3273, 0.3370, 0.2913, **Epoch: 200
Validation Loss: 
1.7517, 1.6890, 1.6096, 1.5354, 1.4686, 1.3972, 1.3377, 1.2898, 1.2118, 1.1644, **Epoch: 10
1.1328, 1.0728, 1.0567, 1.0219, 0.9959, 0.9886, 0.9398, 0.9495, 0.9863, 0.9221, **Epoch: 20
0.9214, 0.9221, 0.9273, 0.9620, 0.9356, 0.9382, 0.9732, 0.9235, 0.9114, 0.9071, **Epoch: 30
0.9436, 0.9299, 0.9509, 0.9416, 0.9386, 0.9607, 0.9743, 0.9787, 0.9609, 0.9755, **Epoch: 40
0.9369, 0.9394, 1.0011, 0.9696, 0.9410, 0.9371, 0.9390, 0.9627, 0.9361, 0.9441, **Epoch: 50
0.8982, 0.8890, 0.8984, 0.9369, 0.9042, 0.8875, 0.8884, 0.9657, 0.8978, 0.8957, **Epoch: 60
0.9420, 0.9210, 0.9456, 0.9157, 0.8966, 0.9088, 0.9090, 0.8988, 0.9139, 0.8924, **Epoch: 70
0.8950, 0.9119, 0.9119, 0.9370, 0.9042, 0.9424, 0.9302, 0.9292, 0.9560, 0.9079, **Epoch: 80
0.8696, 0.9194, 0.9326, 0.9482, 0.9263, 0.9117, 0.8981, 0.9101, 0.9193, 0.8876, **Epoch: 90
0.9001, 0.9081, 0.9144, 0.9326, 0.9222, 0.9872, 0.9536, 0.9552, 0.9653, 0.9199, **Epoch: 100
0.9302, 0.9408, 0.9381, 0.9081, 0.9172, 0.9008, 0.9055, 0.9209, 0.9120, 0.9421, **Epoch: 110
0.8888, 0.9384, 0.8886, 0.9083, 0.9272, 0.9356, 0.8923, 0.9093, 0.9119, 0.8762, **Epoch: 120
0.9180, 0.8871, 0.9421, 0.9158, 0.9089, 0.9320, 0.9452, 0.9147, 0.8837, 0.9484, **Epoch: 130
0.9591, 0.9209, 0.9390, 0.9250, 0.9460, 0.9324, 0.9104, 0.9444, 0.9013, 0.9437, **Epoch: 140
0.9257, 0.8828, 0.9273, 0.8861, 0.9080, 0.8876, 0.8911, 0.8823, 0.9173, 0.9461, **Epoch: 150
0.9345, 0.9169, 0.8866, 0.9081, 0.9433, 0.9115, 0.9164, 0.9551, 0.9565, 0.9272, **Epoch: 160
0.9064, 0.9496, 0.9106, 0.8928, 0.9318, 0.9374, 0.9100, 0.9148, 0.9052, 0.9272, **Epoch: 170
0.8996, 0.9569, 0.9666, 0.9386, 0.9255, 0.8984, 0.8935, 0.9214, 0.9141, 0.9542, **Epoch: 180
0.9306, 0.9339, 0.8965, 0.9302, 0.9068, 0.9166, 0.8834, 0.9029, 0.9146, 0.9549, **Epoch: 190
0.8875, 0.9556, 0.9351, 0.9397, 0.9394, 0.9284, 0.9284, 0.9732, 0.9286, 0.8837, **Epoch: 200
Training Accuracy: 
0.6963, 0.8074, 0.8704, 0.8667, 0.8778, 0.9111, 0.8815, 0.8667, 0.9148, 0.9074, **Epoch: 10
0.9259, 0.9407, 0.9037, 0.9259, 0.9296, 0.9296, 0.9111, 0.9222, 0.9074, 0.9296, **Epoch: 20
0.9296, 0.9370, 0.9111, 0.9259, 0.9148, 0.9370, 0.9148, 0.9333, 0.9296, 0.9259, **Epoch: 30
0.9074, 0.9407, 0.9556, 0.9222, 0.9296, 0.9185, 0.9333, 0.9481, 0.9519, 0.9259, **Epoch: 40
0.9259, 0.9259, 0.9407, 0.9333, 0.9111, 0.9296, 0.9296, 0.9111, 0.9444, 0.9333, **Epoch: 50
0.9333, 0.9704, 0.9407, 0.9519, 0.9407, 0.9296, 0.9296, 0.9222, 0.9185, 0.9296, **Epoch: 60
0.9667, 0.9481, 0.9370, 0.9481, 0.9556, 0.9556, 0.9333, 0.9333, 0.9370, 0.9370, **Epoch: 70
0.9148, 0.9148, 0.9481, 0.9556, 0.9259, 0.9593, 0.9333, 0.9370, 0.9222, 0.9556, **Epoch: 80
0.9407, 0.9519, 0.9407, 0.9296, 0.9370, 0.9481, 0.9407, 0.9333, 0.9222, 0.9296, **Epoch: 90
0.9407, 0.9222, 0.9296, 0.9519, 0.9185, 0.9185, 0.9556, 0.9296, 0.9111, 0.9185, **Epoch: 100
0.9259, 0.9407, 0.9370, 0.9556, 0.9333, 0.9481, 0.9148, 0.9148, 0.9296, 0.9296, **Epoch: 110
0.9259, 0.9370, 0.9444, 0.9370, 0.9333, 0.9444, 0.9296, 0.9370, 0.9630, 0.9481, **Epoch: 120
0.9296, 0.9222, 0.9370, 0.9593, 0.9185, 0.9519, 0.9333, 0.9370, 0.9704, 0.9148, **Epoch: 130
0.9333, 0.9111, 0.9815, 0.9444, 0.9444, 0.9556, 0.9667, 0.9296, 0.9593, 0.9111, **Epoch: 140
0.9593, 0.9333, 0.9296, 0.9222, 0.9407, 0.9259, 0.9593, 0.9407, 0.9259, 0.9259, **Epoch: 150
0.9407, 0.9407, 0.9333, 0.9296, 0.9259, 0.9370, 0.9296, 0.9222, 0.9370, 0.9519, **Epoch: 160
0.9333, 0.9444, 0.9148, 0.9556, 0.9185, 0.9259, 0.9481, 0.9296, 0.9222, 0.9370, **Epoch: 170
0.9333, 0.9481, 0.9407, 0.9296, 0.9296, 0.9074, 0.9370, 0.9333, 0.9222, 0.9630, **Epoch: 180
0.9296, 0.9296, 0.9333, 0.9630, 0.9556, 0.9296, 0.9407, 0.9667, 0.9111, 0.9519, **Epoch: 190
0.9519, 0.9556, 0.9111, 0.9333, 0.9296, 0.9296, 0.9370, 0.9148, 0.9222, 0.9370, **Epoch: 200
Validation Accuracy: 
0.6174, 0.6736, 0.6817, 0.7001, 0.7179, 0.7142, 0.7326, 0.7157, 0.7275, 0.7290, **Epoch: 10
0.7290, 0.7282, 0.7496, 0.7378, 0.7201, 0.7541, 0.7511, 0.7651, 0.7504, 0.7570, **Epoch: 20
0.7171, 0.7275, 0.7334, 0.7275, 0.7230, 0.7290, 0.7356, 0.7319, 0.7334, 0.7290, **Epoch: 30
0.7186, 0.7319, 0.7216, 0.7267, 0.7275, 0.7267, 0.7304, 0.7334, 0.7253, 0.7186, **Epoch: 40
0.7164, 0.7083, 0.7216, 0.7120, 0.7349, 0.7371, 0.7326, 0.7253, 0.7341, 0.7319, **Epoch: 50
0.7208, 0.7282, 0.7201, 0.7097, 0.7378, 0.7186, 0.7267, 0.7304, 0.7120, 0.7334, **Epoch: 60
0.7238, 0.7363, 0.7504, 0.7208, 0.7230, 0.7452, 0.7371, 0.7297, 0.7334, 0.7408, **Epoch: 70
0.7334, 0.7230, 0.7452, 0.7363, 0.7363, 0.7371, 0.7467, 0.7194, 0.7393, 0.7171, **Epoch: 80
0.7230, 0.7216, 0.7282, 0.7341, 0.7422, 0.7415, 0.7341, 0.7326, 0.7326, 0.7496, **Epoch: 90
0.7216, 0.7356, 0.7275, 0.7349, 0.7275, 0.7334, 0.7164, 0.7341, 0.7275, 0.7230, **Epoch: 100
0.7312, 0.7304, 0.7171, 0.7304, 0.7386, 0.7304, 0.7341, 0.7400, 0.7341, 0.7319, **Epoch: 110
0.7400, 0.7415, 0.7386, 0.7179, 0.7408, 0.7282, 0.7186, 0.7290, 0.7445, 0.7467, **Epoch: 120
0.7393, 0.7326, 0.7312, 0.7378, 0.7408, 0.7341, 0.7297, 0.7223, 0.7334, 0.7216, **Epoch: 130
0.7334, 0.7267, 0.7334, 0.7260, 0.7393, 0.7216, 0.7157, 0.7386, 0.7253, 0.7459, **Epoch: 140
0.7415, 0.7452, 0.7518, 0.7290, 0.7415, 0.7326, 0.7290, 0.7275, 0.7253, 0.7216, **Epoch: 150
0.7312, 0.7282, 0.7312, 0.7378, 0.7194, 0.7386, 0.7127, 0.7326, 0.7482, 0.7312, **Epoch: 160
0.7341, 0.7267, 0.7290, 0.7267, 0.7334, 0.7349, 0.7319, 0.7326, 0.7400, 0.7238, **Epoch: 170
0.7363, 0.7290, 0.7253, 0.7518, 0.7312, 0.7430, 0.7171, 0.7474, 0.7415, 0.7408, **Epoch: 180
0.7312, 0.7371, 0.7238, 0.7216, 0.7297, 0.7386, 0.7378, 0.7245, 0.7290, 0.7171, **Epoch: 190
0.7253, 0.7400, 0.7312, 0.7253, 0.7422, 0.7223, 0.7334, 0.7297, 0.7393, 0.7422, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1531
Training Loss: 
1.9556, 1.6533, 1.5591, 1.4806, 1.3799, 1.2691, 1.1582, 1.0333, 0.9960, 0.8610, **Epoch: 10
0.8481, 0.7508, 0.7343, 0.6085, 0.5786, 0.5868, 0.5914, 0.5542, 0.4833, 0.4988, **Epoch: 20
0.4886, 0.4132, 0.3789, 0.4074, 0.4347, 0.3790, 0.4249, 0.4018, 0.3601, 0.3784, **Epoch: 30
0.3248, 0.3107, 0.3324, 0.4105, 0.3328, 0.4056, 0.3483, 0.3648, 0.3217, 0.3216, **Epoch: 40
0.3040, 0.3692, 0.3170, 0.3881, 0.2884, 0.3045, 0.3206, 0.3020, 0.3484, 0.3240, **Epoch: 50
0.3181, 0.3354, 0.3530, 0.3005, 0.3533, 0.3035, 0.2903, 0.2544, 0.2695, 0.3385, **Epoch: 60
0.2972, 0.2796, 0.3178, 0.3041, 0.2984, 0.3390, 0.3305, 0.3083, 0.3372, 0.3372, **Epoch: 70
0.2658, 0.3212, 0.3436, 0.2794, 0.3355, 0.2947, 0.3255, 0.3294, 0.2888, 0.3372, **Epoch: 80
0.3795, 0.3078, 0.3107, 0.3367, 0.3344, 0.3097, 0.2845, 0.2700, 0.3451, 0.2711, **Epoch: 90
0.2912, 0.3050, 0.3503, 0.2867, 0.2720, 0.3485, 0.3843, 0.3340, 0.3229, 0.3370, **Epoch: 100
0.3389, 0.3296, 0.2845, 0.3045, 0.3967, 0.3108, 0.3725, 0.3265, 0.3819, 0.3129, **Epoch: 110
0.3136, 0.2564, 0.2891, 0.2983, 0.3024, 0.3556, 0.3336, 0.3750, 0.3430, 0.3570, **Epoch: 120
0.2799, 0.3276, 0.3386, 0.3229, 0.3199, 0.2883, 0.3104, 0.3468, 0.3156, 0.3320, **Epoch: 130
0.3536, 0.3084, 0.3104, 0.3046, 0.3604, 0.3448, 0.3216, 0.3090, 0.2946, 0.3241, **Epoch: 140
0.2947, 0.3075, 0.2924, 0.3669, 0.3289, 0.3193, 0.2410, 0.2844, 0.3004, 0.3256, **Epoch: 150
0.2665, 0.3412, 0.2904, 0.2928, 0.2861, 0.3046, 0.3073, 0.2959, 0.3799, 0.2759, **Epoch: 160
0.3512, 0.3819, 0.3775, 0.2901, 0.3746, 0.3164, 0.3219, 0.2719, 0.3442, 0.3652, **Epoch: 170
0.3423, 0.3244, 0.2909, 0.3279, 0.3692, 0.3302, 0.3118, 0.2870, 0.3470, 0.2871, **Epoch: 180
0.3353, 0.3722, 0.3272, 0.3476, 0.2835, 0.3118, 0.3628, 0.2990, 0.3013, 0.3024, **Epoch: 190
0.2735, 0.3076, 0.3244, 0.3148, 0.2928, 0.3607, 0.2766, 0.2702, 0.2712, 0.3003, **Epoch: 200
Validation Loss: 
1.7275, 1.6549, 1.5890, 1.4943, 1.4378, 1.3677, 1.3101, 1.2689, 1.1732, 1.1682, **Epoch: 10
1.1112, 1.0766, 1.0537, 1.0435, 1.0077, 0.9745, 0.9695, 0.9313, 0.9329, 0.9099, **Epoch: 20
0.9224, 0.9332, 0.9386, 0.9398, 0.9227, 0.9480, 0.9436, 0.9282, 0.9239, 0.9473, **Epoch: 30
0.9766, 0.9539, 0.9718, 0.9656, 0.9607, 0.9680, 0.9842, 0.9597, 0.9629, 0.9473, **Epoch: 40
0.9460, 0.9555, 0.9397, 0.9670, 0.9269, 0.9220, 0.9841, 0.9046, 0.9789, 0.9428, **Epoch: 50
0.9765, 0.9582, 0.9481, 0.9722, 0.9994, 0.9254, 0.9284, 0.9521, 0.9556, 0.9525, **Epoch: 60
0.9594, 0.9501, 0.9441, 0.9244, 0.9512, 0.9592, 0.9426, 0.9702, 0.9440, 0.9881, **Epoch: 70
0.8913, 0.9620, 0.9552, 0.9296, 0.9709, 0.9413, 0.9526, 0.9440, 0.9558, 0.9548, **Epoch: 80
0.9271, 0.9393, 0.9160, 0.9816, 0.9489, 0.9234, 0.9630, 0.9663, 0.9522, 0.9529, **Epoch: 90
0.9453, 0.9505, 0.9309, 0.9357, 0.9545, 0.9491, 0.9600, 0.9633, 0.9369, 0.9083, **Epoch: 100
0.9496, 0.9501, 0.9153, 0.9388, 0.9298, 0.9557, 0.9827, 0.9321, 0.9437, 0.9313, **Epoch: 110
0.9249, 0.9417, 0.9291, 0.9116, 0.9615, 0.9448, 0.9757, 0.9450, 0.9261, 0.9628, **Epoch: 120
0.9381, 0.9508, 0.9640, 0.9310, 0.9453, 0.9503, 0.9277, 0.9523, 0.9318, 0.9662, **Epoch: 130
0.9800, 0.9451, 0.9340, 0.9471, 0.9703, 0.9580, 0.9677, 0.9532, 0.9428, 0.9216, **Epoch: 140
0.9393, 0.9387, 0.9359, 0.9087, 0.9093, 0.9308, 0.9367, 0.9723, 0.9220, 0.9313, **Epoch: 150
0.9298, 0.9456, 0.9294, 0.9496, 0.9493, 0.9509, 0.9301, 0.9230, 0.9393, 0.9105, **Epoch: 160
0.9276, 0.9161, 0.9606, 0.9541, 0.9307, 0.9818, 0.9601, 0.9417, 0.9545, 0.9394, **Epoch: 170
0.9740, 0.9548, 0.9264, 0.9301, 0.9664, 0.9542, 0.9238, 0.9417, 0.9150, 0.9440, **Epoch: 180
0.9453, 0.9282, 0.9316, 0.9439, 0.9497, 0.9614, 0.9870, 0.9428, 0.8999, 0.9549, **Epoch: 190
0.9503, 0.9332, 0.9059, 0.9534, 0.9048, 0.9351, 0.9463, 0.9309, 0.9804, 0.8917, **Epoch: 200
Training Accuracy: 
0.7222, 0.7704, 0.8407, 0.8556, 0.8556, 0.8852, 0.9148, 0.8852, 0.9111, 0.9000, **Epoch: 10
0.9296, 0.9333, 0.9148, 0.9111, 0.9037, 0.9222, 0.9037, 0.8963, 0.9259, 0.9222, **Epoch: 20
0.9296, 0.9593, 0.9333, 0.9111, 0.9000, 0.9481, 0.9407, 0.9000, 0.9407, 0.9296, **Epoch: 30
0.9333, 0.9519, 0.9556, 0.9296, 0.9259, 0.9407, 0.9296, 0.9333, 0.9148, 0.9481, **Epoch: 40
0.9407, 0.9444, 0.9111, 0.9148, 0.9185, 0.9148, 0.9407, 0.9259, 0.9370, 0.9185, **Epoch: 50
0.9370, 0.9222, 0.9185, 0.9259, 0.9074, 0.9222, 0.9407, 0.9296, 0.9370, 0.9444, **Epoch: 60
0.9148, 0.9259, 0.9185, 0.9407, 0.9222, 0.9037, 0.9296, 0.9519, 0.9630, 0.9407, **Epoch: 70
0.9259, 0.9222, 0.9259, 0.9333, 0.9333, 0.9148, 0.9481, 0.9556, 0.9593, 0.9185, **Epoch: 80
0.9370, 0.9407, 0.9185, 0.9370, 0.9370, 0.9185, 0.9296, 0.9222, 0.9185, 0.9481, **Epoch: 90
0.9111, 0.9407, 0.9444, 0.9407, 0.9074, 0.9444, 0.9407, 0.9481, 0.9333, 0.9222, **Epoch: 100
0.9333, 0.9630, 0.9444, 0.9370, 0.9296, 0.9370, 0.9111, 0.9222, 0.9556, 0.9370, **Epoch: 110
0.9296, 0.9481, 0.9259, 0.9407, 0.9259, 0.9333, 0.9185, 0.9481, 0.9407, 0.9407, **Epoch: 120
0.9222, 0.9222, 0.9370, 0.9111, 0.9185, 0.9407, 0.9111, 0.9333, 0.9370, 0.9296, **Epoch: 130
0.9296, 0.9407, 0.9259, 0.9407, 0.9259, 0.9185, 0.9296, 0.9333, 0.9370, 0.9222, **Epoch: 140
0.9259, 0.9000, 0.9519, 0.9222, 0.9370, 0.9370, 0.9556, 0.9259, 0.9519, 0.9593, **Epoch: 150
0.9259, 0.9370, 0.9481, 0.9630, 0.9370, 0.9333, 0.9519, 0.9630, 0.9481, 0.9296, **Epoch: 160
0.9111, 0.9370, 0.9444, 0.9370, 0.9370, 0.9741, 0.9444, 0.9407, 0.9481, 0.9259, **Epoch: 170
0.9370, 0.9222, 0.9296, 0.9148, 0.9630, 0.9481, 0.9296, 0.9222, 0.9333, 0.9296, **Epoch: 180
0.9370, 0.9296, 0.9185, 0.9296, 0.9074, 0.9370, 0.9370, 0.9370, 0.9370, 0.9519, **Epoch: 190
0.9296, 0.9333, 0.9111, 0.9407, 0.9630, 0.9148, 0.9444, 0.9259, 0.9407, 0.9259, **Epoch: 200
Validation Accuracy: 
0.6071, 0.6721, 0.6699, 0.6942, 0.6965, 0.6979, 0.7016, 0.7260, 0.7282, 0.7371, **Epoch: 10
0.7341, 0.7223, 0.7422, 0.7496, 0.7378, 0.7386, 0.7393, 0.7386, 0.7334, 0.7408, **Epoch: 20
0.7467, 0.7578, 0.7482, 0.7312, 0.7260, 0.7393, 0.7312, 0.7408, 0.7157, 0.7245, **Epoch: 30
0.7216, 0.7356, 0.7304, 0.7179, 0.7319, 0.7312, 0.7356, 0.7386, 0.7208, 0.7304, **Epoch: 40
0.7275, 0.7282, 0.7312, 0.7097, 0.7267, 0.7238, 0.7341, 0.7216, 0.7260, 0.7245, **Epoch: 50
0.7371, 0.7334, 0.7075, 0.7349, 0.7171, 0.7304, 0.7304, 0.7459, 0.7341, 0.7297, **Epoch: 60
0.7090, 0.7393, 0.7267, 0.7511, 0.7149, 0.7253, 0.7363, 0.7290, 0.7349, 0.7371, **Epoch: 70
0.7208, 0.7319, 0.7282, 0.7157, 0.7290, 0.7341, 0.7356, 0.7408, 0.7326, 0.7290, **Epoch: 80
0.7437, 0.7474, 0.7275, 0.7341, 0.7223, 0.7290, 0.7275, 0.7267, 0.7253, 0.7253, **Epoch: 90
0.7326, 0.7341, 0.7282, 0.7171, 0.7105, 0.7267, 0.7290, 0.7105, 0.7275, 0.7290, **Epoch: 100
0.7208, 0.7253, 0.7378, 0.7363, 0.7312, 0.7326, 0.7349, 0.7334, 0.7408, 0.7216, **Epoch: 110
0.7386, 0.7349, 0.7371, 0.7223, 0.7186, 0.7164, 0.7378, 0.7208, 0.7312, 0.7275, **Epoch: 120
0.7267, 0.7445, 0.7482, 0.7371, 0.7371, 0.7171, 0.7334, 0.7319, 0.7297, 0.7422, **Epoch: 130
0.7260, 0.7326, 0.7304, 0.7230, 0.7253, 0.7334, 0.7386, 0.7304, 0.7216, 0.7201, **Epoch: 140
0.7253, 0.7267, 0.7127, 0.7253, 0.7334, 0.7356, 0.7312, 0.7290, 0.7282, 0.7408, **Epoch: 150
0.7334, 0.7297, 0.7097, 0.7378, 0.7319, 0.7415, 0.7223, 0.7267, 0.7312, 0.7201, **Epoch: 160
0.7437, 0.7194, 0.7275, 0.7105, 0.7393, 0.7275, 0.7341, 0.7319, 0.7452, 0.7230, **Epoch: 170
0.7238, 0.7208, 0.7186, 0.7312, 0.7216, 0.7408, 0.7326, 0.7253, 0.7415, 0.7171, **Epoch: 180
0.7326, 0.7371, 0.7393, 0.7319, 0.7186, 0.7334, 0.7334, 0.7238, 0.7260, 0.7363, **Epoch: 190
0.7393, 0.7319, 0.7334, 0.7157, 0.7356, 0.7297, 0.7415, 0.7467, 0.7208, 0.7164, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1532
Training Loss: 
1.9455, 1.9294, 1.9009, 1.8630, 1.8237, 1.7717, 1.7079, 1.6650, 1.6145, 1.5471, **Epoch: 10
1.5085, 1.4463, 1.4087, 1.3773, 1.3537, 1.2899, 1.2979, 1.2693, 1.2286, 1.1805, **Epoch: 20
1.1827, 1.1335, 1.1259, 1.0654, 1.0775, 1.0456, 1.0832, 1.0613, 0.9839, 1.0042, **Epoch: 30
1.0022, 0.9685, 0.9697, 0.9908, 0.9431, 0.9552, 0.9005, 0.9240, 0.8512, 0.8465, **Epoch: 40
0.8716, 0.8728, 0.8472, 0.8435, 0.8259, 0.8016, 0.8132, 0.7909, 0.8064, 0.7846, **Epoch: 50
0.8006, 0.7833, 0.8205, 0.7712, 0.7545, 0.7623, 0.7482, 0.7091, 0.7003, 0.6846, **Epoch: 60
0.7398, 0.7026, 0.7224, 0.7502, 0.7271, 0.7931, 0.7529, 0.7127, 0.7034, 0.7147, **Epoch: 70
0.6844, 0.7110, 0.6491, 0.7149, 0.7459, 0.7040, 0.6778, 0.6708, 0.6836, 0.7460, **Epoch: 80
0.7134, 0.6646, 0.6730, 0.6863, 0.7263, 0.7124, 0.7252, 0.7310, 0.6871, 0.6748, **Epoch: 90
0.6790, 0.6643, 0.6626, 0.7557, 0.6905, 0.7021, 0.6680, 0.6983, 0.7242, 0.6541, **Epoch: 100
0.7285, 0.6979, 0.6605, 0.6843, 0.6836, 0.7293, 0.6544, 0.7004, 0.7761, 0.7037, **Epoch: 110
0.7241, 0.6719, 0.7249, 0.6809, 0.6415, 0.7398, 0.7072, 0.7023, 0.6726, 0.6919, **Epoch: 120
0.6638, 0.6404, 0.6751, 0.6749, 0.6518, 0.6538, 0.6865, 0.6910, 0.7034, 0.7129, **Epoch: 130
0.6271, 0.6652, 0.7405, 0.6868, 0.7008, 0.7259, 0.7122, 0.6980, 0.6795, 0.6974, **Epoch: 140
0.6704, 0.7107, 0.6771, 0.6839, 0.6912, 0.7682, 0.7000, 0.6973, 0.7111, 0.7120, **Epoch: 150
0.6445, 0.6524, 0.6461, 0.7073, 0.7122, 0.7225, 0.7132, 0.7020, 0.7038, 0.6906, **Epoch: 160
0.6747, 0.6856, 0.6655, 0.6713, 0.6973, 0.6653, 0.6951, 0.6940, 0.7192, 0.6794, **Epoch: 170
0.7387, 0.7259, 0.6750, 0.7168, 0.7096, 0.6814, 0.7171, 0.6654, 0.7263, 0.6227, **Epoch: 180
0.6951, 0.6947, 0.6714, 0.7286, 0.6298, 0.7284, 0.6463, 0.7429, 0.6507, 0.7468, **Epoch: 190
0.6793, 0.7058, 0.6765, 0.6689, 0.6998, 0.6625, 0.7013, 0.7291, 0.6849, 0.6945, **Epoch: 200
Validation Loss: 
1.9322, 1.9096, 1.8770, 1.8406, 1.8021, 1.7683, 1.7216, 1.6804, 1.6394, 1.5901, **Epoch: 10
1.5713, 1.5543, 1.5180, 1.4823, 1.4560, 1.4260, 1.3929, 1.3973, 1.3789, 1.3585, **Epoch: 20
1.3233, 1.3168, 1.3046, 1.2728, 1.2614, 1.2503, 1.2383, 1.2162, 1.1924, 1.2101, **Epoch: 30
1.1948, 1.1826, 1.1671, 1.1631, 1.1420, 1.1423, 1.1298, 1.1230, 1.0977, 1.0952, **Epoch: 40
1.0594, 1.0721, 1.0931, 1.0840, 1.0502, 1.0478, 1.0580, 1.0545, 1.0454, 1.0330, **Epoch: 50
1.0366, 1.0322, 1.0202, 1.0086, 1.0211, 1.0312, 1.0003, 0.9906, 1.0005, 1.0029, **Epoch: 60
1.0044, 0.9860, 1.0209, 0.9932, 0.9750, 0.9813, 0.9850, 0.9670, 0.9807, 1.0025, **Epoch: 70
0.9920, 1.0082, 0.9735, 0.9708, 0.9612, 0.9674, 0.9778, 0.9545, 1.0060, 0.9584, **Epoch: 80
0.9688, 0.9832, 0.9635, 0.9793, 0.9822, 0.9821, 0.9767, 0.9851, 0.9776, 0.9806, **Epoch: 90
0.9686, 0.9725, 0.9598, 0.9667, 0.9987, 0.9698, 0.9645, 0.9792, 0.9782, 0.9687, **Epoch: 100
0.9616, 0.9951, 0.9703, 0.9813, 0.9677, 0.9757, 0.9819, 0.9787, 0.9740, 0.9814, **Epoch: 110
0.9879, 0.9597, 0.9321, 0.9853, 0.9908, 0.9656, 0.9713, 0.9618, 0.9732, 0.9790, **Epoch: 120
0.9857, 0.9798, 0.9571, 0.9644, 0.9799, 0.9673, 0.9523, 0.9906, 0.9642, 0.9715, **Epoch: 130
0.9661, 0.9672, 0.9731, 0.9891, 0.9640, 0.9634, 0.9700, 0.9714, 0.9680, 0.9634, **Epoch: 140
0.9829, 0.9739, 0.9777, 0.9645, 0.9986, 0.9497, 0.9851, 0.9738, 0.9482, 0.9726, **Epoch: 150
0.9832, 0.9641, 0.9663, 0.9679, 0.9684, 0.9801, 0.9825, 0.9618, 0.9773, 0.9675, **Epoch: 160
0.9630, 0.9745, 0.9751, 0.9614, 0.9531, 0.9667, 0.9653, 0.9927, 0.9625, 0.9718, **Epoch: 170
0.9586, 0.9567, 0.9758, 0.9677, 0.9552, 0.9649, 0.9693, 0.9844, 0.9514, 0.9754, **Epoch: 180
0.9780, 0.9625, 0.9657, 0.9896, 0.9640, 0.9639, 0.9954, 0.9786, 0.9582, 0.9796, **Epoch: 190
0.9742, 0.9640, 0.9788, 0.9555, 0.9545, 0.9786, 0.9540, 0.9698, 0.9525, 0.9580, **Epoch: 200
Training Accuracy: 
0.4481, 0.3889, 0.3815, 0.3889, 0.3630, 0.4111, 0.4333, 0.4444, 0.5148, 0.5630, **Epoch: 10
0.5815, 0.6111, 0.6185, 0.6296, 0.6222, 0.6593, 0.6926, 0.7111, 0.6852, 0.7000, **Epoch: 20
0.7370, 0.7111, 0.7259, 0.7185, 0.7407, 0.7593, 0.7296, 0.7593, 0.7667, 0.7519, **Epoch: 30
0.7444, 0.7778, 0.7889, 0.7407, 0.7704, 0.7704, 0.7704, 0.7926, 0.7926, 0.7963, **Epoch: 40
0.8185, 0.8333, 0.8222, 0.7926, 0.8111, 0.8333, 0.8148, 0.8148, 0.8259, 0.8556, **Epoch: 50
0.8519, 0.8556, 0.8630, 0.8630, 0.8444, 0.8630, 0.8778, 0.9000, 0.8593, 0.8630, **Epoch: 60
0.8778, 0.8593, 0.8630, 0.8667, 0.8889, 0.8630, 0.8704, 0.8593, 0.8333, 0.8630, **Epoch: 70
0.8593, 0.8630, 0.8519, 0.8815, 0.9111, 0.8926, 0.8815, 0.9296, 0.8963, 0.8667, **Epoch: 80
0.8630, 0.8926, 0.8852, 0.8815, 0.8815, 0.9000, 0.8519, 0.8889, 0.8963, 0.8963, **Epoch: 90
0.8407, 0.8778, 0.8852, 0.8778, 0.8889, 0.8815, 0.8778, 0.8593, 0.8704, 0.8778, **Epoch: 100
0.8852, 0.8667, 0.8296, 0.8667, 0.8778, 0.8444, 0.8667, 0.8667, 0.8963, 0.8815, **Epoch: 110
0.8852, 0.8852, 0.8778, 0.8852, 0.8741, 0.8704, 0.8222, 0.8519, 0.8815, 0.8667, **Epoch: 120
0.8889, 0.8704, 0.8815, 0.8852, 0.8667, 0.8667, 0.8630, 0.8778, 0.8741, 0.9185, **Epoch: 130
0.8296, 0.8815, 0.8741, 0.8852, 0.8556, 0.8963, 0.8556, 0.8741, 0.8889, 0.9074, **Epoch: 140
0.8704, 0.8519, 0.8741, 0.8556, 0.8963, 0.8889, 0.8704, 0.8889, 0.8741, 0.8667, **Epoch: 150
0.8444, 0.8926, 0.9074, 0.8593, 0.9185, 0.8926, 0.8815, 0.8741, 0.8704, 0.8667, **Epoch: 160
0.8667, 0.8963, 0.8815, 0.8593, 0.8926, 0.8630, 0.8852, 0.8889, 0.8556, 0.8741, **Epoch: 170
0.8926, 0.8889, 0.8778, 0.9111, 0.8852, 0.8741, 0.8741, 0.9037, 0.8778, 0.8630, **Epoch: 180
0.8556, 0.8741, 0.8630, 0.8630, 0.8778, 0.9037, 0.8667, 0.8815, 0.8519, 0.8519, **Epoch: 190
0.8667, 0.8926, 0.8926, 0.8704, 0.8741, 0.8704, 0.8704, 0.8852, 0.8926, 0.8741, **Epoch: 200
Validation Accuracy: 
0.4099, 0.3752, 0.3663, 0.3671, 0.3789, 0.3929, 0.3981, 0.4343, 0.4719, 0.4882, **Epoch: 10
0.5236, 0.5229, 0.5332, 0.5377, 0.5377, 0.5650, 0.5775, 0.5990, 0.6056, 0.5953, **Epoch: 20
0.6189, 0.6211, 0.6270, 0.6381, 0.6307, 0.6270, 0.6514, 0.6462, 0.6595, 0.6647, **Epoch: 30
0.6403, 0.6573, 0.6869, 0.6839, 0.6721, 0.6662, 0.6839, 0.6647, 0.6728, 0.6920, **Epoch: 40
0.6950, 0.6928, 0.6905, 0.6935, 0.6979, 0.6950, 0.7164, 0.6942, 0.7157, 0.7238, **Epoch: 50
0.7312, 0.7208, 0.7304, 0.7275, 0.7260, 0.7245, 0.7334, 0.7489, 0.7282, 0.7127, **Epoch: 60
0.7393, 0.7341, 0.7341, 0.7319, 0.7408, 0.7482, 0.7408, 0.7555, 0.7341, 0.7326, **Epoch: 70
0.7312, 0.7600, 0.7703, 0.7482, 0.7614, 0.7445, 0.7378, 0.7408, 0.7511, 0.7607, **Epoch: 80
0.7334, 0.7422, 0.7467, 0.7371, 0.7422, 0.7349, 0.7445, 0.7459, 0.7629, 0.7304, **Epoch: 90
0.7474, 0.7400, 0.7437, 0.7496, 0.7422, 0.7474, 0.7578, 0.7548, 0.7408, 0.7504, **Epoch: 100
0.7430, 0.7533, 0.7452, 0.7371, 0.7319, 0.7570, 0.7430, 0.7474, 0.7445, 0.7437, **Epoch: 110
0.7563, 0.7526, 0.7555, 0.7467, 0.7422, 0.7504, 0.7474, 0.7703, 0.7363, 0.7341, **Epoch: 120
0.7496, 0.7400, 0.7474, 0.7600, 0.7437, 0.7349, 0.7437, 0.7555, 0.7511, 0.7467, **Epoch: 130
0.7290, 0.7518, 0.7304, 0.7474, 0.7496, 0.7400, 0.7319, 0.7614, 0.7371, 0.7378, **Epoch: 140
0.7415, 0.7482, 0.7459, 0.7437, 0.7526, 0.7585, 0.7533, 0.7526, 0.7422, 0.7526, **Epoch: 150
0.7467, 0.7422, 0.7363, 0.7445, 0.7541, 0.7415, 0.7496, 0.7489, 0.7341, 0.7578, **Epoch: 160
0.7363, 0.7459, 0.7570, 0.7474, 0.7437, 0.7378, 0.7504, 0.7452, 0.7430, 0.7578, **Epoch: 170
0.7666, 0.7555, 0.7555, 0.7526, 0.7408, 0.7452, 0.7378, 0.7349, 0.7386, 0.7408, **Epoch: 180
0.7341, 0.7459, 0.7445, 0.7415, 0.7445, 0.7563, 0.7570, 0.7526, 0.7555, 0.7422, **Epoch: 190
0.7386, 0.7489, 0.7518, 0.7474, 0.7445, 0.7378, 0.7548, 0.7570, 0.7386, 0.7445, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1532
Training Loss: 
1.9462, 1.9323, 1.9105, 1.8808, 1.8416, 1.8045, 1.7689, 1.7072, 1.6375, 1.5920, **Epoch: 10
1.5348, 1.5219, 1.4748, 1.3940, 1.3737, 1.3313, 1.2772, 1.2293, 1.1701, 1.1757, **Epoch: 20
1.1207, 1.1288, 1.0903, 1.0685, 1.0036, 1.0196, 0.9486, 0.9381, 0.9109, 0.9250, **Epoch: 30
0.9270, 0.9349, 0.8882, 0.9134, 0.8617, 0.8992, 0.8540, 0.8420, 0.8375, 0.7858, **Epoch: 40
0.8459, 0.7987, 0.7967, 0.8023, 0.7824, 0.8098, 0.8337, 0.7702, 0.7849, 0.7778, **Epoch: 50
0.7852, 0.7534, 0.7587, 0.7319, 0.7266, 0.7189, 0.7842, 0.7009, 0.7256, 0.7058, **Epoch: 60
0.7297, 0.7535, 0.7491, 0.7255, 0.7310, 0.7079, 0.6848, 0.6880, 0.7092, 0.7101, **Epoch: 70
0.7037, 0.6725, 0.7438, 0.6827, 0.7042, 0.6960, 0.7116, 0.6762, 0.7228, 0.7405, **Epoch: 80
0.7336, 0.6685, 0.7330, 0.6942, 0.6993, 0.7533, 0.6964, 0.6752, 0.7597, 0.7199, **Epoch: 90
0.7301, 0.6997, 0.6989, 0.7389, 0.7053, 0.6855, 0.7000, 0.7075, 0.6793, 0.7307, **Epoch: 100
0.6983, 0.7148, 0.7038, 0.6811, 0.6908, 0.6879, 0.6586, 0.6925, 0.6817, 0.7425, **Epoch: 110
0.6668, 0.6957, 0.7046, 0.7262, 0.6927, 0.6839, 0.6736, 0.7539, 0.7067, 0.6768, **Epoch: 120
0.7214, 0.6899, 0.7162, 0.7334, 0.6750, 0.6831, 0.7250, 0.7095, 0.7264, 0.6758, **Epoch: 130
0.7137, 0.6771, 0.6857, 0.6886, 0.7276, 0.6701, 0.6498, 0.7062, 0.7037, 0.7272, **Epoch: 140
0.6896, 0.7063, 0.6813, 0.6499, 0.6676, 0.7542, 0.7239, 0.6666, 0.7216, 0.7002, **Epoch: 150
0.7200, 0.6413, 0.7242, 0.6413, 0.7076, 0.7194, 0.7045, 0.7265, 0.7290, 0.6854, **Epoch: 160
0.6594, 0.6974, 0.6662, 0.7299, 0.6463, 0.6844, 0.6921, 0.6690, 0.6791, 0.6942, **Epoch: 170
0.7103, 0.7155, 0.7017, 0.7547, 0.6843, 0.6830, 0.6923, 0.6948, 0.6980, 0.6846, **Epoch: 180
0.7510, 0.6930, 0.6889, 0.6621, 0.7140, 0.6785, 0.6849, 0.6546, 0.7464, 0.7129, **Epoch: 190
0.6725, 0.7198, 0.6529, 0.7099, 0.7077, 0.6799, 0.7062, 0.6578, 0.7063, 0.6849, **Epoch: 200
Validation Loss: 
1.9357, 1.9157, 1.8926, 1.8586, 1.8273, 1.7905, 1.7443, 1.7107, 1.6689, 1.6260, **Epoch: 10
1.5851, 1.5392, 1.5117, 1.4662, 1.4334, 1.3997, 1.3963, 1.3457, 1.3269, 1.3192, **Epoch: 20
1.2652, 1.2526, 1.2337, 1.1992, 1.1924, 1.1846, 1.1888, 1.1820, 1.1668, 1.1457, **Epoch: 30
1.1269, 1.1386, 1.1240, 1.1245, 1.1026, 1.1220, 1.1095, 1.1125, 1.0867, 1.0724, **Epoch: 40
1.0912, 1.0581, 1.0585, 1.0576, 1.0737, 1.0504, 1.0591, 1.0699, 1.0094, 1.0576, **Epoch: 50
1.0365, 1.0308, 1.0132, 1.0215, 1.0187, 1.0159, 1.0095, 1.0133, 1.0236, 0.9921, **Epoch: 60
1.0073, 0.9823, 0.9818, 0.9837, 0.9938, 0.9754, 0.9517, 0.9748, 0.9788, 0.9692, **Epoch: 70
0.9694, 0.9920, 1.0103, 1.0070, 0.9832, 1.0019, 0.9797, 0.9712, 0.9907, 0.9886, **Epoch: 80
0.9649, 0.9796, 0.9714, 0.9765, 0.9578, 0.9742, 0.9758, 0.9735, 0.9398, 0.9772, **Epoch: 90
0.9895, 0.9640, 0.9677, 0.9708, 0.9702, 0.9723, 0.9809, 0.9815, 0.9616, 0.9965, **Epoch: 100
0.9866, 0.9918, 0.9652, 0.9795, 0.9692, 0.9838, 0.9721, 0.9891, 0.9896, 0.9907, **Epoch: 110
0.9694, 0.9639, 0.9696, 0.9822, 0.9560, 0.9969, 0.9826, 0.9925, 0.9730, 0.9846, **Epoch: 120
0.9570, 0.9765, 0.9726, 0.9914, 0.9626, 0.9824, 0.9777, 0.9596, 0.9749, 0.9562, **Epoch: 130
0.9646, 0.9664, 0.9664, 0.9820, 0.9735, 0.9805, 0.9820, 0.9903, 0.9721, 0.9663, **Epoch: 140
0.9786, 0.9916, 0.9769, 0.9804, 1.0171, 0.9872, 0.9988, 0.9790, 0.9565, 0.9859, **Epoch: 150
0.9812, 0.9698, 1.0094, 0.9825, 0.9877, 0.9842, 0.9530, 0.9596, 0.9464, 0.9834, **Epoch: 160
0.9600, 0.9739, 0.9939, 0.9893, 0.9436, 0.9669, 0.9735, 0.9633, 0.9580, 0.9923, **Epoch: 170
0.9772, 0.9889, 0.9720, 0.9855, 0.9878, 0.9845, 0.9742, 0.9843, 0.9475, 0.9723, **Epoch: 180
0.9623, 0.9948, 0.9669, 0.9822, 0.9845, 0.9826, 0.9768, 0.9542, 0.9715, 0.9412, **Epoch: 190
0.9866, 0.9970, 1.0188, 1.0028, 0.9703, 0.9652, 0.9807, 0.9873, 0.9499, 0.9805, **Epoch: 200
Training Accuracy: 
0.3444, 0.3037, 0.3111, 0.3074, 0.3111, 0.3333, 0.3407, 0.3481, 0.4222, 0.5593, **Epoch: 10
0.5593, 0.6630, 0.7037, 0.7481, 0.7333, 0.7370, 0.7519, 0.7185, 0.7519, 0.7667, **Epoch: 20
0.7444, 0.7519, 0.7667, 0.7889, 0.7519, 0.7444, 0.7704, 0.7667, 0.7926, 0.7741, **Epoch: 30
0.7556, 0.7963, 0.7556, 0.7741, 0.7778, 0.7778, 0.7852, 0.8111, 0.7963, 0.7741, **Epoch: 40
0.7815, 0.8000, 0.8037, 0.8222, 0.8185, 0.8222, 0.8074, 0.8222, 0.8259, 0.8407, **Epoch: 50
0.8481, 0.8593, 0.8370, 0.8444, 0.8481, 0.8741, 0.8778, 0.8741, 0.8667, 0.8370, **Epoch: 60
0.8667, 0.8519, 0.8852, 0.8741, 0.8741, 0.8519, 0.8704, 0.8556, 0.9111, 0.8963, **Epoch: 70
0.8704, 0.8630, 0.8778, 0.8704, 0.8556, 0.8889, 0.8963, 0.8556, 0.8741, 0.8593, **Epoch: 80
0.8444, 0.8667, 0.8741, 0.8778, 0.8519, 0.8741, 0.8630, 0.8926, 0.8741, 0.8741, **Epoch: 90
0.8667, 0.8704, 0.9185, 0.8852, 0.8593, 0.8926, 0.8926, 0.8852, 0.8667, 0.8815, **Epoch: 100
0.8741, 0.8778, 0.8889, 0.9000, 0.8593, 0.8667, 0.8815, 0.8593, 0.8778, 0.8852, **Epoch: 110
0.8667, 0.8630, 0.8519, 0.8704, 0.8815, 0.8704, 0.8704, 0.8593, 0.8667, 0.8481, **Epoch: 120
0.9037, 0.8556, 0.8667, 0.8852, 0.8630, 0.8704, 0.8593, 0.8704, 0.8630, 0.8704, **Epoch: 130
0.8556, 0.8741, 0.8778, 0.8889, 0.8778, 0.8815, 0.8630, 0.8630, 0.8481, 0.8926, **Epoch: 140
0.8407, 0.8815, 0.9037, 0.8852, 0.8852, 0.8481, 0.8815, 0.8519, 0.8704, 0.8926, **Epoch: 150
0.8667, 0.8556, 0.8667, 0.8852, 0.8704, 0.8593, 0.8481, 0.8704, 0.8630, 0.8704, **Epoch: 160
0.8704, 0.9111, 0.9037, 0.8519, 0.8778, 0.8704, 0.8593, 0.8926, 0.8519, 0.8926, **Epoch: 170
0.8667, 0.8889, 0.8333, 0.8704, 0.8370, 0.8889, 0.8852, 0.8815, 0.8926, 0.8593, **Epoch: 180
0.8741, 0.8556, 0.8444, 0.8481, 0.8815, 0.8778, 0.8889, 0.8852, 0.8852, 0.8593, **Epoch: 190
0.8815, 0.8815, 0.8926, 0.8741, 0.8778, 0.8741, 0.8519, 0.8556, 0.8370, 0.8778, **Epoch: 200
Validation Accuracy: 
0.3397, 0.3198, 0.3124, 0.3095, 0.3183, 0.3287, 0.3360, 0.3516, 0.4106, 0.4904, **Epoch: 10
0.5362, 0.5739, 0.6285, 0.6337, 0.6492, 0.6677, 0.6617, 0.6669, 0.6736, 0.6603, **Epoch: 20
0.6721, 0.6684, 0.6691, 0.6706, 0.6795, 0.6802, 0.6728, 0.6780, 0.6802, 0.6713, **Epoch: 30
0.6861, 0.6869, 0.6758, 0.6521, 0.6773, 0.6728, 0.6780, 0.6758, 0.6758, 0.6832, **Epoch: 40
0.6832, 0.6809, 0.6854, 0.6869, 0.6928, 0.6869, 0.6928, 0.7075, 0.7061, 0.7083, **Epoch: 50
0.7164, 0.7157, 0.7341, 0.7260, 0.7356, 0.7363, 0.7371, 0.7349, 0.7422, 0.7371, **Epoch: 60
0.7533, 0.7408, 0.7422, 0.7304, 0.7179, 0.7319, 0.7415, 0.7489, 0.7504, 0.7555, **Epoch: 70
0.7378, 0.7482, 0.7393, 0.7482, 0.7703, 0.7504, 0.7467, 0.7304, 0.7319, 0.7334, **Epoch: 80
0.7260, 0.7504, 0.7563, 0.7614, 0.7467, 0.7437, 0.7548, 0.7526, 0.7371, 0.7430, **Epoch: 90
0.7378, 0.7290, 0.7548, 0.7482, 0.7474, 0.7600, 0.7422, 0.7356, 0.7437, 0.7408, **Epoch: 100
0.7267, 0.7430, 0.7541, 0.7518, 0.7415, 0.7467, 0.7629, 0.7452, 0.7378, 0.7422, **Epoch: 110
0.7459, 0.7452, 0.7459, 0.7415, 0.7386, 0.7371, 0.7312, 0.7386, 0.7467, 0.7422, **Epoch: 120
0.7563, 0.7341, 0.7430, 0.7312, 0.7326, 0.7570, 0.7504, 0.7474, 0.7459, 0.7422, **Epoch: 130
0.7312, 0.7518, 0.7533, 0.7511, 0.7511, 0.7629, 0.7452, 0.7319, 0.7356, 0.7504, **Epoch: 140
0.7489, 0.7548, 0.7467, 0.7474, 0.7452, 0.7260, 0.7504, 0.7341, 0.7445, 0.7614, **Epoch: 150
0.7430, 0.7526, 0.7415, 0.7304, 0.7341, 0.7275, 0.7430, 0.7422, 0.7541, 0.7408, **Epoch: 160
0.7563, 0.7563, 0.7437, 0.7371, 0.7548, 0.7496, 0.7445, 0.7504, 0.7570, 0.7386, **Epoch: 170
0.7378, 0.7459, 0.7474, 0.7363, 0.7437, 0.7445, 0.7489, 0.7600, 0.7674, 0.7541, **Epoch: 180
0.7371, 0.7334, 0.7349, 0.7386, 0.7393, 0.7445, 0.7408, 0.7467, 0.7518, 0.7496, **Epoch: 190
0.7363, 0.7445, 0.7422, 0.7349, 0.7297, 0.7526, 0.7504, 0.7282, 0.7415, 0.7541, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
----------------------------------------------------------
Time: 0510-1534
Training Loss: 
1.9458, 1.9321, 1.9062, 1.8805, 1.8341, 1.7939, 1.7290, 1.6885, 1.6574, 1.5645, **Epoch: 10
1.5027, 1.4497, 1.4312, 1.4146, 1.3465, 1.3415, 1.2949, 1.2530, 1.2448, 1.1985, **Epoch: 20
1.1955, 1.1736, 1.1612, 1.1514, 1.1302, 1.0807, 1.0608, 1.0903, 1.0213, 1.0111, **Epoch: 30
1.0374, 0.9801, 0.9684, 0.9700, 0.9786, 0.9267, 0.9821, 0.9665, 0.9025, 0.9257, **Epoch: 40
0.9521, 0.9011, 0.9081, 0.8952, 0.8603, 0.8628, 0.8340, 0.8935, 0.8740, 0.8241, **Epoch: 50
0.8909, 0.8439, 0.8278, 0.8639, 0.8190, 0.8141, 0.8289, 0.8244, 0.7970, 0.8131, **Epoch: 60
0.7506, 0.7737, 0.7802, 0.7902, 0.7414, 0.7781, 0.7454, 0.7491, 0.7484, 0.7289, **Epoch: 70
0.7247, 0.7195, 0.6649, 0.7089, 0.7364, 0.7489, 0.7326, 0.7192, 0.6577, 0.7225, **Epoch: 80
0.7182, 0.7236, 0.7007, 0.7123, 0.7777, 0.6903, 0.6792, 0.6922, 0.7334, 0.7599, **Epoch: 90
0.6975, 0.7202, 0.7504, 0.6876, 0.7208, 0.7177, 0.6489, 0.6591, 0.7114, 0.6695, **Epoch: 100
0.6922, 0.6456, 0.6857, 0.6579, 0.6725, 0.7389, 0.7008, 0.6699, 0.7168, 0.7119, **Epoch: 110
0.6790, 0.6981, 0.7474, 0.7049, 0.6846, 0.6768, 0.6684, 0.7230, 0.7109, 0.6724, **Epoch: 120
0.6573, 0.7194, 0.7560, 0.6431, 0.6580, 0.7051, 0.6957, 0.7404, 0.6985, 0.6871, **Epoch: 130
0.6436, 0.6907, 0.6762, 0.6871, 0.7050, 0.6905, 0.6638, 0.6965, 0.7104, 0.6561, **Epoch: 140
0.7145, 0.6950, 0.7274, 0.7002, 0.6942, 0.6709, 0.6773, 0.6968, 0.7047, 0.6442, **Epoch: 150
0.7036, 0.6660, 0.7131, 0.7006, 0.6964, 0.7312, 0.6671, 0.6395, 0.6865, 0.7194, **Epoch: 160
0.6944, 0.6887, 0.6910, 0.7406, 0.7157, 0.7209, 0.6916, 0.6977, 0.6648, 0.6787, **Epoch: 170
0.7175, 0.6371, 0.7334, 0.6918, 0.6944, 0.6793, 0.6711, 0.6665, 0.6854, 0.6871, **Epoch: 180
0.7251, 0.7005, 0.7471, 0.6657, 0.6681, 0.6982, 0.6850, 0.6948, 0.7396, 0.7255, **Epoch: 190
0.6963, 0.6615, 0.6882, 0.6679, 0.7105, 0.6940, 0.6927, 0.6989, 0.7271, 0.6763, **Epoch: 200
Validation Loss: 
1.9344, 1.9141, 1.8886, 1.8503, 1.8156, 1.7709, 1.7332, 1.6869, 1.6502, 1.6073, **Epoch: 10
1.5782, 1.5382, 1.5042, 1.4887, 1.4623, 1.4287, 1.3983, 1.3949, 1.3677, 1.3297, **Epoch: 20
1.3279, 1.2910, 1.2964, 1.2687, 1.3005, 1.2594, 1.2671, 1.2260, 1.2209, 1.2303, **Epoch: 30
1.2148, 1.1913, 1.1888, 1.1693, 1.1750, 1.1806, 1.1691, 1.1470, 1.1392, 1.1269, **Epoch: 40
1.1323, 1.1083, 1.1188, 1.1164, 1.1164, 1.1038, 1.1145, 1.1213, 1.0718, 1.1013, **Epoch: 50
1.0913, 1.0648, 1.0646, 1.0788, 1.0678, 1.0713, 1.0759, 1.0646, 1.0601, 1.0667, **Epoch: 60
1.0538, 1.0516, 1.0480, 1.0264, 1.0254, 1.0103, 1.0276, 1.0203, 1.0389, 1.0513, **Epoch: 70
0.9951, 1.0083, 1.0267, 0.9853, 1.0162, 0.9981, 0.9969, 1.0104, 1.0135, 1.0275, **Epoch: 80
1.0124, 0.9879, 0.9913, 1.0286, 1.0105, 0.9899, 0.9997, 0.9921, 0.9703, 0.9787, **Epoch: 90
0.9852, 0.9866, 1.0007, 0.9731, 0.9897, 0.9826, 0.9744, 0.9739, 0.9641, 0.9844, **Epoch: 100
0.9675, 0.9882, 0.9887, 0.9880, 0.9929, 0.9875, 0.9863, 0.9769, 0.9837, 0.9909, **Epoch: 110
0.9775, 0.9827, 0.9680, 0.9804, 0.9628, 0.9765, 0.9564, 0.9974, 0.9696, 0.9710, **Epoch: 120
0.9624, 0.9609, 0.9671, 0.9880, 0.9762, 0.9793, 0.9986, 0.9523, 0.9787, 0.9807, **Epoch: 130
0.9676, 0.9689, 0.9464, 0.9749, 0.9425, 1.0004, 0.9721, 0.9609, 0.9697, 0.9869, **Epoch: 140
0.9602, 0.9581, 0.9733, 0.9994, 0.9706, 0.9981, 0.9801, 0.9730, 0.9781, 0.9686, **Epoch: 150
0.9849, 0.9838, 0.9656, 0.9811, 0.9835, 0.9759, 0.9651, 0.9614, 0.9436, 0.9569, **Epoch: 160
0.9776, 0.9421, 0.9474, 0.9591, 0.9801, 0.9835, 0.9592, 0.9801, 0.9847, 0.9975, **Epoch: 170
0.9568, 0.9712, 0.9684, 0.9716, 0.9686, 0.9916, 0.9677, 1.0052, 0.9896, 0.9863, **Epoch: 180
0.9720, 0.9638, 1.0015, 0.9953, 0.9852, 0.9961, 0.9787, 0.9685, 0.9598, 0.9451, **Epoch: 190
0.9719, 0.9582, 0.9502, 0.9581, 0.9974, 0.9663, 0.9615, 0.9420, 0.9748, 0.9725, **Epoch: 200
Training Accuracy: 
0.3111, 0.2815, 0.2704, 0.2889, 0.2481, 0.2963, 0.3185, 0.3481, 0.4148, 0.5111, **Epoch: 10
0.5037, 0.5481, 0.5667, 0.5481, 0.5704, 0.5741, 0.5556, 0.5963, 0.5963, 0.5815, **Epoch: 20
0.5926, 0.6407, 0.6407, 0.6741, 0.7185, 0.7037, 0.7074, 0.7370, 0.7444, 0.7370, **Epoch: 30
0.7593, 0.7815, 0.7741, 0.7852, 0.7741, 0.7852, 0.7481, 0.7852, 0.7926, 0.7778, **Epoch: 40
0.7741, 0.7667, 0.7889, 0.7852, 0.7704, 0.8000, 0.7593, 0.7852, 0.7815, 0.7963, **Epoch: 50
0.7963, 0.7963, 0.7815, 0.7741, 0.8037, 0.8074, 0.8296, 0.8296, 0.8074, 0.7926, **Epoch: 60
0.7963, 0.8148, 0.8259, 0.8185, 0.8370, 0.8407, 0.8370, 0.8333, 0.8333, 0.8519, **Epoch: 70
0.7926, 0.8333, 0.8333, 0.7815, 0.8407, 0.8519, 0.7926, 0.8667, 0.8556, 0.8667, **Epoch: 80
0.8556, 0.8630, 0.9037, 0.8630, 0.8704, 0.8815, 0.8889, 0.8741, 0.8704, 0.8667, **Epoch: 90
0.8963, 0.8815, 0.8667, 0.8704, 0.8556, 0.8741, 0.8556, 0.8741, 0.8741, 0.8667, **Epoch: 100
0.8889, 0.8926, 0.8815, 0.9000, 0.9000, 0.8926, 0.8889, 0.8444, 0.8556, 0.8667, **Epoch: 110
0.8704, 0.8593, 0.8815, 0.8889, 0.8630, 0.8630, 0.8481, 0.8926, 0.8778, 0.8741, **Epoch: 120
0.8778, 0.8444, 0.8741, 0.8778, 0.8852, 0.8593, 0.8704, 0.9111, 0.8926, 0.8778, **Epoch: 130
0.8852, 0.8593, 0.8852, 0.8667, 0.8630, 0.8741, 0.8963, 0.8926, 0.9000, 0.8852, **Epoch: 140
0.8926, 0.8556, 0.8778, 0.8593, 0.8667, 0.9000, 0.8889, 0.8926, 0.8963, 0.8741, **Epoch: 150
0.8778, 0.8889, 0.8815, 0.8889, 0.8926, 0.8889, 0.8481, 0.8926, 0.8741, 0.8556, **Epoch: 160
0.8667, 0.8704, 0.8963, 0.8741, 0.8778, 0.8259, 0.8852, 0.9000, 0.8741, 0.8852, **Epoch: 170
0.8852, 0.8852, 0.8926, 0.8778, 0.8704, 0.8556, 0.9000, 0.8963, 0.8778, 0.8889, **Epoch: 180
0.8741, 0.8852, 0.8926, 0.8889, 0.8667, 0.8370, 0.8963, 0.8926, 0.8889, 0.8815, **Epoch: 190
0.8630, 0.8852, 0.8704, 0.8926, 0.8778, 0.8852, 0.8630, 0.8667, 0.8296, 0.8630, **Epoch: 200
Validation Accuracy: 
0.3161, 0.3006, 0.3013, 0.3013, 0.3013, 0.3058, 0.3242, 0.3619, 0.4298, 0.4601, **Epoch: 10
0.4874, 0.4970, 0.5185, 0.5059, 0.5281, 0.5244, 0.5244, 0.5258, 0.5391, 0.5451, **Epoch: 20
0.5495, 0.5613, 0.5768, 0.5835, 0.5931, 0.5916, 0.6145, 0.6307, 0.6160, 0.6521, **Epoch: 30
0.6455, 0.6448, 0.6684, 0.6640, 0.6736, 0.6640, 0.6677, 0.6595, 0.6758, 0.6802, **Epoch: 40
0.6669, 0.6728, 0.6706, 0.6662, 0.6713, 0.6869, 0.6677, 0.6869, 0.6662, 0.6691, **Epoch: 50
0.6758, 0.6846, 0.6824, 0.6839, 0.6809, 0.7046, 0.6913, 0.6987, 0.6898, 0.7001, **Epoch: 60
0.7046, 0.7031, 0.7223, 0.7075, 0.7157, 0.6957, 0.7157, 0.7105, 0.7024, 0.7105, **Epoch: 70
0.7171, 0.7127, 0.7290, 0.7267, 0.7230, 0.7253, 0.7127, 0.7326, 0.7297, 0.7238, **Epoch: 80
0.7326, 0.7267, 0.7201, 0.7282, 0.7326, 0.7304, 0.7422, 0.7275, 0.7312, 0.7378, **Epoch: 90
0.7400, 0.7533, 0.7467, 0.7422, 0.7290, 0.7489, 0.7304, 0.7533, 0.7437, 0.7504, **Epoch: 100
0.7526, 0.7386, 0.7541, 0.7363, 0.7459, 0.7422, 0.7459, 0.7356, 0.7349, 0.7400, **Epoch: 110
0.7260, 0.7511, 0.7437, 0.7445, 0.7637, 0.7445, 0.7541, 0.7518, 0.7504, 0.7326, **Epoch: 120
0.7319, 0.7408, 0.7504, 0.7600, 0.7400, 0.7445, 0.7393, 0.7459, 0.7511, 0.7334, **Epoch: 130
0.7467, 0.7282, 0.7445, 0.7422, 0.7637, 0.7445, 0.7474, 0.7570, 0.7696, 0.7629, **Epoch: 140
0.7452, 0.7430, 0.7356, 0.7297, 0.7282, 0.7518, 0.7637, 0.7548, 0.7474, 0.7578, **Epoch: 150
0.7452, 0.7341, 0.7415, 0.7474, 0.7592, 0.7445, 0.7474, 0.7592, 0.7555, 0.7356, **Epoch: 160
0.7430, 0.7467, 0.7489, 0.7349, 0.7482, 0.7326, 0.7430, 0.7563, 0.7511, 0.7489, **Epoch: 170
0.7504, 0.7400, 0.7408, 0.7437, 0.7504, 0.7452, 0.7371, 0.7334, 0.7518, 0.7378, **Epoch: 180
0.7474, 0.7445, 0.7422, 0.7378, 0.7570, 0.7371, 0.7578, 0.7415, 0.7459, 0.7496, **Epoch: 190
0.7386, 0.7578, 0.7474, 0.7563, 0.7659, 0.7533, 0.7437, 0.7400, 0.7533, 0.7437, **Epoch: 200
Learning rate: 0.1
Weight decay: 0.0005
Drop rate: 0.5
Epochs: 200
--------------------------END------------------------------
